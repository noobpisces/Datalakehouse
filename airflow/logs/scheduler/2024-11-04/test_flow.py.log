[2024-11-04T10:41:56.592+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:41:56.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:41:56.596+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:41:56.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:41:56.616+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:41:56.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:41:56.618+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:41:56.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-04T10:44:32.420+0000] {processor.py:157} INFO - Started process (PID=215) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:44:32.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:44:32.423+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:44:32.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:44:32.448+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:44:32.444+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:44:32.449+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:44:32.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T10:45:02.664+0000] {processor.py:157} INFO - Started process (PID=266) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:02.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:45:02.667+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:45:02.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:02.687+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:45:02.682+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:45:02.688+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:02.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T10:45:33.020+0000] {processor.py:157} INFO - Started process (PID=320) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:33.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:45:33.023+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:45:33.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:33.044+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:45:33.039+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:45:33.045+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:45:33.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T10:46:03.504+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:03.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:46:03.506+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:46:03.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:03.528+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:46:03.522+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:46:03.529+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:03.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T10:46:33.811+0000] {processor.py:157} INFO - Started process (PID=452) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:33.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:46:33.814+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:46:33.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:33.836+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:46:33.831+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:46:33.838+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:46:33.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T10:47:04.167+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:04.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:47:04.170+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:47:04.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:04.192+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:47:04.187+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:47:04.194+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:04.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T10:47:34.821+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:35.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:47:35.085+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:47:35.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:37.865+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:47:35.103+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:47:37.867+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:47:38.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 3.319 seconds
[2024-11-04T10:48:08.341+0000] {processor.py:157} INFO - Started process (PID=905) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:08.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:48:08.344+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:48:08.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:08.362+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:48:08.358+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:48:08.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:08.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T10:48:38.532+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:38.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:48:38.535+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:48:38.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:38.559+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:48:38.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:48:38.560+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:48:38.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-04T10:49:08.829+0000] {processor.py:157} INFO - Started process (PID=1411) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:08.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:49:08.832+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:49:08.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:08.851+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:49:08.847+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:49:08.852+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:08.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-04T10:49:39.323+0000] {processor.py:157} INFO - Started process (PID=1462) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:39.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:49:39.326+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:49:39.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:39.346+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:49:39.342+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:49:39.347+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:49:39.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-04T10:50:09.761+0000] {processor.py:157} INFO - Started process (PID=1513) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:09.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:50:09.765+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:50:09.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:09.791+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:50:09.785+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:50:09.792+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:09.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-04T10:50:40.209+0000] {processor.py:157} INFO - Started process (PID=1564) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:40.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:50:40.211+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:50:40.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:40.233+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:50:40.228+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:50:40.234+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:50:40.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T10:51:10.560+0000] {processor.py:157} INFO - Started process (PID=1615) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:10.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:51:10.563+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:51:10.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:10.583+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:51:10.579+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:51:10.584+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:10.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-04T10:51:41.107+0000] {processor.py:157} INFO - Started process (PID=1822) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:41.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:51:41.112+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:51:41.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:41.136+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:51:41.131+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:51:41.138+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:51:41.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T10:52:11.308+0000] {processor.py:157} INFO - Started process (PID=2011) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:11.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:52:11.311+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:52:11.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:11.336+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:52:11.329+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:52:11.337+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:11.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.056 seconds
[2024-11-04T10:52:41.600+0000] {processor.py:157} INFO - Started process (PID=2191) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:41.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:52:41.603+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:52:41.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:41.623+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:52:41.619+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:52:41.624+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:52:41.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-04T10:53:12.186+0000] {processor.py:157} INFO - Started process (PID=2242) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:12.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:53:12.189+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:53:12.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:12.209+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:53:12.204+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:53:12.210+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:12.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T10:53:42.534+0000] {processor.py:157} INFO - Started process (PID=2293) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:42.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:53:42.537+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:53:42.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:42.559+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:53:42.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:53:42.560+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:53:42.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-04T10:54:12.910+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:12.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:54:12.913+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:54:12.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:12.933+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:54:12.929+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:54:12.934+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:12.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-04T10:54:43.527+0000] {processor.py:157} INFO - Started process (PID=2395) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:43.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:54:43.534+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:54:43.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:43.575+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:54:43.566+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:54:43.577+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:54:43.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.091 seconds
[2024-11-04T10:55:13.821+0000] {processor.py:157} INFO - Started process (PID=2446) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:13.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:55:13.823+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:55:13.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:13.843+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:55:13.839+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:55:13.844+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:13.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-04T10:55:44.032+0000] {processor.py:157} INFO - Started process (PID=2497) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:44.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:55:44.035+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:55:44.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:44.056+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:55:44.051+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:55:44.057+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:55:44.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T10:56:14.506+0000] {processor.py:157} INFO - Started process (PID=2729) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:14.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:56:14.510+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:56:14.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:14.536+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:56:14.531+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:56:14.537+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:14.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T10:56:45.215+0000] {processor.py:157} INFO - Started process (PID=3005) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:45.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:56:45.218+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:56:45.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:45.238+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:56:45.234+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:56:45.240+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:56:46.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.800 seconds
[2024-11-04T10:57:16.624+0000] {processor.py:157} INFO - Started process (PID=3056) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:16.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:57:16.627+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:57:16.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:16.649+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:57:16.645+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:57:16.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:16.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-04T10:57:46.967+0000] {processor.py:157} INFO - Started process (PID=3107) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:46.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:57:46.971+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:57:46.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:47.004+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:57:46.995+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:57:47.006+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:57:47.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-04T10:58:17.220+0000] {processor.py:157} INFO - Started process (PID=3158) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:17.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:58:17.223+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:58:17.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:17.243+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:58:17.238+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:58:17.244+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:17.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-04T10:58:48.028+0000] {processor.py:157} INFO - Started process (PID=3562) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:48.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:58:48.040+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:58:48.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:48.123+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:58:48.111+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:58:48.124+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:58:48.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.143 seconds
[2024-11-04T10:59:18.217+0000] {processor.py:157} INFO - Started process (PID=3710) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:18.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:59:18.221+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:59:18.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:18.246+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:59:18.240+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:59:18.248+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:18.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T10:59:48.956+0000] {processor.py:157} INFO - Started process (PID=3761) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:48.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T10:59:48.959+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:59:48.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:48.983+0000] {logging_mixin.py:151} INFO - [2024-11-04T10:59:48.977+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T10:59:48.984+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T10:59:49.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-04T11:00:19.200+0000] {processor.py:157} INFO - Started process (PID=3812) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:19.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:00:19.202+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:00:19.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:19.222+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:00:19.217+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:00:19.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:19.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-04T11:00:49.513+0000] {processor.py:157} INFO - Started process (PID=3863) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:49.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:00:49.515+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:00:49.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:49.536+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:00:49.532+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:00:49.537+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:00:49.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-04T11:01:19.804+0000] {processor.py:157} INFO - Started process (PID=3914) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:19.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:01:19.807+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:01:19.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:19.828+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:01:19.823+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:01:19.829+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:19.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:01:50.252+0000] {processor.py:157} INFO - Started process (PID=4287) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:50.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:01:50.259+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:01:50.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:50.312+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:01:50.304+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:01:50.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:01:50.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.100 seconds
[2024-11-04T11:02:22.052+0000] {processor.py:157} INFO - Started process (PID=4348) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:22.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:02:22.055+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:02:22.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:22.080+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:02:22.073+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:02:22.081+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:22.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.055 seconds
[2024-11-04T11:02:53.046+0000] {processor.py:157} INFO - Started process (PID=4573) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:53.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:02:53.049+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:02:53.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:53.074+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:02:53.068+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:02:53.075+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:02:53.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-04T11:03:23.541+0000] {processor.py:157} INFO - Started process (PID=4797) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:23.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:03:23.544+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:03:23.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:23.567+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:03:23.562+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:03:23.569+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:23.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:03:53.819+0000] {processor.py:157} INFO - Started process (PID=4848) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:53.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:03:53.822+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:03:53.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:53.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:03:53.840+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:03:53.846+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:03:53.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:04:24.028+0000] {processor.py:157} INFO - Started process (PID=4899) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:24.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:04:24.032+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:04:24.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:24.056+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:04:24.051+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:04:24.058+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:24.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-04T11:04:54.212+0000] {processor.py:157} INFO - Started process (PID=4950) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:54.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:04:54.217+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:04:54.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:54.246+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:04:54.241+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:04:54.248+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:04:54.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.059 seconds
[2024-11-04T11:05:24.537+0000] {processor.py:157} INFO - Started process (PID=5001) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:24.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:05:24.540+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:05:24.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:24.563+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:05:24.557+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:05:24.563+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:24.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:05:54.818+0000] {processor.py:157} INFO - Started process (PID=5209) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:54.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:05:54.822+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:05:54.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:54.846+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:05:54.840+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:05:54.847+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:05:54.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-04T11:06:25.393+0000] {processor.py:157} INFO - Started process (PID=5488) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:25.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:06:25.398+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:06:25.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:25.427+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:06:25.421+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:06:25.428+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.060 seconds
[2024-11-04T11:06:55.568+0000] {processor.py:157} INFO - Started process (PID=5602) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:55.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:06:55.575+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:06:55.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:55.598+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:06:55.593+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:06:55.600+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:06:55.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-04T11:07:25.950+0000] {processor.py:157} INFO - Started process (PID=5655) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:25.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:07:25.959+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:07:25.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:25.984+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:07:25.978+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:07:25.986+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:26.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-04T11:07:56.301+0000] {processor.py:157} INFO - Started process (PID=5891) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:56.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:07:56.305+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:07:56.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:56.332+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:07:56.326+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:07:56.333+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:07:56.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.056 seconds
[2024-11-04T11:08:26.596+0000] {processor.py:157} INFO - Started process (PID=6206) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:26.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:08:26.599+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:08:26.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:26.621+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:08:26.616+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:08:26.622+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:26.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:08:57.076+0000] {processor.py:157} INFO - Started process (PID=6257) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:57.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:08:57.079+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:08:57.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:57.103+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:08:57.097+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:08:57.104+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:08:57.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:09:27.588+0000] {processor.py:157} INFO - Started process (PID=6308) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:27.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:09:27.592+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:09:27.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:27.614+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:09:27.609+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:09:27.615+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:27.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:09:57.982+0000] {processor.py:157} INFO - Started process (PID=6359) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:57.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:09:57.985+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:09:57.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:58.006+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:09:58.002+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:09:58.008+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:09:58.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:10:28.552+0000] {processor.py:157} INFO - Started process (PID=6410) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:28.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:10:28.556+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:10:28.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:28.578+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:10:28.574+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:10:28.580+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:28.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.055 seconds
[2024-11-04T11:10:59.105+0000] {processor.py:157} INFO - Started process (PID=6461) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:59.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:10:59.108+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:10:59.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:59.130+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:10:59.124+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:10:59.131+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:10:59.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:11:29.623+0000] {processor.py:157} INFO - Started process (PID=6512) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:11:29.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:11:29.626+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:11:29.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:11:29.649+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:11:29.643+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:11:29.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:11:29.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:12:00.253+0000] {processor.py:157} INFO - Started process (PID=6563) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:00.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:12:00.260+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:12:00.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:00.285+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:12:00.280+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:12:00.287+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:00.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.055 seconds
[2024-11-04T11:12:30.871+0000] {processor.py:157} INFO - Started process (PID=6667) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:30.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:12:30.874+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:12:30.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:30.899+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:12:30.894+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:12:30.901+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:12:30.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T11:13:01.340+0000] {processor.py:157} INFO - Started process (PID=6896) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:01.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:13:01.344+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:13:01.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:01.392+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:13:01.381+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:13:01.393+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:01.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.087 seconds
[2024-11-04T11:13:31.486+0000] {processor.py:157} INFO - Started process (PID=7170) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:31.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:13:31.489+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:13:31.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:31.516+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:13:31.509+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:13:31.517+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:13:31.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T11:14:02.151+0000] {processor.py:157} INFO - Started process (PID=7223) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:02.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:14:02.154+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:14:02.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:02.179+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:14:02.170+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:14:02.181+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:02.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-04T11:14:32.659+0000] {processor.py:157} INFO - Started process (PID=7274) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:32.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:14:32.663+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:14:32.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:32.688+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:14:32.683+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:14:32.689+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:14:32.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-04T11:15:03.259+0000] {processor.py:157} INFO - Started process (PID=7325) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:03.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:15:03.262+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:15:03.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:03.291+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:15:03.286+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:15:03.292+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:03.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.054 seconds
[2024-11-04T11:15:33.689+0000] {processor.py:157} INFO - Started process (PID=7376) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:33.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:15:33.692+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:15:33.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:33.718+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:15:33.712+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:15:33.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:15:33.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.053 seconds
[2024-11-04T11:16:04.253+0000] {processor.py:157} INFO - Started process (PID=7427) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:04.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:16:04.256+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:16:04.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:04.277+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:16:04.272+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:16:04.278+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:04.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:16:34.702+0000] {processor.py:157} INFO - Started process (PID=7478) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:34.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:16:34.705+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:16:34.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:34.736+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:16:34.726+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:16:34.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:16:34.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.066 seconds
[2024-11-04T11:17:05.039+0000] {processor.py:157} INFO - Started process (PID=7529) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:05.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:17:05.042+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:17:05.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:05.063+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:17:05.058+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:17:05.064+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:05.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:17:35.489+0000] {processor.py:157} INFO - Started process (PID=7580) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:35.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:17:35.494+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:17:35.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:35.541+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:17:35.532+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:17:35.542+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:17:35.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.077 seconds
[2024-11-04T11:18:05.964+0000] {processor.py:157} INFO - Started process (PID=7631) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:05.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:18:05.967+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:18:05.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:05.990+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:18:05.985+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:18:05.991+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:06.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:18:36.292+0000] {processor.py:157} INFO - Started process (PID=7682) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:36.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:18:36.295+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:18:36.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:36.315+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:18:36.311+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:18:36.317+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:18:36.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-04T11:19:06.780+0000] {processor.py:157} INFO - Started process (PID=7736) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:06.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:19:06.783+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:19:06.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:06.814+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:19:06.809+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:19:06.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:06.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.055 seconds
[2024-11-04T11:19:37.509+0000] {processor.py:157} INFO - Started process (PID=7787) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:37.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:19:37.518+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:19:37.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:37.542+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:19:37.536+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:19:37.544+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:19:37.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.060 seconds
[2024-11-04T11:20:07.630+0000] {processor.py:157} INFO - Started process (PID=8072) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:07.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:20:07.634+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:20:07.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:07.662+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:20:07.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:20:07.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:07.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-04T11:20:37.915+0000] {processor.py:157} INFO - Started process (PID=8358) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:37.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:20:37.918+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:20:37.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:37.941+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:20:37.936+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:20:37.942+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:20:37.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:21:08.385+0000] {processor.py:157} INFO - Started process (PID=8412) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:21:08.388+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:21:08.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:08.410+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:21:08.405+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:21:08.411+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:08.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:21:38.610+0000] {processor.py:157} INFO - Started process (PID=8463) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:38.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:21:38.612+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:21:38.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:38.634+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:21:38.629+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:21:38.635+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:21:38.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-04T11:22:08.884+0000] {processor.py:157} INFO - Started process (PID=8514) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:08.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:22:08.886+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:22:08.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:08.908+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:22:08.903+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:22:08.909+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:08.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-04T11:22:38.966+0000] {processor.py:157} INFO - Started process (PID=8559) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:38.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:22:38.970+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:22:38.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:38.993+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:22:38.987+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:22:38.994+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:22:39.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:23:09.429+0000] {processor.py:157} INFO - Started process (PID=8610) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:09.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:23:09.432+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:23:09.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:09.453+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:23:09.448+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:23:09.454+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:09.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:23:39.853+0000] {processor.py:157} INFO - Started process (PID=8661) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:39.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:23:39.856+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:23:39.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:39.878+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:23:39.873+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:23:39.879+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:23:39.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:24:10.481+0000] {processor.py:157} INFO - Started process (PID=8712) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:10.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:24:10.484+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:24:10.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:10.505+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:24:10.500+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:24:10.506+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:10.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:24:41.080+0000] {processor.py:157} INFO - Started process (PID=8763) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:41.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:24:41.083+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:24:41.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:41.104+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:24:41.098+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:24:41.105+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:24:41.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:25:11.722+0000] {processor.py:157} INFO - Started process (PID=8814) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:11.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:25:11.725+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:25:11.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:11.747+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:25:11.741+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:25:11.748+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:11.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:25:42.398+0000] {processor.py:157} INFO - Started process (PID=9040) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:42.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:25:42.402+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:25:42.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:42.436+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:25:42.428+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:25:42.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:25:42.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.103 seconds
[2024-11-04T11:26:12.705+0000] {processor.py:157} INFO - Started process (PID=9308) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:12.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:26:12.718+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:26:12.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:12.747+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:26:12.740+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:26:12.749+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:12.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.088 seconds
[2024-11-04T11:26:42.898+0000] {processor.py:157} INFO - Started process (PID=9444) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:42.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:26:42.900+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:26:42.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:42.922+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:26:42.917+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:26:42.923+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:26:42.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-04T11:27:13.621+0000] {processor.py:157} INFO - Started process (PID=9495) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:13.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:27:13.625+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:27:13.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:13.652+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:27:13.646+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:27:13.653+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:13.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-04T11:27:43.963+0000] {processor.py:157} INFO - Started process (PID=9925) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:43.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:27:43.967+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:27:43.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:43.995+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:27:43.987+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:27:43.996+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:27:44.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.063 seconds
[2024-11-04T11:28:14.191+0000] {processor.py:157} INFO - Started process (PID=10192) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:14.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:28:14.194+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:28:14.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:14.228+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:28:14.221+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:28:14.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:14.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.070 seconds
[2024-11-04T11:28:44.337+0000] {processor.py:157} INFO - Started process (PID=10285) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:44.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:28:44.344+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:28:44.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:44.368+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:28:44.362+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:28:44.369+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:28:44.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-04T11:29:14.529+0000] {processor.py:157} INFO - Started process (PID=10336) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:14.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:29:14.532+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:29:14.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:14.555+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:29:14.550+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:29:14.556+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:14.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-04T11:29:44.853+0000] {processor.py:157} INFO - Started process (PID=10390) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:44.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:29:44.856+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:29:44.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:44.877+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:29:44.872+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:29:44.879+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:29:44.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:30:15.373+0000] {processor.py:157} INFO - Started process (PID=10441) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:15.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:30:15.375+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:30:15.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:15.397+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:30:15.392+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:30:15.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:15.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:30:45.820+0000] {processor.py:157} INFO - Started process (PID=10492) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:45.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:30:45.823+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:30:45.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:45.861+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:30:45.840+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:30:45.862+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:30:45.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.063 seconds
[2024-11-04T11:31:16.679+0000] {processor.py:157} INFO - Started process (PID=10543) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:16.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:31:16.682+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:31:16.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:16.733+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:31:16.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:31:16.735+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:16.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.082 seconds
[2024-11-04T11:31:47.309+0000] {processor.py:157} INFO - Started process (PID=10594) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:47.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:31:47.312+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:31:47.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:47.334+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:31:47.328+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:31:47.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:31:47.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.059 seconds
[2024-11-04T11:32:17.758+0000] {processor.py:157} INFO - Started process (PID=10645) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:17.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:32:17.761+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:32:17.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:17.782+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:32:17.777+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:32:17.784+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:17.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.055 seconds
[2024-11-04T11:32:48.398+0000] {processor.py:157} INFO - Started process (PID=10696) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:48.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:32:48.401+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:32:48.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:48.424+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:32:48.418+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:32:48.425+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:32:48.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:33:19.040+0000] {processor.py:157} INFO - Started process (PID=10747) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:19.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:33:19.043+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:33:19.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:19.064+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:33:19.060+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:33:19.065+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:19.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:33:49.487+0000] {processor.py:157} INFO - Started process (PID=10798) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:49.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:33:49.490+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:33:49.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:49.511+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:33:49.506+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:33:49.512+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:33:49.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:34:20.055+0000] {processor.py:157} INFO - Started process (PID=10849) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:20.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:34:20.058+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:34:20.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:20.080+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:34:20.075+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:34:20.081+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:20.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:34:50.757+0000] {processor.py:157} INFO - Started process (PID=10900) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:50.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:34:50.760+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:34:50.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:50.781+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:34:50.776+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:34:50.782+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:34:50.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:35:21.313+0000] {processor.py:157} INFO - Started process (PID=10951) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:21.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:35:21.315+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:35:21.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:21.337+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:35:21.332+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:35:21.338+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:21.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:35:51.824+0000] {processor.py:157} INFO - Started process (PID=11002) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:51.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:35:51.827+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:35:51.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:51.849+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:35:51.844+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:35:51.851+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:35:51.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:36:22.308+0000] {processor.py:157} INFO - Started process (PID=11053) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:22.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:36:22.311+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:36:22.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:22.336+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:36:22.331+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:36:22.338+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-04T11:36:52.817+0000] {processor.py:157} INFO - Started process (PID=11104) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:52.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:36:52.820+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:36:52.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:52.841+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:36:52.836+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:36:52.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:36:52.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:37:23.463+0000] {processor.py:157} INFO - Started process (PID=11155) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:23.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:37:23.466+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:37:23.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:23.488+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:37:23.482+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:37:23.489+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:23.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-04T11:37:53.984+0000] {processor.py:157} INFO - Started process (PID=11206) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:53.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:37:53.987+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:37:53.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:54.009+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:37:54.004+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:37:54.010+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:37:54.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-04T11:38:24.541+0000] {processor.py:157} INFO - Started process (PID=11257) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:24.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:38:24.544+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:38:24.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:24.564+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:38:24.559+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:38:24.565+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:24.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:38:55.051+0000] {processor.py:157} INFO - Started process (PID=11308) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:55.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:38:55.054+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:38:55.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:55.075+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:38:55.069+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:38:55.076+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:38:55.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:39:25.556+0000] {processor.py:157} INFO - Started process (PID=11359) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:25.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:39:25.559+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:39:25.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:25.581+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:39:25.576+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:39:25.582+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:25.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:39:56.209+0000] {processor.py:157} INFO - Started process (PID=11410) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:56.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:39:56.212+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:39:56.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:56.233+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:39:56.228+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:39:56.234+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:39:56.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-04T11:40:26.804+0000] {processor.py:157} INFO - Started process (PID=11461) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:26.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:40:26.808+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:40:26.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:26.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:40:26.829+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:40:26.847+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:26.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.068 seconds
[2024-11-04T11:40:57.510+0000] {processor.py:157} INFO - Started process (PID=11512) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:57.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:40:57.515+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:40:57.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:57.539+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:40:57.534+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:40:57.541+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:40:57.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-04T11:41:28.234+0000] {processor.py:157} INFO - Started process (PID=11563) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:28.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:41:28.236+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:28.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:28.257+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:28.252+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:41:28.258+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:28.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-04T11:41:35.600+0000] {processor.py:157} INFO - Started process (PID=11585) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:35.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:41:35.603+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:35.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:35.635+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:35.628+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-04T11:41:35.639+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:35.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.071 seconds
[2024-11-04T11:41:41.856+0000] {processor.py:157} INFO - Started process (PID=11605) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:41.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:41:41.859+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:41.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:41.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:42.056+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:42.056+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-04T11:41:42.058+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:42.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:41:42.077+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:42.076+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-03T00:00:00+00:00, run_after=2024-11-04T00:00:00+00:00
[2024-11-04T11:41:42.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.249 seconds
[2024-11-04T11:41:42.998+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:42.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:41:43.001+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:43.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:43.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:41:43.057+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:43.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:41:43.092+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:41:43.092+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:41:43.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.128 seconds
[2024-11-04T11:42:13.972+0000] {processor.py:157} INFO - Started process (PID=11853) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:14.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:42:14.074+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:14.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:14.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:14.217+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:14.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:42:14.259+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:14.258+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:42:14.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.326 seconds
[2024-11-04T11:42:45.303+0000] {processor.py:157} INFO - Started process (PID=12166) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:45.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:42:45.307+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:45.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:45.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:42:45.395+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:45.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:42:45.441+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:42:45.441+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:42:46.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.885 seconds
[2024-11-04T11:43:16.554+0000] {processor.py:157} INFO - Started process (PID=12291) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:16.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:43:16.559+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:16.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:16.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:16.649+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:16.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:43:16.681+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:16.681+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:43:16.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.159 seconds
[2024-11-04T11:43:46.896+0000] {processor.py:157} INFO - Started process (PID=12595) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:46.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:43:46.905+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:46.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:46.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:43:47.047+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:47.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:43:47.112+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:43:47.112+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:43:47.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.306 seconds
[2024-11-04T11:44:17.915+0000] {processor.py:157} INFO - Started process (PID=12922) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:17.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:44:17.919+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:17.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:17.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:18.009+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:18.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:44:18.036+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:18.036+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:44:18.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.152 seconds
[2024-11-04T11:44:48.247+0000] {processor.py:157} INFO - Started process (PID=13255) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:48.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:44:48.253+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:48.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:48.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:44:48.373+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:48.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:44:48.414+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:44:48.414+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:44:48.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.205 seconds
[2024-11-04T11:45:18.549+0000] {processor.py:157} INFO - Started process (PID=13422) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:18.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:45:18.555+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:18.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:18.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:18.639+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:18.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:45:18.670+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:18.670+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:45:18.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.148 seconds
[2024-11-04T11:45:49.711+0000] {processor.py:157} INFO - Started process (PID=13473) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:49.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:45:49.714+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:49.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:49.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:45:49.776+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:49.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:45:49.797+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:45:49.797+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:45:49.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T11:46:20.149+0000] {processor.py:157} INFO - Started process (PID=13524) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:20.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:46:20.152+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:20.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:20.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:20.216+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:20.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:46:20.236+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:20.236+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:46:20.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T11:46:50.413+0000] {processor.py:157} INFO - Started process (PID=13575) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:50.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:46:50.416+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:50.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:50.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:46:50.480+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:50.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:46:50.503+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:46:50.503+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:46:50.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T11:47:20.789+0000] {processor.py:157} INFO - Started process (PID=13626) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:20.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:47:20.793+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:20.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:20.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:20.854+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:20.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:47:20.873+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:20.873+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:47:20.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T11:47:51.140+0000] {processor.py:157} INFO - Started process (PID=13677) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:51.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:47:51.143+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:51.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:51.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:47:51.207+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:51.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:47:51.230+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:47:51.229+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:47:51.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T11:48:21.489+0000] {processor.py:157} INFO - Started process (PID=13728) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:21.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:48:21.492+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:21.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:21.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:21.553+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:21.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:48:21.575+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:21.575+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:48:21.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T11:48:51.891+0000] {processor.py:157} INFO - Started process (PID=13779) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:51.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:48:51.894+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:51.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:51.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:48:51.956+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:51.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:48:51.976+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:48:51.976+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:48:51.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T11:49:22.303+0000] {processor.py:157} INFO - Started process (PID=13830) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:22.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:49:22.306+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:22.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:22.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:22.367+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:22.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:49:22.389+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:22.388+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:49:22.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T11:49:52.773+0000] {processor.py:157} INFO - Started process (PID=13881) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:52.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:49:52.777+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:52.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:52.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:49:52.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:52.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:49:52.866+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:49:52.866+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:49:52.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T11:50:23.164+0000] {processor.py:157} INFO - Started process (PID=13932) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:23.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:50:23.167+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:23.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:23.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:23.238+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:23.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:50:23.259+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:23.259+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:50:23.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T11:50:53.584+0000] {processor.py:157} INFO - Started process (PID=13983) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:53.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:50:53.588+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:53.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:53.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:50:53.658+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:53.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:50:53.677+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:50:53.676+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:50:53.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-04T11:51:24.388+0000] {processor.py:157} INFO - Started process (PID=14028) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:24.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:51:24.392+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:24.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:24.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:24.454+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:24.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:51:24.477+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:24.477+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:51:24.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T11:51:54.851+0000] {processor.py:157} INFO - Started process (PID=14079) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:54.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:51:54.855+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:54.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:54.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:51:54.926+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:54.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:51:54.949+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:51:54.949+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:51:54.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.119 seconds
[2024-11-04T11:52:25.322+0000] {processor.py:157} INFO - Started process (PID=14130) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:25.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:52:25.325+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:25.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:25.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:25.410+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:25.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:52:25.435+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:25.435+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:52:25.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.137 seconds
[2024-11-04T11:52:55.745+0000] {processor.py:157} INFO - Started process (PID=14181) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:55.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:52:55.748+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:55.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:55.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:52:55.822+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:55.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:52:55.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:52:55.845+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:52:55.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T11:53:26.136+0000] {processor.py:157} INFO - Started process (PID=14232) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:26.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:53:26.139+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:26.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:26.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:26.208+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:26.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:53:26.230+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:26.229+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:53:26.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T11:53:56.532+0000] {processor.py:157} INFO - Started process (PID=14283) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:56.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:53:56.535+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:56.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:56.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:53:56.596+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:56.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:53:56.617+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:53:56.617+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:53:56.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T11:54:26.914+0000] {processor.py:157} INFO - Started process (PID=14334) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:26.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:54:26.918+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:26.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:26.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:26.978+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:26.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:54:26.999+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:26.999+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:54:27.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T11:54:57.500+0000] {processor.py:157} INFO - Started process (PID=14385) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:57.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:54:57.504+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:57.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:57.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:54:57.575+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:57.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:54:57.604+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:54:57.603+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:54:57.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T11:55:27.949+0000] {processor.py:157} INFO - Started process (PID=14436) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:27.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:55:27.953+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:27.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:27.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:28.016+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:28.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:55:28.036+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:28.036+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:55:28.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T11:55:58.383+0000] {processor.py:157} INFO - Started process (PID=14487) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:58.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:55:58.386+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:58.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:58.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:55:58.450+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:58.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:55:58.474+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:55:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:55:58.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T11:56:28.859+0000] {processor.py:157} INFO - Started process (PID=14538) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:28.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:56:28.862+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:28.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:28.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:28.923+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:28.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:56:28.945+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:28.945+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:56:28.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T11:56:59.452+0000] {processor.py:157} INFO - Started process (PID=14589) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:59.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:56:59.456+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:59.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:59.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:56:59.550+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:59.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:56:59.582+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:56:59.581+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:56:59.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.157 seconds
[2024-11-04T11:57:29.912+0000] {processor.py:157} INFO - Started process (PID=14640) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:57:29.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:57:29.915+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:57:29.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:57:29.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:57:29.978+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:57:29.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:57:29.998+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:57:29.998+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:57:30.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T11:58:00.328+0000] {processor.py:157} INFO - Started process (PID=14691) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:00.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:58:00.332+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:00.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:00.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:00.405+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:00.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:58:00.428+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:00.428+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:58:00.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T11:58:30.713+0000] {processor.py:157} INFO - Started process (PID=14742) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:30.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:58:30.717+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:30.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:30.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:58:30.780+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:30.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:58:30.804+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:58:30.804+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:58:30.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T11:59:01.226+0000] {processor.py:157} INFO - Started process (PID=14793) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:01.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:59:01.230+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:01.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:01.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:01.292+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:01.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:59:01.313+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:01.313+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:59:01.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T11:59:31.757+0000] {processor.py:157} INFO - Started process (PID=14844) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:31.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T11:59:31.761+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:31.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:31.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T11:59:31.821+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:31.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T11:59:31.842+0000] {logging_mixin.py:151} INFO - [2024-11-04T11:59:31.842+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T11:59:31.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:00:02.207+0000] {processor.py:157} INFO - Started process (PID=14895) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:02.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:00:02.211+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:02.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:02.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:02.274+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:02.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:00:02.295+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:02.295+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:00:02.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:00:32.579+0000] {processor.py:157} INFO - Started process (PID=14946) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:32.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:00:32.583+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:32.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:32.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:00:32.645+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:32.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:00:32.666+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:00:32.666+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:00:32.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:01:02.841+0000] {processor.py:157} INFO - Started process (PID=14997) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:02.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:01:02.844+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:02.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:02.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:02.905+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:02.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:01:02.925+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:02.925+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:01:02.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:01:33.127+0000] {processor.py:157} INFO - Started process (PID=15048) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:33.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:01:33.131+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:33.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:33.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:01:33.192+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:33.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:01:33.214+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:01:33.214+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:01:33.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:02:03.519+0000] {processor.py:157} INFO - Started process (PID=15099) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:03.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:02:03.523+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:03.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:03.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:03.586+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:03.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:02:03.606+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:03.606+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:02:03.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:02:33.879+0000] {processor.py:157} INFO - Started process (PID=15150) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:33.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:02:33.882+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:33.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:33.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:02:33.945+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:33.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:02:33.965+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:02:33.965+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:02:33.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:03:04.150+0000] {processor.py:157} INFO - Started process (PID=15201) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:04.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:03:04.154+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:04.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:04.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:04.216+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:04.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:03:04.236+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:04.236+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:03:04.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:03:34.496+0000] {processor.py:157} INFO - Started process (PID=15252) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:34.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:03:34.500+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:34.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:34.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:03:34.562+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:34.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:03:34.584+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:03:34.583+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:03:34.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:04:04.906+0000] {processor.py:157} INFO - Started process (PID=15303) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:04.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:04:04.909+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:04.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:04.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:04.972+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:04.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:04:04.992+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:04.992+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:04:05.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:04:35.274+0000] {processor.py:157} INFO - Started process (PID=15354) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:35.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:04:35.277+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:35.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:35.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:04:35.336+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:35.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:04:35.357+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:04:35.356+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:04:35.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.104 seconds
[2024-11-04T12:05:05.678+0000] {processor.py:157} INFO - Started process (PID=15405) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:05.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:05:05.681+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:05.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:05.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:05.743+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:05.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:05:05.763+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:05.763+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:05:05.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:05:36.037+0000] {processor.py:157} INFO - Started process (PID=15456) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:36.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:05:36.041+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:36.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:36.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:05:36.107+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:36.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:05:36.132+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:05:36.132+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:05:36.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T12:06:06.420+0000] {processor.py:157} INFO - Started process (PID=15507) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:06.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:06:06.423+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:06.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:06.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:06.486+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:06.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:06:06.507+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:06.507+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:06:06.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:06:36.810+0000] {processor.py:157} INFO - Started process (PID=15558) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:36.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:06:36.814+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:36.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:36.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:06:36.882+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:36.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:06:36.903+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:06:36.903+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:06:36.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T12:07:07.113+0000] {processor.py:157} INFO - Started process (PID=15609) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:07.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:07:07.116+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:07.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:07.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:07.179+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:07.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:07:07.200+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:07.200+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:07:07.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:07:37.812+0000] {processor.py:157} INFO - Started process (PID=15654) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:37.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:07:37.815+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:37.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:37.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:07:37.883+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:37.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:07:37.906+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:07:37.906+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:07:37.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T12:08:08.329+0000] {processor.py:157} INFO - Started process (PID=15705) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:08.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:08:08.332+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:08.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:08.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:08.394+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:08.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:08:08.414+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:08.414+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:08:08.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:08:38.702+0000] {processor.py:157} INFO - Started process (PID=15756) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:38.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:08:38.705+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:38.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:38.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:08:38.786+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:38.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:08:38.809+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:08:38.809+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:08:38.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.130 seconds
[2024-11-04T12:09:09.101+0000] {processor.py:157} INFO - Started process (PID=15807) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:09.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:09:09.105+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:09.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:09.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:09.180+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:09.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:09:09.201+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:09.201+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:09:09.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T12:09:39.630+0000] {processor.py:157} INFO - Started process (PID=15858) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:39.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:09:39.633+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:39.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:39.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:09:39.696+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:39.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:09:39.715+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:09:39.715+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:09:39.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:10:09.961+0000] {processor.py:157} INFO - Started process (PID=15909) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:09.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:10:09.964+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:09.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:09.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:10.027+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:10.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:10:10.056+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:10.056+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:10:10.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T12:10:40.350+0000] {processor.py:157} INFO - Started process (PID=15960) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:40.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:10:40.354+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:40.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:40.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:10:40.414+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:40.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:10:40.436+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:10:40.436+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:10:40.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:11:10.735+0000] {processor.py:157} INFO - Started process (PID=16011) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:10.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:11:10.738+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:10.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:10.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:10.809+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:10.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:11:10.831+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:10.831+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:11:10.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T12:11:41.175+0000] {processor.py:157} INFO - Started process (PID=16062) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:41.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:11:41.178+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:41.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:41.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:11:41.239+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:41.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:11:41.259+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:11:41.259+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:11:41.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T12:12:11.591+0000] {processor.py:157} INFO - Started process (PID=16113) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:11.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:12:11.594+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:11.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:11.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:11.668+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:11.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:12:11.689+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:11.689+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:12:11.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T12:12:41.999+0000] {processor.py:157} INFO - Started process (PID=16164) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:42.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:12:42.002+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:42.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:42.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:12:42.073+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:42.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:12:42.093+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:12:42.093+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:12:42.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T12:13:12.456+0000] {processor.py:157} INFO - Started process (PID=16215) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:12.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:13:12.459+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:12.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:12.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:12.521+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:12.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:13:12.542+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:12.542+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:13:12.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:13:42.855+0000] {processor.py:157} INFO - Started process (PID=16266) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:42.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:13:42.859+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:42.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:42.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:13:42.921+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:42.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:13:42.941+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:13:42.941+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:13:42.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:14:13.214+0000] {processor.py:157} INFO - Started process (PID=16317) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:13.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:14:13.217+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:13.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:13.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:13.280+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:13.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:14:13.301+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:13.301+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:14:13.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:14:43.750+0000] {processor.py:157} INFO - Started process (PID=16368) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:43.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:14:43.753+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:43.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:43.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:14:43.813+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:43.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:14:43.833+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:14:43.833+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:14:43.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:15:14.117+0000] {processor.py:157} INFO - Started process (PID=16419) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:14.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:15:14.120+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:14.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:14.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:14.182+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:14.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:15:14.203+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:14.203+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:15:14.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:15:44.514+0000] {processor.py:157} INFO - Started process (PID=16470) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:44.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:15:44.517+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:44.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:44.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:15:44.577+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:44.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:15:44.598+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:15:44.597+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:15:44.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:16:15.013+0000] {processor.py:157} INFO - Started process (PID=16521) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:15.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:16:15.017+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:15.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:15.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:15.081+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:15.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:16:15.103+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:15.103+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:16:15.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:16:45.315+0000] {processor.py:157} INFO - Started process (PID=16572) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:45.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:16:45.318+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:45.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:45.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:16:45.379+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:45.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:16:45.400+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:16:45.400+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:16:45.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:17:15.734+0000] {processor.py:157} INFO - Started process (PID=16623) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:15.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:17:15.738+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:15.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:15.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:15.797+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:15.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:17:15.817+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:15.817+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:17:15.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:17:46.016+0000] {processor.py:157} INFO - Started process (PID=16674) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:46.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:17:46.019+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:46.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:46.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:17:46.081+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:46.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:17:46.101+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:17:46.101+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:17:46.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:18:16.442+0000] {processor.py:157} INFO - Started process (PID=16725) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:16.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:18:16.446+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:16.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:16.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:16.520+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:16.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:18:16.544+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:16.544+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:18:16.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.129 seconds
[2024-11-04T12:18:46.753+0000] {processor.py:157} INFO - Started process (PID=16776) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:46.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:18:46.757+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:46.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:46.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:18:46.822+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:46.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:18:46.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:18:46.844+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:18:46.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:19:17.172+0000] {processor.py:157} INFO - Started process (PID=16827) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:17.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:19:17.176+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:17.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:17.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:17.237+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:17.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:19:17.259+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:17.259+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:19:17.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:19:47.658+0000] {processor.py:157} INFO - Started process (PID=16878) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:47.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:19:47.662+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:47.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:47.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:19:47.726+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:47.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:19:47.747+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:19:47.747+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:19:47.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:20:17.961+0000] {processor.py:157} INFO - Started process (PID=16929) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:17.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:20:17.964+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:17.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:18.027+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:18.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:20:18.049+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:18.049+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:20:18.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T12:20:48.355+0000] {processor.py:157} INFO - Started process (PID=16980) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:48.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:20:48.359+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:48.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:48.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:20:48.421+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:48.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:20:48.441+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:20:48.441+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:20:48.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:21:18.757+0000] {processor.py:157} INFO - Started process (PID=17031) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:18.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:21:18.760+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:18.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:18.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:18.822+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:18.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:21:18.844+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:18.844+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:21:18.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:21:49.209+0000] {processor.py:157} INFO - Started process (PID=17082) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:49.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:21:49.212+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:49.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:49.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:21:49.285+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:49.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:21:49.308+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:21:49.308+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:21:49.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.123 seconds
[2024-11-04T12:22:19.558+0000] {processor.py:157} INFO - Started process (PID=17133) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:19.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:22:19.562+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:19.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:19.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:19.623+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:19.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:22:19.643+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:19.643+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:22:19.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-04T12:22:49.950+0000] {processor.py:157} INFO - Started process (PID=17184) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:49.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:22:49.953+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:49.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:49.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:22:50.017+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:50.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:22:50.038+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:22:50.038+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:22:50.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:23:20.753+0000] {processor.py:157} INFO - Started process (PID=17229) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:20.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:23:20.756+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:20.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:20.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:20.819+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:20.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:23:20.841+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:20.841+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:23:20.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:23:51.177+0000] {processor.py:157} INFO - Started process (PID=17280) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:51.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:23:51.181+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:51.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:51.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:23:51.241+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:51.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:23:51.262+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:23:51.262+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:23:51.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:24:21.577+0000] {processor.py:157} INFO - Started process (PID=17331) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:21.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:24:21.580+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:21.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:21.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:21.643+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:21.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:24:21.665+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:21.665+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:24:21.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:24:52.439+0000] {processor.py:157} INFO - Started process (PID=17382) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:52.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:24:52.442+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:52.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:52.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:24:52.503+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:52.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:24:52.523+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:24:52.523+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:24:52.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:25:22.796+0000] {processor.py:157} INFO - Started process (PID=17433) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:22.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:25:22.800+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:22.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:22.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:22.860+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:22.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:25:22.882+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:22.882+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:25:22.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:25:53.164+0000] {processor.py:157} INFO - Started process (PID=17484) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:53.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:25:53.167+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:53.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:53.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:25:53.231+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:53.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:25:53.252+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:25:53.252+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:25:53.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:26:23.522+0000] {processor.py:157} INFO - Started process (PID=17535) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:23.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:26:23.526+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:23.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:23.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:23.586+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:23.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:26:23.606+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:23.606+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:26:23.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.104 seconds
[2024-11-04T12:26:53.871+0000] {processor.py:157} INFO - Started process (PID=17586) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:53.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:26:53.874+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:53.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:53.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:26:53.936+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:53.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:26:53.957+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:26:53.957+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:26:53.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:27:24.223+0000] {processor.py:157} INFO - Started process (PID=17637) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:24.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:27:24.226+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:24.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:24.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:24.287+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:24.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:27:24.308+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:24.308+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:27:24.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:27:54.596+0000] {processor.py:157} INFO - Started process (PID=17688) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:54.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:27:54.599+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:54.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:54.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:27:54.661+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:54.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:27:54.682+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:27:54.682+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:27:54.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:28:24.954+0000] {processor.py:157} INFO - Started process (PID=17739) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:24.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:28:24.957+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:24.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:24.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:25.018+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:25.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:28:25.038+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:25.038+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:28:25.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.104 seconds
[2024-11-04T12:28:55.223+0000] {processor.py:157} INFO - Started process (PID=17790) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:55.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:28:55.226+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:55.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:55.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:28:55.286+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:55.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:28:55.307+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:28:55.307+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:28:55.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:29:25.614+0000] {processor.py:157} INFO - Started process (PID=17841) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:25.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:29:25.618+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:25.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:25.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:25.681+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:25.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:29:25.703+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:25.703+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:29:25.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:29:56.110+0000] {processor.py:157} INFO - Started process (PID=17892) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:56.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:29:56.113+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:56.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:56.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:29:56.175+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:56.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:29:56.196+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:29:56.196+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:29:56.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:30:26.489+0000] {processor.py:157} INFO - Started process (PID=17943) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:26.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:30:26.492+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:26.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:26.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:26.555+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:26.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:30:26.575+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:26.575+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:30:26.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:30:56.837+0000] {processor.py:157} INFO - Started process (PID=17994) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:56.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:30:56.841+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:56.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:56.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:30:56.904+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:56.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:30:56.926+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:30:56.925+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:30:56.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:31:27.169+0000] {processor.py:157} INFO - Started process (PID=18045) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:27.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:31:27.172+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:27.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:27.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:27.241+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:27.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:31:27.264+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:27.264+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:31:27.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.119 seconds
[2024-11-04T12:31:57.537+0000] {processor.py:157} INFO - Started process (PID=18096) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:57.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:31:57.541+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:57.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:57.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:31:57.605+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:57.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:31:57.627+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:31:57.627+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:31:57.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:32:27.790+0000] {processor.py:157} INFO - Started process (PID=18147) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:27.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:32:27.793+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:27.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:27.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:27.853+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:27.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:32:27.875+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:27.875+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:32:27.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:32:58.154+0000] {processor.py:157} INFO - Started process (PID=18198) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:58.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:32:58.157+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:58.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:58.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:32:58.220+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:58.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:32:58.240+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:32:58.240+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:32:58.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:33:28.530+0000] {processor.py:157} INFO - Started process (PID=18249) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:28.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:33:28.534+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:28.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:28.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:28.594+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:28.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:33:28.615+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:28.614+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:33:28.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:33:58.800+0000] {processor.py:157} INFO - Started process (PID=18300) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:58.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:33:58.804+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:58.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:58.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:33:58.864+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:58.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:33:58.884+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:33:58.884+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:33:58.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:34:29.032+0000] {processor.py:157} INFO - Started process (PID=18351) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:29.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:34:29.035+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:29.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:29.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:29.096+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:29.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:34:29.116+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:29.116+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:34:29.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:34:59.480+0000] {processor.py:157} INFO - Started process (PID=18402) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:59.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:34:59.484+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:59.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:59.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:34:59.545+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:59.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:34:59.565+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:34:59.564+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:34:59.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:35:29.828+0000] {processor.py:157} INFO - Started process (PID=18453) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:35:29.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:35:29.832+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:35:29.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:35:29.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:35:29.902+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:35:29.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:35:29.925+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:35:29.925+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:35:29.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.122 seconds
[2024-11-04T12:36:00.233+0000] {processor.py:157} INFO - Started process (PID=18504) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:00.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:36:00.236+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:00.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:00.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:00.298+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:00.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:36:00.320+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:00.320+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:36:00.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:36:30.603+0000] {processor.py:157} INFO - Started process (PID=18555) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:30.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:36:30.607+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:30.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:30.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:36:30.667+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:30.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:36:30.688+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:36:30.688+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:36:30.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:37:01.036+0000] {processor.py:157} INFO - Started process (PID=18606) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:01.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:37:01.039+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:01.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:01.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:01.098+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:01.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:37:01.119+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:01.119+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:37:01.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:37:31.381+0000] {processor.py:157} INFO - Started process (PID=18657) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:31.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:37:31.384+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:31.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:31.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:37:31.445+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:31.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:37:31.465+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:37:31.465+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:37:31.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:38:01.738+0000] {processor.py:157} INFO - Started process (PID=18708) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:01.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:38:01.742+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:01.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:01.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:01.801+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:01.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:38:01.823+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:01.823+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:38:01.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:38:32.076+0000] {processor.py:157} INFO - Started process (PID=18759) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:32.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:38:32.079+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:32.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:32.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:38:32.140+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:32.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:38:32.161+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:38:32.160+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:38:32.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:39:02.847+0000] {processor.py:157} INFO - Started process (PID=18804) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:02.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:39:02.851+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:02.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:02.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:02.911+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:02.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:39:02.932+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:02.931+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:39:02.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:39:33.230+0000] {processor.py:157} INFO - Started process (PID=18855) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:33.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:39:33.233+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:33.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:33.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:39:33.295+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:33.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:39:33.316+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:39:33.316+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:39:33.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:40:03.578+0000] {processor.py:157} INFO - Started process (PID=18906) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:03.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:40:03.581+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:03.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:03.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:03.643+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:03.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:40:03.664+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:03.664+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:40:03.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:40:33.922+0000] {processor.py:157} INFO - Started process (PID=18957) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:33.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:40:33.926+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:33.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:33.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:40:33.988+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:33.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:40:34.008+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:40:34.008+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:40:34.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:41:04.278+0000] {processor.py:157} INFO - Started process (PID=19008) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:04.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:41:04.281+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:04.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:04.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:04.343+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:04.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:41:04.363+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:04.363+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:41:04.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:41:34.604+0000] {processor.py:157} INFO - Started process (PID=19059) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:34.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:41:34.607+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:34.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:34.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:41:34.668+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:34.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:41:34.688+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:41:34.688+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:41:34.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.104 seconds
[2024-11-04T12:42:04.934+0000] {processor.py:157} INFO - Started process (PID=19110) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:04.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:42:04.937+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:04.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:04.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:05.000+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:05.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:42:05.022+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:05.022+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:42:05.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:42:35.259+0000] {processor.py:157} INFO - Started process (PID=19161) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:35.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:42:35.262+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:35.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:35.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:42:35.325+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:35.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:42:35.345+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:42:35.345+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:42:35.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:43:05.604+0000] {processor.py:157} INFO - Started process (PID=19212) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:05.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:43:05.607+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:05.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:05.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:05.667+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:05.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:43:05.687+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:05.687+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:43:05.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:43:35.929+0000] {processor.py:157} INFO - Started process (PID=19263) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:35.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:43:35.933+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:35.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:35.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:43:35.993+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:35.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:43:36.014+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:43:36.014+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:43:36.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:44:06.285+0000] {processor.py:157} INFO - Started process (PID=19314) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:06.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:44:06.288+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:06.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:06.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:06.351+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:06.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:44:06.373+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:06.372+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:44:06.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:44:36.643+0000] {processor.py:157} INFO - Started process (PID=19365) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:36.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:44:36.647+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:36.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:36.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:44:36.710+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:36.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:44:36.730+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:44:36.729+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:44:36.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T12:45:07.106+0000] {processor.py:157} INFO - Started process (PID=19416) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:07.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:45:07.110+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:07.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:07.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:07.170+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:07.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:45:07.191+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:07.191+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:45:07.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:45:37.474+0000] {processor.py:157} INFO - Started process (PID=19467) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:37.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:45:37.477+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:37.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:37.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:45:37.538+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:37.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:45:37.559+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:45:37.559+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:45:37.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:46:07.805+0000] {processor.py:157} INFO - Started process (PID=19518) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:07.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:46:07.809+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:07.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:07.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:07.889+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:07.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:46:07.912+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:07.912+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:46:07.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.131 seconds
[2024-11-04T12:46:38.089+0000] {processor.py:157} INFO - Started process (PID=19569) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:38.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:46:38.093+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:38.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:38.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:46:38.158+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:38.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:46:38.177+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:46:38.177+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:46:38.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:47:08.407+0000] {processor.py:157} INFO - Started process (PID=19620) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:08.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:47:08.411+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:08.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:08.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:08.472+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:08.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:47:08.492+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:08.492+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:47:08.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:47:38.779+0000] {processor.py:157} INFO - Started process (PID=19671) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:38.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:47:38.782+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:38.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:38.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:47:38.844+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:38.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:47:38.864+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:47:38.864+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:47:38.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:48:09.035+0000] {processor.py:157} INFO - Started process (PID=19722) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:09.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:48:09.038+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:09.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:09.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:09.097+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:09.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:48:09.118+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:09.118+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:48:09.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:48:39.465+0000] {processor.py:157} INFO - Started process (PID=19773) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:39.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:48:39.469+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:39.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:39.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:48:39.534+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:39.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:48:39.557+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:48:39.556+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:48:39.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T12:49:09.723+0000] {processor.py:157} INFO - Started process (PID=19824) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:09.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:49:09.727+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:09.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:09.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:09.790+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:09.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:49:09.811+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:09.811+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:49:09.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:49:40.121+0000] {processor.py:157} INFO - Started process (PID=19875) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:40.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:49:40.124+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:40.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:40.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:49:40.185+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:40.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:49:40.206+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:49:40.206+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:49:40.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:50:10.380+0000] {processor.py:157} INFO - Started process (PID=19926) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:10.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:50:10.384+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:10.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:10.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:10.444+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:10.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:50:10.465+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:10.464+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:50:10.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:50:40.769+0000] {processor.py:157} INFO - Started process (PID=19977) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:40.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:50:40.773+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:40.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:40.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:50:40.839+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:40.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:50:40.859+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:50:40.858+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:50:40.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:51:11.148+0000] {processor.py:157} INFO - Started process (PID=20028) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:11.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:51:11.151+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:11.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:11.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:11.214+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:11.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:51:11.233+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:11.233+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:51:11.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:51:41.492+0000] {processor.py:157} INFO - Started process (PID=20079) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:41.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:51:41.495+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:41.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:41.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:51:41.556+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:41.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:51:41.576+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:51:41.576+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:51:41.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:52:11.849+0000] {processor.py:157} INFO - Started process (PID=20130) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:11.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:52:11.852+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:11.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:11.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:11.915+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:11.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:52:11.936+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:11.936+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:52:11.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T12:52:42.206+0000] {processor.py:157} INFO - Started process (PID=20181) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:42.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:52:42.209+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:42.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:42.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:52:42.271+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:42.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:52:42.292+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:52:42.292+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:52:42.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:53:12.572+0000] {processor.py:157} INFO - Started process (PID=20232) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:12.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:53:12.576+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:12.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:12.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:12.639+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:12.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:53:12.661+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:12.661+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:53:12.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T12:53:42.942+0000] {processor.py:157} INFO - Started process (PID=20283) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:42.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:53:42.945+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:42.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:42.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:53:43.006+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:43.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:53:43.027+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:53:43.026+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:53:43.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:54:13.297+0000] {processor.py:157} INFO - Started process (PID=20334) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:13.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:54:13.300+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:13.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:13.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:13.363+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:13.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:54:13.382+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:13.381+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:54:13.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:54:44.192+0000] {processor.py:157} INFO - Started process (PID=20379) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:44.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:54:44.196+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:44.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:44.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:54:44.258+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:44.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:54:44.278+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:54:44.277+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:54:44.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:55:14.569+0000] {processor.py:157} INFO - Started process (PID=20430) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:14.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:55:14.573+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:14.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:14.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:14.634+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:14.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:55:14.655+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:14.655+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:55:14.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:55:44.904+0000] {processor.py:157} INFO - Started process (PID=20481) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:44.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:55:44.908+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:44.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:44.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:55:44.968+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:44.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:55:44.987+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:55:44.987+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:55:45.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.105 seconds
[2024-11-04T12:56:15.224+0000] {processor.py:157} INFO - Started process (PID=20532) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:15.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:56:15.228+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:15.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:15.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:15.288+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:15.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:56:15.310+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:15.310+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:56:15.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:56:45.593+0000] {processor.py:157} INFO - Started process (PID=20583) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:45.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:56:45.596+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:45.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:45.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:56:45.656+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:45.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:56:45.676+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:56:45.676+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:56:45.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.103 seconds
[2024-11-04T12:57:15.934+0000] {processor.py:157} INFO - Started process (PID=20634) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:15.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:57:15.938+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:15.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:15.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:15.999+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:15.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:57:16.022+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:16.022+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:57:16.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T12:57:46.261+0000] {processor.py:157} INFO - Started process (PID=20685) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:46.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:57:46.265+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:46.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:46.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:57:46.327+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:46.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:57:46.347+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:57:46.347+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:57:46.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T12:58:16.544+0000] {processor.py:157} INFO - Started process (PID=20736) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:16.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:58:16.548+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:16.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:16.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:16.609+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:16.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:58:16.630+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:16.630+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:58:16.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-04T12:58:46.991+0000] {processor.py:157} INFO - Started process (PID=20787) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:46.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:58:46.995+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:46.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:47.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:58:47.064+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:47.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:58:47.086+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:58:47.086+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:58:47.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T12:59:17.393+0000] {processor.py:157} INFO - Started process (PID=20838) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:17.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:59:17.396+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:17.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:17.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:17.461+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:17.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:59:17.484+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:17.484+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:59:17.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T12:59:47.965+0000] {processor.py:157} INFO - Started process (PID=20889) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:47.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T12:59:47.969+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:47.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:47.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T12:59:48.031+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:48.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T12:59:48.051+0000] {logging_mixin.py:151} INFO - [2024-11-04T12:59:48.051+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T12:59:48.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-04T13:00:18.381+0000] {processor.py:157} INFO - Started process (PID=20940) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:18.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:00:18.385+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:18.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:18.446+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:18.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:00:18.468+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:18.468+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:00:18.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T13:00:48.880+0000] {processor.py:157} INFO - Started process (PID=20991) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:48.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:00:48.883+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:48.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:48.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:00:48.954+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:48.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:00:48.977+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:00:48.977+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:00:48.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:01:19.417+0000] {processor.py:157} INFO - Started process (PID=21042) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:19.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:01:19.421+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:19.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:19.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:19.483+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:19.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:01:19.505+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:19.505+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:01:19.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:01:50.158+0000] {processor.py:157} INFO - Started process (PID=21093) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:50.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:01:50.161+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:50.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:50.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:01:50.224+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:50.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:01:50.246+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:01:50.246+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:01:50.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:02:20.632+0000] {processor.py:157} INFO - Started process (PID=21144) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:20.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:02:20.635+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:20.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:20.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:20.701+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:20.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:02:20.728+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:20.728+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:02:20.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T13:02:51.017+0000] {processor.py:157} INFO - Started process (PID=21195) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:51.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:02:51.021+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:51.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:51.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:02:51.084+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:51.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:02:51.104+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:02:51.104+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:02:51.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:03:21.516+0000] {processor.py:157} INFO - Started process (PID=21246) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:21.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:03:21.519+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:21.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:21.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:21.581+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:21.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:03:21.603+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:21.602+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:03:21.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:03:51.918+0000] {processor.py:157} INFO - Started process (PID=21297) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:51.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:03:51.921+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:51.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:51.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:03:51.984+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:51.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:03:52.004+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:03:52.004+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:03:52.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:04:22.324+0000] {processor.py:157} INFO - Started process (PID=21348) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:22.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:04:22.329+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:22.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:22.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:22.393+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:22.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:04:22.415+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:22.415+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:04:22.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T13:04:52.878+0000] {processor.py:157} INFO - Started process (PID=21399) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:52.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:04:52.882+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:52.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:52.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:04:52.948+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:52.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:04:52.973+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:04:52.973+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:04:52.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T13:05:23.844+0000] {processor.py:157} INFO - Started process (PID=21450) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:23.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:05:23.849+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:23.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:23.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:23.944+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:23.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:05:23.976+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:23.976+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:05:24.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.170 seconds
[2024-11-04T13:05:54.141+0000] {processor.py:157} INFO - Started process (PID=21501) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:54.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:05:54.147+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:54.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:54.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:05:54.247+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:54.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:05:54.294+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:05:54.293+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:05:54.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.196 seconds
[2024-11-04T13:06:24.496+0000] {processor.py:157} INFO - Started process (PID=21552) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:24.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:06:24.502+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:24.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:24.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:24.601+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:24.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:06:24.633+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:24.632+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:06:24.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.173 seconds
[2024-11-04T13:06:54.820+0000] {processor.py:157} INFO - Started process (PID=21603) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:54.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:06:54.826+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:54.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:54.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:06:54.911+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:54.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:06:54.940+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:06:54.940+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:06:54.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.159 seconds
[2024-11-04T13:07:25.101+0000] {processor.py:157} INFO - Started process (PID=21654) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:25.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:07:25.107+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:25.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:25.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:25.179+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:25.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:07:25.201+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:25.201+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:07:25.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:07:55.287+0000] {processor.py:157} INFO - Started process (PID=21705) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:55.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:07:55.292+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:55.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:55.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:07:55.370+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:55.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:07:55.399+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:07:55.399+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:07:55.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.141 seconds
[2024-11-04T13:08:25.788+0000] {processor.py:157} INFO - Started process (PID=21756) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:25.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:08:25.791+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:25.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:25.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:25.856+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:25.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:08:25.878+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:25.878+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:08:25.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:08:56.237+0000] {processor.py:157} INFO - Started process (PID=21807) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:56.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:08:56.241+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:56.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:56.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:08:56.323+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:56.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:08:56.354+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:08:56.354+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:08:56.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.147 seconds
[2024-11-04T13:09:26.568+0000] {processor.py:157} INFO - Started process (PID=21858) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:26.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:09:26.571+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:26.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:26.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:26.636+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:26.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:09:26.658+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:26.658+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:09:26.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-04T13:09:57.033+0000] {processor.py:157} INFO - Started process (PID=21909) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:57.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:09:57.037+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:57.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:57.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:09:57.103+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:57.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:09:57.125+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:09:57.125+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:09:57.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T13:10:27.466+0000] {processor.py:157} INFO - Started process (PID=21960) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:27.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:10:27.469+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:27.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:27.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:27.531+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:27.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:10:27.552+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:27.552+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:10:27.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:10:57.997+0000] {processor.py:157} INFO - Started process (PID=22011) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:57.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:10:58.000+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:58.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:58.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:10:58.064+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:58.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:10:58.086+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:10:58.086+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:10:58.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T13:11:28.874+0000] {processor.py:157} INFO - Started process (PID=22056) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:28.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:11:28.879+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:28.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:28.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:28.960+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:28.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:11:29.006+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:29.005+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:11:29.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.169 seconds
[2024-11-04T13:11:59.567+0000] {processor.py:157} INFO - Started process (PID=22107) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:59.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:11:59.570+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:59.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:59.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:11:59.635+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:59.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:11:59.655+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:11:59.654+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:11:59.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T13:12:30.023+0000] {processor.py:157} INFO - Started process (PID=22158) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:12:30.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:12:30.027+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:12:30.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:12:30.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:12:30.093+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:12:30.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:12:30.116+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:12:30.116+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:12:30.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.119 seconds
[2024-11-04T13:13:00.491+0000] {processor.py:157} INFO - Started process (PID=22209) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:00.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:13:00.495+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:00.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:00.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:00.574+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:00.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:13:00.596+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:00.596+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:13:00.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.129 seconds
[2024-11-04T13:13:30.860+0000] {processor.py:157} INFO - Started process (PID=22260) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:30.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:13:30.863+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:30.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:30.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:13:30.928+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:30.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:13:30.948+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:13:30.948+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:13:30.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:14:01.293+0000] {processor.py:157} INFO - Started process (PID=22311) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:01.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:14:01.296+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:01.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:01.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:01.362+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:01.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:14:01.383+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:01.383+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:14:01.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T13:14:31.721+0000] {processor.py:157} INFO - Started process (PID=22362) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:31.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:14:31.724+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:31.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:31.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:14:31.797+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:31.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:14:31.821+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:14:31.821+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:14:31.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.129 seconds
[2024-11-04T13:15:02.173+0000] {processor.py:157} INFO - Started process (PID=22413) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:02.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:15:02.176+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:02.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:02.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:02.238+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:02.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:15:02.258+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:02.258+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:15:02.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-04T13:15:32.712+0000] {processor.py:157} INFO - Started process (PID=22464) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:32.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:15:32.716+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:32.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:32.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:15:32.790+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:32.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:15:32.814+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:15:32.814+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:15:32.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.128 seconds
[2024-11-04T13:16:03.130+0000] {processor.py:157} INFO - Started process (PID=22515) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:03.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:16:03.134+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:03.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:03.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:03.196+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:03.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:16:03.218+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:03.217+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:16:03.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T13:16:33.530+0000] {processor.py:157} INFO - Started process (PID=22566) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:33.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:16:33.534+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:33.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:33.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:16:33.596+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:33.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:16:33.618+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:16:33.618+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:16:33.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:17:03.898+0000] {processor.py:157} INFO - Started process (PID=22617) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:03.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:17:03.901+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:03.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:03.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:03.966+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:03.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:17:03.989+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:03.989+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:17:04.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:17:34.367+0000] {processor.py:157} INFO - Started process (PID=22668) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:34.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:17:34.370+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:34.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:34.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:17:34.459+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:34.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:17:34.502+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:17:34.502+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:17:34.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.172 seconds
[2024-11-04T13:18:04.975+0000] {processor.py:157} INFO - Started process (PID=22719) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:04.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:18:04.978+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:04.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:05.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:05.043+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:05.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:18:05.063+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:05.063+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:18:05.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:18:35.358+0000] {processor.py:157} INFO - Started process (PID=22770) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:35.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:18:35.361+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:35.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:35.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:18:35.437+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:35.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:18:35.472+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:18:35.471+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:18:35.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.150 seconds
[2024-11-04T13:19:05.947+0000] {processor.py:157} INFO - Started process (PID=22821) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:05.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:19:05.951+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:05.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:05.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:06.017+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:06.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:19:06.041+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:06.041+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:19:06.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.119 seconds
[2024-11-04T13:19:36.362+0000] {processor.py:157} INFO - Started process (PID=22872) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:36.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:19:36.366+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:36.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:36.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:19:36.431+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:36.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:19:36.452+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:19:36.452+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:19:36.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T13:20:06.739+0000] {processor.py:157} INFO - Started process (PID=22923) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:06.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:20:06.743+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:06.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:06.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:06.807+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:06.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:20:06.828+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:06.828+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:20:06.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:20:37.045+0000] {processor.py:157} INFO - Started process (PID=22974) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:37.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:20:37.048+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:37.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:37.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:20:37.113+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:37.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:20:37.137+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:20:37.137+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:20:37.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T13:21:07.597+0000] {processor.py:157} INFO - Started process (PID=23025) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:07.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:21:07.600+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:07.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:07.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:07.663+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:07.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:21:07.685+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:07.685+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:21:07.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:21:38.039+0000] {processor.py:157} INFO - Started process (PID=23076) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:38.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:21:38.042+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:38.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:38.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:21:38.125+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:38.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:21:38.149+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:21:38.149+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:21:38.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.136 seconds
[2024-11-04T13:22:08.510+0000] {processor.py:157} INFO - Started process (PID=23127) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:08.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:22:08.513+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:08.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:08.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:08.577+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:08.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:22:08.597+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:08.597+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:22:08.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T13:22:38.916+0000] {processor.py:157} INFO - Started process (PID=23178) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:38.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:22:38.921+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:38.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:38.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:22:39.014+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:39.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:22:39.056+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:22:39.055+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:22:39.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.178 seconds
[2024-11-04T13:23:09.391+0000] {processor.py:157} INFO - Started process (PID=23229) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:09.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:23:09.397+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:09.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:09.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:09.470+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:09.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:23:09.491+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:09.491+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:23:09.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.126 seconds
[2024-11-04T13:23:39.924+0000] {processor.py:157} INFO - Started process (PID=23280) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:39.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:23:39.929+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:39.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:39.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:23:39.998+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:39.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:23:40.019+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:23:40.019+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:23:40.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T13:24:10.416+0000] {processor.py:157} INFO - Started process (PID=23331) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:10.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:24:10.419+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:10.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:10.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:10.481+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:10.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:24:10.503+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:10.502+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:24:10.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-04T13:24:40.832+0000] {processor.py:157} INFO - Started process (PID=23382) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:40.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:24:40.836+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:40.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:40.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:24:40.902+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:40.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:24:40.923+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:24:40.923+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:24:40.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-04T13:25:11.560+0000] {processor.py:157} INFO - Started process (PID=23433) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:11.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:25:11.563+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:11.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:11.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:11.627+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:11.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:25:11.649+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:11.649+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:25:11.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:25:42.126+0000] {processor.py:157} INFO - Started process (PID=23484) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:42.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:25:42.130+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:42.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:42.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:25:42.232+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:42.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:25:42.290+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:25:42.290+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:25:42.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.199 seconds
[2024-11-04T13:26:12.587+0000] {processor.py:157} INFO - Started process (PID=23535) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:12.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:26:12.590+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:12.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:12.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:12.655+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:12.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:26:12.677+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:12.677+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:26:12.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T13:26:43.159+0000] {processor.py:157} INFO - Started process (PID=23586) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:43.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:26:43.162+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:43.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:43.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:26:43.224+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:43.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:26:43.248+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:26:43.248+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:26:43.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:27:13.617+0000] {processor.py:157} INFO - Started process (PID=23637) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:13.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:27:13.620+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:13.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:13.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:13.686+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:13.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:27:13.710+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:13.709+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:27:13.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:27:44.490+0000] {processor.py:157} INFO - Started process (PID=23682) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:44.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:27:44.493+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:44.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:44.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:27:44.561+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:44.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:27:44.585+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:27:44.585+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:27:44.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T13:28:15.152+0000] {processor.py:157} INFO - Started process (PID=23733) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:15.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:28:15.155+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:15.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:15.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:15.221+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:15.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:28:15.245+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:15.245+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:28:15.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T13:28:45.630+0000] {processor.py:157} INFO - Started process (PID=23784) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:45.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:28:45.633+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:45.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:45.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:28:45.701+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:45.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:28:45.723+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:28:45.723+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:28:45.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.119 seconds
[2024-11-04T13:29:16.193+0000] {processor.py:157} INFO - Started process (PID=23835) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:16.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:29:16.198+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:16.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:16.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:16.270+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:16.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:29:16.292+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:16.291+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:29:16.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:29:46.854+0000] {processor.py:157} INFO - Started process (PID=23886) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:46.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:29:46.857+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:46.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:46.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:29:46.921+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:46.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:29:46.942+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:29:46.942+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:29:46.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:30:17.477+0000] {processor.py:157} INFO - Started process (PID=23937) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:17.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:30:17.480+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:17.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:17.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:17.546+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:17.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:30:17.569+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:17.569+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:30:17.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:30:47.953+0000] {processor.py:157} INFO - Started process (PID=23988) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:47.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:30:47.957+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:47.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:47.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:30:48.019+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:48.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:30:48.048+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:30:48.047+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:30:48.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.125 seconds
[2024-11-04T13:31:18.521+0000] {processor.py:157} INFO - Started process (PID=24039) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:18.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:31:18.524+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:18.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:18.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:18.588+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:18.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:31:18.611+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:18.611+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:31:18.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T13:31:48.979+0000] {processor.py:157} INFO - Started process (PID=24090) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:48.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:31:48.983+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:48.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:49.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:31:49.055+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:49.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:31:49.078+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:31:49.078+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:31:49.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.126 seconds
[2024-11-04T13:32:19.437+0000] {processor.py:157} INFO - Started process (PID=24141) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:19.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:32:19.440+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:19.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:19.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:19.502+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:19.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:32:19.524+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:19.524+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:32:19.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:32:50.137+0000] {processor.py:157} INFO - Started process (PID=24192) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:50.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:32:50.141+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:50.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:50.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:32:50.233+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:50.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:32:50.270+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:32:50.270+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:32:50.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.161 seconds
[2024-11-04T13:33:20.789+0000] {processor.py:157} INFO - Started process (PID=24243) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:20.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:33:20.794+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:20.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:20.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:20.866+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:20.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:33:20.889+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:20.889+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:33:20.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.126 seconds
[2024-11-04T13:33:51.384+0000] {processor.py:157} INFO - Started process (PID=24294) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:51.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:33:51.388+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:51.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:51.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:33:51.461+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:51.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:33:51.486+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:33:51.486+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:33:51.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.131 seconds
[2024-11-04T13:34:21.835+0000] {processor.py:157} INFO - Started process (PID=24345) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:21.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:34:21.839+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:21.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:21.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:21.918+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:21.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:34:21.941+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:21.941+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:34:21.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.131 seconds
[2024-11-04T13:34:52.549+0000] {processor.py:157} INFO - Started process (PID=24396) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:52.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:34:52.553+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:52.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:52.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:34:52.630+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:52.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:34:52.656+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:34:52.656+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:34:52.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.138 seconds
[2024-11-04T13:35:23.128+0000] {processor.py:157} INFO - Started process (PID=24447) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:23.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:35:23.131+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:23.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:23.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:23.197+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:23.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:35:23.220+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:23.220+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:35:23.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T13:35:53.711+0000] {processor.py:157} INFO - Started process (PID=24498) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:53.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:35:53.715+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:53.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:53.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:35:53.786+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:53.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:35:53.808+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:35:53.808+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:35:53.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.124 seconds
[2024-11-04T13:36:24.382+0000] {processor.py:157} INFO - Started process (PID=24549) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:24.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:36:24.386+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:24.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:24.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:24.477+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:24.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:36:24.530+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:24.530+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:36:24.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.191 seconds
[2024-11-04T13:36:55.074+0000] {processor.py:157} INFO - Started process (PID=24600) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:55.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:36:55.077+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:55.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:55.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:36:55.142+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:55.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:36:55.166+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:36:55.166+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:36:55.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T13:37:25.584+0000] {processor.py:157} INFO - Started process (PID=24651) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:25.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:37:25.589+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:25.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:25.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:25.657+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:25.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:37:25.680+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:25.680+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:37:25.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.122 seconds
[2024-11-04T13:37:56.059+0000] {processor.py:157} INFO - Started process (PID=24702) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:56.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:37:56.062+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:56.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:56.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:37:56.129+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:56.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:37:56.153+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:37:56.153+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:37:56.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T13:38:26.509+0000] {processor.py:157} INFO - Started process (PID=24753) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:26.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:38:26.512+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:26.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:26.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:26.582+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:26.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:38:26.607+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:26.606+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:38:26.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:38:56.925+0000] {processor.py:157} INFO - Started process (PID=24804) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:56.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:38:56.928+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:56.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:56.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:38:56.998+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:56.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:38:57.028+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:38:57.028+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:38:57.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:39:27.564+0000] {processor.py:157} INFO - Started process (PID=24855) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:27.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:39:27.569+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:27.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:27.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:27.641+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:27.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:39:27.665+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:27.664+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:39:27.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:39:58.108+0000] {processor.py:157} INFO - Started process (PID=24906) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:58.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:39:58.111+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:58.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:58.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:39:58.183+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:58.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:39:58.206+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:39:58.206+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:39:58.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.125 seconds
[2024-11-04T13:40:28.681+0000] {processor.py:157} INFO - Started process (PID=24957) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:28.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:40:28.686+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:28.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:28.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:28.759+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:28.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:40:28.787+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:28.786+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:40:28.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.129 seconds
[2024-11-04T13:40:58.943+0000] {processor.py:157} INFO - Started process (PID=25008) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:58.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:40:58.948+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:58.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:58.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:40:59.034+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:59.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:40:59.061+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:40:59.061+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:40:59.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.145 seconds
[2024-11-04T13:41:29.192+0000] {processor.py:157} INFO - Started process (PID=25059) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:29.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:41:29.196+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:29.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:29.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:29.264+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:29.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:41:29.289+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:29.288+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:41:29.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.123 seconds
[2024-11-04T13:41:59.384+0000] {processor.py:157} INFO - Started process (PID=25110) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:59.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:41:59.389+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:59.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:59.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:41:59.460+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:59.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:41:59.486+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:41:59.486+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:41:59.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:42:29.590+0000] {processor.py:157} INFO - Started process (PID=25161) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:42:29.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:42:29.593+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:42:29.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:42:29.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:42:29.663+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:42:29.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:42:29.689+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:42:29.689+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:42:29.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.127 seconds
[2024-11-04T13:43:00.222+0000] {processor.py:157} INFO - Started process (PID=25212) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:00.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:43:00.225+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:00.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:00.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:00.291+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:00.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:43:00.313+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:00.313+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:43:00.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T13:43:30.911+0000] {processor.py:157} INFO - Started process (PID=25263) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:30.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:43:30.915+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:30.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:30.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:43:30.983+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:30.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:43:31.007+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:43:31.007+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:43:31.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:44:01.631+0000] {processor.py:157} INFO - Started process (PID=25314) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:01.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:44:01.635+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:01.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:01.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:01.703+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:01.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:44:01.729+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:01.729+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:44:01.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:44:32.376+0000] {processor.py:157} INFO - Started process (PID=25365) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:32.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:44:32.379+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:32.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:32.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:44:32.451+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:32.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:44:32.475+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:44:32.475+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:44:32.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.123 seconds
[2024-11-04T13:45:03.133+0000] {processor.py:157} INFO - Started process (PID=25416) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:03.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:45:03.136+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:03.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:03.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:03.207+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:03.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:45:03.238+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:03.238+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:45:03.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.135 seconds
[2024-11-04T13:45:33.640+0000] {processor.py:157} INFO - Started process (PID=25467) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:33.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:45:33.643+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:33.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:33.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:45:33.706+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:33.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:45:33.727+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:45:33.727+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:45:33.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-04T13:46:04.415+0000] {processor.py:157} INFO - Started process (PID=25518) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:04.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:46:04.419+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:04.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:04.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:04.486+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:04.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:46:04.509+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:04.509+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:46:04.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.118 seconds
[2024-11-04T13:46:34.937+0000] {processor.py:157} INFO - Started process (PID=25569) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:34.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:46:34.941+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:34.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:34.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:46:35.007+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:35.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:46:35.030+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:46:35.029+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:46:35.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-04T13:47:05.360+0000] {processor.py:157} INFO - Started process (PID=25620) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:05.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:47:05.364+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:05.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:05.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:05.436+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:05.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:47:05.461+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:05.461+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:47:05.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.123 seconds
[2024-11-04T13:47:36.283+0000] {processor.py:157} INFO - Started process (PID=25671) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:36.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:47:36.287+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:36.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:36.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:47:36.354+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:36.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:47:36.375+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:47:36.375+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:47:36.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T13:48:06.863+0000] {processor.py:157} INFO - Started process (PID=25722) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:48:06.867+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:06.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:06.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:06.949+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:06.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:48:06.977+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:06.977+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:48:07.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.141 seconds
[2024-11-04T13:48:37.206+0000] {processor.py:157} INFO - Started process (PID=25773) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:37.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:48:37.210+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:37.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:37.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:48:37.273+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:37.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:48:37.295+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:48:37.295+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:48:37.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.111 seconds
[2024-11-04T13:49:07.913+0000] {processor.py:157} INFO - Started process (PID=25824) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:07.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:49:07.916+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:07.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:07.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:07.985+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:07.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:49:08.009+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:08.009+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:49:08.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:49:38.743+0000] {processor.py:157} INFO - Started process (PID=25875) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:38.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:49:38.746+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:38.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:38.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:49:38.816+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:38.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:49:38.839+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:49:38.839+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:49:38.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:50:09.386+0000] {processor.py:157} INFO - Started process (PID=25926) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:09.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:50:09.389+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:09.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:09.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:09.455+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:09.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:50:09.477+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:09.477+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:50:09.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T13:50:40.177+0000] {processor.py:157} INFO - Started process (PID=25977) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:40.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:50:40.182+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:40.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:40.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:50:40.257+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:40.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:50:40.285+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:50:40.285+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:50:40.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.133 seconds
[2024-11-04T13:51:10.895+0000] {processor.py:157} INFO - Started process (PID=26022) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:10.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:51:10.899+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:10.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:10.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:10.981+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:10.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:51:11.006+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:11.005+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:51:11.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.134 seconds
[2024-11-04T13:51:41.350+0000] {processor.py:157} INFO - Started process (PID=26073) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:41.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:51:41.353+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:41.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:41.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:51:41.416+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:41.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:51:41.441+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:51:41.441+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:51:41.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-04T13:52:11.780+0000] {processor.py:157} INFO - Started process (PID=26124) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:11.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:52:11.783+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:11.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:11.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:11.845+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:11.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:52:11.868+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:11.868+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:52:11.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-04T13:52:42.311+0000] {processor.py:157} INFO - Started process (PID=26175) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:42.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:52:42.315+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:42.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:42.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:52:42.387+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:42.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:52:42.414+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:52:42.414+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:52:42.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.128 seconds
[2024-11-04T13:53:12.917+0000] {processor.py:157} INFO - Started process (PID=26226) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:12.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:53:12.920+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:12.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:12.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:13.005+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:13.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:53:13.031+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:13.031+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:53:13.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.140 seconds
[2024-11-04T13:53:43.435+0000] {processor.py:157} INFO - Started process (PID=26277) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:43.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:53:43.439+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:43.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:43.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:53:43.505+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:43.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:53:43.538+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:53:43.537+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:53:43.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.129 seconds
[2024-11-04T13:54:13.984+0000] {processor.py:157} INFO - Started process (PID=26328) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:13.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:54:13.987+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:13.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:14.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:14.052+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:14.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:54:14.073+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:14.073+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:54:14.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:54:44.540+0000] {processor.py:157} INFO - Started process (PID=26379) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:44.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:54:44.544+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:44.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:44.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:54:44.613+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:44.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:54:44.641+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:54:44.641+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:54:44.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.126 seconds
[2024-11-04T13:55:15.311+0000] {processor.py:157} INFO - Started process (PID=26430) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:15.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:55:15.315+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:15.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:15.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:15.386+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:15.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:55:15.412+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:15.411+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:55:15.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.123 seconds
[2024-11-04T13:55:45.855+0000] {processor.py:157} INFO - Started process (PID=26481) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:45.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:55:45.859+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:45.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:45.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:55:45.927+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:45.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:55:45.950+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:55:45.949+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:55:45.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.124 seconds
[2024-11-04T13:56:16.430+0000] {processor.py:157} INFO - Started process (PID=26532) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:16.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:56:16.433+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:16.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:16.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:16.502+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:16.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:56:16.526+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:16.526+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:56:16.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.121 seconds
[2024-11-04T13:56:47.227+0000] {processor.py:157} INFO - Started process (PID=26583) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:47.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:56:47.230+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:47.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:47.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:56:47.294+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:47.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:56:47.315+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:56:47.314+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:56:47.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-04T13:57:17.561+0000] {processor.py:157} INFO - Started process (PID=26634) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:17.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:57:17.567+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:17.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:17.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:17.638+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:17.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:57:17.658+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:17.658+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:57:17.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.120 seconds
[2024-11-04T13:57:47.980+0000] {processor.py:157} INFO - Started process (PID=26685) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:47.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:57:47.983+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:47.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:48.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:57:48.048+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:48.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:57:48.071+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:57:48.071+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:57:48.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:58:18.613+0000] {processor.py:157} INFO - Started process (PID=26736) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:18.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:58:18.617+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:18.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:18.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:18.686+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:18.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:58:18.712+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:18.712+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:58:18.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.125 seconds
[2024-11-04T13:58:49.134+0000] {processor.py:157} INFO - Started process (PID=26787) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:49.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:58:49.138+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:49.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:49.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:58:49.202+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:49.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:58:49.224+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:58:49.224+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:58:49.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T13:59:19.841+0000] {processor.py:157} INFO - Started process (PID=26838) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:19.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:59:19.844+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:19.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:19.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:19.908+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:19.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:59:19.930+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:19.930+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:59:19.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.117 seconds
[2024-11-04T13:59:50.458+0000] {processor.py:157} INFO - Started process (PID=26889) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:50.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T13:59:50.461+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:50.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:50.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T13:59:50.525+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:50.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T13:59:50.547+0000] {logging_mixin.py:151} INFO - [2024-11-04T13:59:50.547+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T13:59:50.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-04T14:00:20.729+0000] {processor.py:157} INFO - Started process (PID=26940) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:20.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T14:00:20.733+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:20.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:20.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:20.810+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:20.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T14:00:20.837+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:20.837+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T14:00:20.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.135 seconds
[2024-11-04T14:00:50.939+0000] {processor.py:157} INFO - Started process (PID=26991) to work on /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:50.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-04T14:00:50.943+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:50.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:50.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-04T14:00:51.007+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:51.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-04T14:00:51.029+0000] {logging_mixin.py:151} INFO - [2024-11-04T14:00:51.029+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
[2024-11-04T14:00:51.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
