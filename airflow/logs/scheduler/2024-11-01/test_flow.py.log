[2024-11-01T16:03:06.820+0000] {processor.py:157} INFO - Started process (PID=193) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:06.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:03:06.823+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:06.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:06.972+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.972+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-11-01T16:03:06.983+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.983+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-11-01T16:03:06.991+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.991+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-11-01T16:03:06.992+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.992+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-01T16:03:06.993+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:06.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:03:07.003+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:07.003+0000] {dag.py:2937} INFO - Creating ORM DAG for test_flowwww
[2024-11-01T16:03:07.013+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:07.012+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:03:07.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.213 seconds
[2024-11-01T16:03:37.421+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:37.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:03:37.424+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:37.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:37.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:03:37.502+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:37.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:03:37.543+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:03:37.542+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:03:37.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.160 seconds
[2024-11-01T16:12:00.969+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:00.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:12:00.972+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:00.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:00.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:01.019+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:01.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:12:01.046+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:01.046+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:12:01.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.099 seconds
[2024-11-01T16:12:32.007+0000] {processor.py:157} INFO - Started process (PID=255) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:32.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:12:32.011+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:32.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:32.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:12:32.075+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:32.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:12:32.098+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:12:32.098+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:12:32.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-01T16:13:02.384+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:02.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:13:02.387+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:02.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:02.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:02.444+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:02.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:13:02.463+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:02.462+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:13:02.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.100 seconds
[2024-11-01T16:13:32.933+0000] {processor.py:157} INFO - Started process (PID=346) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:32.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:13:32.937+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:32.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:32.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:13:33.006+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:33.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:13:33.029+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:13:33.029+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:13:33.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.122 seconds
[2024-11-01T16:14:03.497+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:03.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:14:03.500+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:03.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:03.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:03.560+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:03.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:14:03.580+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:03.579+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:14:03.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.106 seconds
[2024-11-01T16:14:33.931+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:33.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:14:33.933+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:33.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:33.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:14:33.990+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:33.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:14:34.009+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:14:34.009+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:14:34.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:15:04.150+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:04.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:15:04.152+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:04.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:04.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:04.206+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:04.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:15:04.225+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:04.225+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:15:04.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.094 seconds
[2024-11-01T16:15:34.607+0000] {processor.py:157} INFO - Started process (PID=636) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:34.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:15:34.609+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:34.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:34.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:15:34.671+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:34.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:15:34.690+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:15:34.690+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:15:34.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.104 seconds
[2024-11-01T16:16:04.936+0000] {processor.py:157} INFO - Started process (PID=767) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:04.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:16:04.939+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:04.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:04.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:05.003+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:05.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:16:05.024+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:05.024+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:16:05.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.113 seconds
[2024-11-01T16:16:35.403+0000] {processor.py:157} INFO - Started process (PID=967) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:35.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:16:35.445+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:35.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:35.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:16:35.561+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:35.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:16:35.606+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:16:35.605+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:16:35.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.252 seconds
[2024-11-01T16:17:05.707+0000] {processor.py:157} INFO - Started process (PID=1020) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:05.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:17:05.710+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:05.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:05.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:05.767+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:05.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:17:05.787+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:05.787+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:17:05.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.107 seconds
[2024-11-01T16:17:35.961+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:35.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:17:35.970+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:35.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:36.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:17:36.092+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:36.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:17:36.143+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:17:36.143+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:17:36.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.232 seconds
[2024-11-01T16:18:06.684+0000] {processor.py:157} INFO - Started process (PID=1324) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:06.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:18:06.687+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:06.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:06.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:06.743+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:06.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:18:06.763+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:06.763+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:18:06.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:18:37.154+0000] {processor.py:157} INFO - Started process (PID=1371) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:37.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:18:37.160+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:37.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:37.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:18:37.225+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:37.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:18:37.247+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:18:37.247+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:18:37.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.114 seconds
[2024-11-01T16:19:07.382+0000] {processor.py:157} INFO - Started process (PID=1620) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:07.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:19:07.386+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:07.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:07.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:07.589+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:07.588+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-01T16:19:07.590+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:07.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:19:07.599+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:07.599+0000] {dag.py:2937} INFO - Creating ORM DAG for test_flowwww
[2024-11-01T16:19:07.609+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:07.609+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:19:07.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.252 seconds
[2024-11-01T16:19:37.826+0000] {processor.py:157} INFO - Started process (PID=1667) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:37.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:19:37.829+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:37.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:37.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:19:37.884+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:37.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:19:37.903+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:19:37.903+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:19:37.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.098 seconds
[2024-11-01T16:20:08.010+0000] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:08.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:20:08.014+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:08.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:08.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:08.084+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:08.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:20:08.106+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:08.105+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:20:08.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.122 seconds
[2024-11-01T16:20:38.552+0000] {processor.py:157} INFO - Started process (PID=1761) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:38.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:20:38.555+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:38.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:38.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:38.609+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:38.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:20:38.628+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:38.628+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:20:38.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.097 seconds
[2024-11-01T16:20:46.417+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:46.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:20:46.420+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:46.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:46.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:20:46.484+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:46.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:20:46.502+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:20:46.502+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:20:46.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-01T16:21:16.564+0000] {processor.py:157} INFO - Started process (PID=1855) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:16.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:21:16.566+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:16.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:16.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:16.621+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:16.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:21:16.638+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:16.638+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:21:16.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.095 seconds
[2024-11-01T16:21:46.851+0000] {processor.py:157} INFO - Started process (PID=1902) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:46.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:21:46.854+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:46.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:46.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:21:46.908+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:46.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:21:46.925+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:21:46.925+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:21:46.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.092 seconds
[2024-11-01T16:22:17.161+0000] {processor.py:157} INFO - Started process (PID=1943) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:17.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:22:17.164+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:17.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:17.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:17.220+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:17.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:22:17.240+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:17.240+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:22:17.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:22:48.047+0000] {processor.py:157} INFO - Started process (PID=2379) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:48.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:22:48.049+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:48.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:48.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:22:48.107+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:48.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:22:48.128+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:22:48.128+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:22:48.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.103 seconds
[2024-11-01T16:23:18.336+0000] {processor.py:157} INFO - Started process (PID=2426) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:18.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:23:18.338+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:18.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:18.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:18.391+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:18.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:23:18.410+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:18.410+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:23:18.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.096 seconds
[2024-11-01T16:23:48.496+0000] {processor.py:157} INFO - Started process (PID=2471) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:48.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:23:48.499+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:48.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:48.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:23:48.551+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:48.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:23:48.568+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:23:48.568+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:23:48.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.091 seconds
[2024-11-01T16:24:14.697+0000] {processor.py:157} INFO - Started process (PID=2514) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:14.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:24:14.701+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:14.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:14.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:14.834+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:14.834+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-01T16:24:14.835+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:14.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:24:14.853+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:14.853+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:24:14.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.181 seconds
[2024-11-01T16:24:15.821+0000] {processor.py:157} INFO - Started process (PID=2521) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:15.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:24:15.824+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:15.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:15.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:15.863+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:15.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:24:15.883+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:15.883+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:24:15.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.095 seconds
[2024-11-01T16:24:25.136+0000] {processor.py:157} INFO - Started process (PID=2850) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:25.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:24:25.140+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:25.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:25.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:25.201+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:25.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:24:25.231+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:25.231+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:24:25.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.139 seconds
[2024-11-01T16:24:37.353+0000] {processor.py:157} INFO - Started process (PID=2940) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:37.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:24:37.356+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:37.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:37.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:24:37.473+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:37.473+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-01T16:24:37.474+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:37.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:24:37.482+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:37.482+0000] {dag.py:2937} INFO - Creating ORM DAG for test_flowwww
[2024-11-01T16:24:37.492+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:24:37.492+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
[2024-11-01T16:24:37.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.177 seconds
[2024-11-01T16:25:08.057+0000] {processor.py:157} INFO - Started process (PID=3100) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:08.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:25:08.060+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:08.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:08.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:08.158+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:08.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:25:08.190+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:08.190+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:25:08.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.177 seconds
[2024-11-01T16:25:38.659+0000] {processor.py:157} INFO - Started process (PID=3432) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:38.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:25:38.662+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:38.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:38.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:25:38.716+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:38.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:25:38.733+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:25:38.733+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:25:38.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.099 seconds
[2024-11-01T16:26:05.618+0000] {processor.py:157} INFO - Started process (PID=3479) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:26:05.620+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.740+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.739+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:test_flowwww' as access control is unset.
[2024-11-01T16:26:05.741+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:26:05.758+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.758+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:26:05.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.166 seconds
[2024-11-01T16:26:05.827+0000] {processor.py:157} INFO - Started process (PID=3484) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:26:05.830+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:05.860+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:26:05.878+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:05.878+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:26:05.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.082 seconds
[2024-11-01T16:26:36.140+0000] {processor.py:157} INFO - Started process (PID=3930) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:36.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:26:36.143+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:36.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:36.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:26:36.196+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:36.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:26:36.215+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:26:36.215+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:26:36.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.095 seconds
[2024-11-01T16:27:06.328+0000] {processor.py:157} INFO - Started process (PID=3977) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:06.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:27:06.330+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:06.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:06.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:06.385+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:06.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:27:06.405+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:06.405+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:27:06.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:27:36.920+0000] {processor.py:157} INFO - Started process (PID=4024) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:36.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:27:36.922+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:36.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:36.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:27:36.976+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:36.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:27:36.995+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:27:36.995+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:27:37.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.095 seconds
[2024-11-01T16:28:08.102+0000] {processor.py:157} INFO - Started process (PID=4116) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:08.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:28:08.110+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:08.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:08.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:08.661+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:08.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:28:08.688+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:08.687+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:28:08.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.626 seconds
[2024-11-01T16:28:39.078+0000] {processor.py:157} INFO - Started process (PID=4164) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:39.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:28:39.082+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:39.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:39.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:28:39.144+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:39.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:28:39.165+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:28:39.165+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:28:44.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 5.688 seconds
[2024-11-01T16:29:14.979+0000] {processor.py:157} INFO - Started process (PID=4220) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:14.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:29:14.982+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:14.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:15.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:15.044+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:15.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:29:15.065+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:15.065+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:29:15.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.109 seconds
[2024-11-01T16:29:45.169+0000] {processor.py:157} INFO - Started process (PID=4267) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:45.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:29:45.172+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:45.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:45.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:29:45.233+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:45.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:29:45.254+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:29:45.254+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:29:45.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-01T16:30:15.354+0000] {processor.py:157} INFO - Started process (PID=4314) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:15.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:30:15.357+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:15.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:15.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:15.419+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:15.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:30:15.441+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:15.440+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:30:15.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-01T16:30:45.541+0000] {processor.py:157} INFO - Started process (PID=4361) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:45.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:30:45.545+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:45.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:45.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:30:45.610+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:45.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:30:45.629+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:30:45.629+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:30:45.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-01T16:31:15.724+0000] {processor.py:157} INFO - Started process (PID=4408) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:15.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:31:15.728+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:15.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:15.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:15.791+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:15.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:31:15.813+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:15.813+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:31:15.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.112 seconds
[2024-11-01T16:31:45.908+0000] {processor.py:157} INFO - Started process (PID=4455) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:45.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:31:45.912+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:45.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:45.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:31:45.973+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:45.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:31:45.994+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:31:45.994+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:31:46.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.108 seconds
[2024-11-01T16:32:16.381+0000] {processor.py:157} INFO - Started process (PID=4683) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:16.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:32:16.385+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:16.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:16.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:16.478+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:16.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:32:16.502+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:16.502+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:32:16.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.148 seconds
[2024-11-01T16:32:46.653+0000] {processor.py:157} INFO - Started process (PID=5018) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:46.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:32:46.657+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:46.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:46.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:32:46.736+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:46.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:32:46.761+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:32:46.761+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:32:46.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.133 seconds
[2024-11-01T16:33:17.063+0000] {processor.py:157} INFO - Started process (PID=5382) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:17.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:33:17.067+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:17.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:17.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:17.154+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:17.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:33:17.180+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:17.180+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:33:17.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.143 seconds
[2024-11-01T16:33:47.420+0000] {processor.py:157} INFO - Started process (PID=5704) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:47.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:33:47.424+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:47.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:47.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:33:47.506+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:47.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:33:47.536+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:33:47.536+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:33:47.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.155 seconds
[2024-11-01T16:34:18.352+0000] {processor.py:157} INFO - Started process (PID=6031) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:18.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:34:18.357+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:18.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:18.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:18.470+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:18.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:34:18.538+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:18.537+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:34:18.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.221 seconds
[2024-11-01T16:34:48.629+0000] {processor.py:157} INFO - Started process (PID=6209) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:48.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:34:48.640+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:48.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:48.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:34:48.745+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:48.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:34:48.790+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:34:48.790+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:34:48.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.192 seconds
[2024-11-01T16:35:18.925+0000] {processor.py:157} INFO - Started process (PID=6256) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:18.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:35:18.928+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:18.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:18.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:18.984+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:18.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:35:19.003+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:19.003+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:35:19.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.100 seconds
[2024-11-01T16:35:49.682+0000] {processor.py:157} INFO - Started process (PID=6303) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:49.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:35:49.685+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:49.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:49.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:35:49.741+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:49.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:35:49.762+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:35:49.762+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:35:49.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:36:20.566+0000] {processor.py:157} INFO - Started process (PID=6350) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:20.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:36:20.570+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:20.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:20.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:20.624+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:20.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:36:20.644+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:20.644+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:36:20.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.098 seconds
[2024-11-01T16:36:51.490+0000] {processor.py:157} INFO - Started process (PID=6397) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:51.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:36:51.494+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:51.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:51.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:36:51.555+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:51.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:36:51.580+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:36:51.580+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:36:51.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.116 seconds
[2024-11-01T16:37:21.682+0000] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:21.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:37:21.685+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:21.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:21.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:21.743+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:21.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:37:21.761+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:21.761+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:37:21.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.100 seconds
[2024-11-01T16:37:51.858+0000] {processor.py:157} INFO - Started process (PID=6491) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:51.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:37:51.861+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:51.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:51.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:37:51.919+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:51.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:37:51.938+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:37:51.938+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:37:51.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.101 seconds
[2024-11-01T16:38:22.095+0000] {processor.py:157} INFO - Started process (PID=6538) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:22.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:38:22.098+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:22.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:22.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:22.152+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:22.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:38:22.171+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:22.171+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:38:22.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.098 seconds
[2024-11-01T16:38:52.436+0000] {processor.py:157} INFO - Started process (PID=6585) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:52.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:38:52.439+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:52.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:52.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:38:52.500+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:52.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:38:52.521+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:38:52.521+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:38:52.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.110 seconds
[2024-11-01T16:39:14.280+0000] {processor.py:157} INFO - Started process (PID=6632) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:14.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:39:14.283+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:14.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:14.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['test_flowwww']) retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:14.348+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:14.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-11-01T16:39:14.370+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:14.369+0000] {dag.py:3696} INFO - Setting next_dagrun for test_flowwww to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
[2024-11-01T16:39:14.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.115 seconds
[2024-11-01T16:39:20.368+0000] {processor.py:157} INFO - Started process (PID=6637) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:20.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:39:20.371+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:20.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:20.389+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:20.386+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138
    cleaned_movies = SparkSubmitOperator(
IndentationError: unexpected indent
[2024-11-01T16:39:20.389+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:20.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T16:39:26.527+0000] {processor.py:157} INFO - Started process (PID=6647) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:26.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:39:26.532+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:26.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:26.565+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:26.559+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    cleaned_movies = SparkSubmitOperator(
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:39:26.566+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:26.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-01T16:39:30.077+0000] {processor.py:157} INFO - Started process (PID=6673) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:30.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:39:30.081+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:30.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:30.114+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:30.110+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:39:30.115+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:30.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-01T16:39:31.102+0000] {processor.py:157} INFO - Started process (PID=6678) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:31.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:39:31.106+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:31.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:31.140+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:39:31.133+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:39:31.142+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:39:31.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.070 seconds
[2024-11-01T16:40:01.282+0000] {processor.py:157} INFO - Started process (PID=6725) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:01.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:40:01.286+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:40:01.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:01.307+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:40:01.301+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:40:01.308+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:01.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:40:31.369+0000] {processor.py:157} INFO - Started process (PID=6772) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:31.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:40:31.372+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:40:31.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:31.394+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:40:31.388+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:40:31.395+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:40:31.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T16:41:01.584+0000] {processor.py:157} INFO - Started process (PID=6819) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:01.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:41:01.587+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:41:01.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:01.608+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:41:01.602+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:41:01.609+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:01.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T16:41:31.918+0000] {processor.py:157} INFO - Started process (PID=6866) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:31.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:41:31.920+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:41:31.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:31.940+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:41:31.936+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:41:31.941+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:41:31.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:42:02.799+0000] {processor.py:157} INFO - Started process (PID=6907) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:02.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:42:02.800+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:42:02.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:02.819+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:42:02.815+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:42:02.820+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:02.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T16:42:33.066+0000] {processor.py:157} INFO - Started process (PID=6954) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:33.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:42:33.068+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:42:33.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:33.087+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:42:33.083+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:42:33.089+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:42:33.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:43:03.716+0000] {processor.py:157} INFO - Started process (PID=7001) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:03.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:43:03.718+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:43:03.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:03.738+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:43:03.733+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:43:03.739+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:03.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T16:43:34.137+0000] {processor.py:157} INFO - Started process (PID=7048) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:34.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:43:34.140+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:43:34.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:34.164+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:43:34.160+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:43:34.165+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:43:34.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T16:44:04.660+0000] {processor.py:157} INFO - Started process (PID=7095) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:04.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:44:04.662+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:44:04.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:04.682+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:44:04.678+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:44:04.683+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:04.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T16:44:35.004+0000] {processor.py:157} INFO - Started process (PID=7142) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:35.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:44:35.006+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:44:35.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:35.025+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:44:35.021+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:44:35.026+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:44:35.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T16:45:05.700+0000] {processor.py:157} INFO - Started process (PID=7189) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:05.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:45:05.702+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:45:05.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:05.725+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:45:05.720+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:45:05.726+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:05.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:45:36.616+0000] {processor.py:157} INFO - Started process (PID=7236) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:36.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:45:36.618+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:45:36.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:36.647+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:45:36.634+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:45:36.648+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:45:36.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T16:46:06.946+0000] {processor.py:157} INFO - Started process (PID=7283) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:06.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:46:06.948+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:46:06.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:06.969+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:46:06.964+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:46:06.970+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:06.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T16:46:37.789+0000] {processor.py:157} INFO - Started process (PID=7330) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:37.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:46:37.791+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:46:37.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:37.813+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:46:37.806+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:46:37.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:46:37.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T16:47:08.229+0000] {processor.py:157} INFO - Started process (PID=7377) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:08.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:47:08.231+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:47:08.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:08.250+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:47:08.245+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:47:08.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:08.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T16:47:38.479+0000] {processor.py:157} INFO - Started process (PID=7424) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:38.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:47:38.481+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:47:38.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:38.502+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:47:38.498+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:47:38.503+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:47:38.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:48:09.175+0000] {processor.py:157} INFO - Started process (PID=7471) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:09.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:48:09.176+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:48:09.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:09.197+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:48:09.192+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:48:09.198+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:09.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:48:39.662+0000] {processor.py:157} INFO - Started process (PID=7518) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:39.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:48:39.664+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:48:39.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:39.685+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:48:39.680+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:48:39.686+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:48:39.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:49:10.253+0000] {processor.py:157} INFO - Started process (PID=7565) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:10.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:49:10.255+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:49:10.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:10.277+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:49:10.272+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:49:10.278+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:10.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:49:40.562+0000] {processor.py:157} INFO - Started process (PID=7612) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:40.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:49:40.565+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:49:40.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:40.589+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:49:40.584+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:49:40.590+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:49:40.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T16:50:11.086+0000] {processor.py:157} INFO - Started process (PID=7659) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:11.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:50:11.088+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:50:11.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:11.106+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:50:11.103+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:50:11.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:11.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T16:50:41.588+0000] {processor.py:157} INFO - Started process (PID=7706) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:41.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:50:41.590+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:50:41.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:41.619+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:50:41.612+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:50:41.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:50:41.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.061 seconds
[2024-11-01T16:51:12.194+0000] {processor.py:157} INFO - Started process (PID=7753) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:12.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:51:12.196+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:51:12.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:12.216+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:51:12.211+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:51:12.217+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:12.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T16:51:42.576+0000] {processor.py:157} INFO - Started process (PID=7800) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:42.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:51:42.578+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:51:42.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:42.602+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:51:42.597+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:51:42.604+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:51:42.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T16:52:13.193+0000] {processor.py:157} INFO - Started process (PID=7847) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:13.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:52:13.195+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:52:13.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:13.217+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:52:13.213+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:52:13.218+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:13.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T16:52:43.757+0000] {processor.py:157} INFO - Started process (PID=7894) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:43.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:52:43.759+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:52:43.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:43.779+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:52:43.775+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:52:43.780+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:52:43.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:53:14.250+0000] {processor.py:157} INFO - Started process (PID=7941) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:14.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:53:14.252+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:53:14.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:14.275+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:53:14.268+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:53:14.277+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:14.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T16:53:44.506+0000] {processor.py:157} INFO - Started process (PID=7988) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:44.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:53:44.508+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:53:44.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:44.547+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:53:44.532+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:53:44.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:53:44.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.073 seconds
[2024-11-01T16:54:15.232+0000] {processor.py:157} INFO - Started process (PID=8035) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:15.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:54:15.235+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:54:15.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:15.255+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:54:15.251+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:54:15.256+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:15.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T16:54:45.784+0000] {processor.py:157} INFO - Started process (PID=8082) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:45.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:54:45.786+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:54:45.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:45.809+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:54:45.802+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:54:45.810+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:54:45.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T16:55:16.473+0000] {processor.py:157} INFO - Started process (PID=8129) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:16.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:55:16.474+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:55:16.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:16.494+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:55:16.490+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:55:16.495+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:16.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T16:55:46.620+0000] {processor.py:157} INFO - Started process (PID=8176) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:46.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:55:46.622+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:55:46.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:46.645+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:55:46.638+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:55:46.646+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:55:46.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T16:56:17.327+0000] {processor.py:157} INFO - Started process (PID=8223) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:17.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:56:17.329+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:56:17.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:17.350+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:56:17.345+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:56:17.351+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:17.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T16:56:47.648+0000] {processor.py:157} INFO - Started process (PID=8270) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:47.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:56:47.650+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:56:47.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:47.672+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:56:47.667+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:56:47.673+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:56:47.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T16:57:18.505+0000] {processor.py:157} INFO - Started process (PID=8317) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:18.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:57:18.507+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:57:18.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:18.527+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:57:18.523+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:57:18.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:18.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:57:49.184+0000] {processor.py:157} INFO - Started process (PID=8364) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:49.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:57:49.186+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:57:49.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:49.207+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:57:49.202+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:57:49.208+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:57:49.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T16:58:19.920+0000] {processor.py:157} INFO - Started process (PID=8411) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:19.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:58:19.922+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:58:19.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:19.943+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:58:19.939+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:58:19.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:19.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:58:50.071+0000] {processor.py:157} INFO - Started process (PID=8458) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:50.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:58:50.073+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:58:50.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:50.093+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:58:50.089+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:58:50.094+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:58:50.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T16:59:20.240+0000] {processor.py:157} INFO - Started process (PID=8505) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:20.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:59:20.242+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:59:20.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:20.265+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:59:20.258+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:59:20.266+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:20.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T16:59:50.594+0000] {processor.py:157} INFO - Started process (PID=8552) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:50.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T16:59:50.596+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:59:50.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:50.616+0000] {logging_mixin.py:151} INFO - [2024-11-01T16:59:50.612+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T16:59:50.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T16:59:50.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:00:20.887+0000] {processor.py:157} INFO - Started process (PID=8599) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:20.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:00:20.889+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:00:20.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:20.909+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:00:20.905+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:00:20.910+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:20.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:00:51.590+0000] {processor.py:157} INFO - Started process (PID=8646) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:51.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:00:51.592+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:00:51.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:51.616+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:00:51.608+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:00:51.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:00:51.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:01:21.871+0000] {processor.py:157} INFO - Started process (PID=8693) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:21.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:01:21.873+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:01:21.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:21.892+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:01:21.888+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:01:21.893+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:21.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:01:52.100+0000] {processor.py:157} INFO - Started process (PID=8740) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:52.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:01:52.102+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:01:52.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:52.122+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:01:52.118+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:01:52.123+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:01:52.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:02:22.826+0000] {processor.py:157} INFO - Started process (PID=8787) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:22.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:02:22.829+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:02:22.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:22.850+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:02:22.844+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:02:22.851+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:22.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:02:53.497+0000] {processor.py:157} INFO - Started process (PID=8828) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:53.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:02:53.499+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:02:53.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:53.519+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:02:53.515+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:02:53.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:02:53.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:03:23.707+0000] {processor.py:157} INFO - Started process (PID=8875) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:23.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:03:23.709+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:03:23.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:23.736+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:03:23.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:03:23.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:23.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-01T17:03:54.412+0000] {processor.py:157} INFO - Started process (PID=8922) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:54.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:03:54.414+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:03:54.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:54.435+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:03:54.430+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:03:54.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:03:54.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T17:04:25.110+0000] {processor.py:157} INFO - Started process (PID=8969) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:25.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:04:25.112+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:04:25.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:25.132+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:04:25.128+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:04:25.133+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:25.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:04:55.956+0000] {processor.py:157} INFO - Started process (PID=9016) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:55.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:04:55.958+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:04:55.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:55.984+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:04:55.978+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:04:55.985+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:04:56.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:05:26.644+0000] {processor.py:157} INFO - Started process (PID=9063) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:26.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:05:26.646+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:05:26.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:26.666+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:05:26.661+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:05:26.667+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:26.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:05:57.332+0000] {processor.py:157} INFO - Started process (PID=9110) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:57.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:05:57.334+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:05:57.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:57.362+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:05:57.353+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:05:57.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:05:57.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.054 seconds
[2024-11-01T17:06:28.157+0000] {processor.py:157} INFO - Started process (PID=9157) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:28.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:06:28.159+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:28.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:28.188+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:28.183+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:06:28.189+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:28.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-01T17:06:35.040+0000] {processor.py:157} INFO - Started process (PID=9178) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:35.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:06:35.041+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:35.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:35.071+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:35.066+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:06:35.072+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:35.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-01T17:06:38.179+0000] {processor.py:157} INFO - Started process (PID=9189) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:38.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:06:38.181+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:38.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:38.211+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:38.205+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:06:38.212+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:38.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-01T17:06:45.281+0000] {processor.py:157} INFO - Started process (PID=9194) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:45.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:06:45.283+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:45.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:45.316+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:06:45.309+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:06:45.318+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:06:45.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-01T17:07:03.959+0000] {processor.py:157} INFO - Started process (PID=9229) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:03.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:07:03.961+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:03.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:03.978+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:03.977+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 166
    clean_keywords >> clean_ratings >> clean_review >> clean_credit >> cleaned_movies >>
                                                                                        ^
SyntaxError: invalid syntax
[2024-11-01T17:07:03.978+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:03.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.039 seconds
[2024-11-01T17:07:10.720+0000] {processor.py:157} INFO - Started process (PID=9246) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:10.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:07:10.722+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:10.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:10.752+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:10.747+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:07:10.754+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:10.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.053 seconds
[2024-11-01T17:07:11.741+0000] {processor.py:157} INFO - Started process (PID=9251) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:11.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:07:11.743+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:11.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:11.772+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:11.767+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:07:11.773+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:11.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-01T17:07:29.291+0000] {processor.py:157} INFO - Started process (PID=9276) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:29.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:07:29.294+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:29.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:29.324+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:29.319+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:07:29.325+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:29.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-01T17:07:30.450+0000] {processor.py:157} INFO - Started process (PID=9291) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:30.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:07:30.452+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:30.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:30.480+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:07:30.475+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:07:30.481+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:07:30.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T17:08:01.197+0000] {processor.py:157} INFO - Started process (PID=9338) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:01.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:08:01.199+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:08:01.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:01.220+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:08:01.215+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:08:01.221+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:01.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:08:31.453+0000] {processor.py:157} INFO - Started process (PID=9385) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:31.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:08:31.454+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:08:31.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:31.476+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:08:31.468+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:08:31.477+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:08:31.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:09:02.130+0000] {processor.py:157} INFO - Started process (PID=9432) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:02.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:09:02.132+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:09:02.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:02.153+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:09:02.149+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:09:02.155+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:02.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:09:32.398+0000] {processor.py:157} INFO - Started process (PID=9479) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:32.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:09:32.400+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:09:32.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:32.422+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:09:32.417+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:09:32.424+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:09:32.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:10:02.627+0000] {processor.py:157} INFO - Started process (PID=9526) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:02.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:10:02.629+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:10:02.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:02.648+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:10:02.643+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:10:02.649+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:02.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:10:32.856+0000] {processor.py:157} INFO - Started process (PID=9573) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:32.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:10:32.858+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:10:32.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:32.878+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:10:32.873+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:10:32.879+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:10:32.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:11:03.127+0000] {processor.py:157} INFO - Started process (PID=9620) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:03.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:11:03.129+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:11:03.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:03.153+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:11:03.145+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:11:03.154+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:03.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:11:33.373+0000] {processor.py:157} INFO - Started process (PID=9667) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:33.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:11:33.375+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:11:33.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:33.397+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:11:33.391+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:11:33.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:11:33.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:12:03.734+0000] {processor.py:157} INFO - Started process (PID=9714) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:03.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:12:03.736+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:12:03.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:03.756+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:12:03.751+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:12:03.757+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:03.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:12:33.874+0000] {processor.py:157} INFO - Started process (PID=9761) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:33.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:12:33.876+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:12:33.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:33.897+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:12:33.891+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:12:33.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:12:33.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:13:04.151+0000] {processor.py:157} INFO - Started process (PID=9808) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:04.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:13:04.153+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:13:04.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:04.179+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:13:04.170+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:13:04.180+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:04.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:13:34.383+0000] {processor.py:157} INFO - Started process (PID=9855) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:34.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:13:34.385+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:13:34.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:34.414+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:13:34.408+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:13:34.416+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:13:34.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.057 seconds
[2024-11-01T17:14:05.393+0000] {processor.py:157} INFO - Started process (PID=9902) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:05.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:14:05.395+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:14:05.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:05.416+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:14:05.412+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:14:05.417+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:05.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:14:35.671+0000] {processor.py:157} INFO - Started process (PID=9949) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:35.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:14:35.673+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:14:35.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:35.697+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:14:35.691+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:14:35.698+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:14:35.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:15:05.924+0000] {processor.py:157} INFO - Started process (PID=9996) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:05.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:15:05.925+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:15:05.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:05.946+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:15:05.941+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:15:05.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:15:36.113+0000] {processor.py:157} INFO - Started process (PID=10043) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:36.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:15:36.115+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:15:36.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:36.134+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:15:36.130+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:15:36.135+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:15:36.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:16:06.360+0000] {processor.py:157} INFO - Started process (PID=10090) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:06.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:16:06.362+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:16:06.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:06.384+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:16:06.379+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:16:06.385+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:06.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-01T17:16:36.716+0000] {processor.py:157} INFO - Started process (PID=10137) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:36.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:16:36.718+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:16:36.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:36.739+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:16:36.732+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:16:36.740+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:16:36.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:17:06.978+0000] {processor.py:157} INFO - Started process (PID=10189) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:06.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:17:06.980+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:17:06.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:07.002+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:17:06.997+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:17:07.003+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:07.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:17:37.178+0000] {processor.py:157} INFO - Started process (PID=10251) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:37.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:17:37.180+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:17:37.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:37.201+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:17:37.196+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:17:37.203+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:17:37.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:18:07.500+0000] {processor.py:157} INFO - Started process (PID=10303) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:07.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:18:07.502+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:18:07.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:07.523+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:18:07.518+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:18:07.524+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:07.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:18:38.255+0000] {processor.py:157} INFO - Started process (PID=10355) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:38.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:18:38.258+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:18:38.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:38.280+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:18:38.274+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:18:38.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:18:38.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:19:08.461+0000] {processor.py:157} INFO - Started process (PID=10407) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:08.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:19:08.462+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:19:08.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:08.484+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:19:08.479+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:19:08.485+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:08.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:19:38.958+0000] {processor.py:157} INFO - Started process (PID=10464) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:38.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:19:38.960+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:19:38.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:38.981+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:19:38.976+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:19:38.982+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:19:38.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:20:09.371+0000] {processor.py:157} INFO - Started process (PID=10825) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:09.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:20:09.374+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:20:09.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:09.403+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:20:09.396+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:20:09.405+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:09.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.060 seconds
[2024-11-01T17:20:39.677+0000] {processor.py:157} INFO - Started process (PID=10984) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:39.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:20:39.679+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:20:39.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:39.699+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:20:39.694+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:20:39.701+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:20:39.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:21:10.014+0000] {processor.py:157} INFO - Started process (PID=11036) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:10.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:21:10.016+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:21:10.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:10.039+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:21:10.033+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:21:10.040+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:10.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:21:40.416+0000] {processor.py:157} INFO - Started process (PID=11088) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:40.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:21:40.418+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:21:40.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:40.438+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:21:40.433+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:21:40.439+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:21:40.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:22:10.939+0000] {processor.py:157} INFO - Started process (PID=11140) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:10.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:22:10.941+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:22:10.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:10.962+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:22:10.957+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:22:10.963+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:10.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:22:41.448+0000] {processor.py:157} INFO - Started process (PID=11192) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:41.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:22:41.450+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:22:41.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:41.470+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:22:41.466+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:22:41.471+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:22:41.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:23:11.808+0000] {processor.py:157} INFO - Started process (PID=11244) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:11.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:23:11.810+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:23:11.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:11.830+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:23:11.825+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:23:11.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:11.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:23:42.542+0000] {processor.py:157} INFO - Started process (PID=11290) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:42.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:23:42.544+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:23:42.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:42.564+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:23:42.560+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:23:42.565+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:23:42.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:24:12.908+0000] {processor.py:157} INFO - Started process (PID=11342) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:12.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:24:12.909+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:24:12.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:12.928+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:24:12.924+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:24:12.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:12.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.039 seconds
[2024-11-01T17:24:43.414+0000] {processor.py:157} INFO - Started process (PID=11394) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:43.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:24:43.415+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:24:43.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:43.436+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:24:43.431+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:24:43.437+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:24:43.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:25:13.827+0000] {processor.py:157} INFO - Started process (PID=11446) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:13.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:25:13.829+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:25:13.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:13.848+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:25:13.844+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:25:13.849+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:13.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:25:44.358+0000] {processor.py:157} INFO - Started process (PID=11908) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:44.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:25:44.359+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:25:44.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:44.381+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:25:44.376+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:25:44.382+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:25:44.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-01T17:26:14.993+0000] {processor.py:157} INFO - Started process (PID=11960) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:14.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:26:14.995+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:26:14.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:15.016+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:26:15.010+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:26:15.017+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:15.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:26:45.812+0000] {processor.py:157} INFO - Started process (PID=12012) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:45.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:26:45.814+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:26:45.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:45.836+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:26:45.830+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:26:45.837+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:26:45.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:27:16.223+0000] {processor.py:157} INFO - Started process (PID=12064) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:16.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:27:16.230+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:27:16.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:16.265+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:27:16.259+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:27:16.266+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:16.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.069 seconds
[2024-11-01T17:27:46.617+0000] {processor.py:157} INFO - Started process (PID=12116) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:46.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:27:46.619+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:27:46.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:46.640+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:27:46.635+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:27:46.641+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:27:46.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:28:16.941+0000] {processor.py:157} INFO - Started process (PID=12168) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:16.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:28:16.943+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:28:16.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:16.963+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:28:16.958+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:28:16.964+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:16.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:28:47.277+0000] {processor.py:157} INFO - Started process (PID=12220) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:47.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:28:47.279+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:28:47.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:47.299+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:28:47.295+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:28:47.300+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:28:47.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:29:17.592+0000] {processor.py:157} INFO - Started process (PID=12272) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:17.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:29:17.595+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:29:17.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:17.616+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:29:17.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:29:17.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:17.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:29:48.153+0000] {processor.py:157} INFO - Started process (PID=12324) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:48.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:29:48.155+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:29:48.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:48.176+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:29:48.171+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:29:48.177+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:29:48.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:30:18.842+0000] {processor.py:157} INFO - Started process (PID=12376) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:18.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:30:18.844+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:30:18.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:18.865+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:30:18.860+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:30:18.866+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:18.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:30:49.421+0000] {processor.py:157} INFO - Started process (PID=12428) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:49.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:30:49.423+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:30:49.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:49.446+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:30:49.439+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:30:49.447+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:30:49.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-01T17:31:19.938+0000] {processor.py:157} INFO - Started process (PID=12480) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:19.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:31:19.940+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:31:19.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:19.960+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:31:19.955+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:31:19.961+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:19.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:31:50.448+0000] {processor.py:157} INFO - Started process (PID=12532) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:50.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:31:50.450+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:31:50.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:50.471+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:31:50.465+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:31:50.472+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:31:50.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:32:21.076+0000] {processor.py:157} INFO - Started process (PID=12584) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:21.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:32:21.078+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:32:21.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:21.100+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:32:21.094+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:32:21.101+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:21.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:32:51.515+0000] {processor.py:157} INFO - Started process (PID=12636) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:51.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:32:51.516+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:32:51.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:51.538+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:32:51.533+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:32:51.539+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:32:51.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:33:21.963+0000] {processor.py:157} INFO - Started process (PID=12688) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:21.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:33:21.965+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:33:21.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:21.987+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:33:21.981+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:33:21.988+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:22.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:33:52.549+0000] {processor.py:157} INFO - Started process (PID=12740) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:52.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:33:52.551+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:33:52.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:52.572+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:33:52.567+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:33:52.573+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:33:52.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:34:23.122+0000] {processor.py:157} INFO - Started process (PID=12792) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:23.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:34:23.124+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:34:23.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:23.144+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:34:23.139+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:34:23.145+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:23.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:34:53.685+0000] {processor.py:157} INFO - Started process (PID=12844) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:53.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:34:53.687+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:34:53.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:53.707+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:34:53.702+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:34:53.708+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:34:53.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:35:24.155+0000] {processor.py:157} INFO - Started process (PID=12896) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:24.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:35:24.157+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:35:24.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:24.178+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:35:24.173+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:35:24.179+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:24.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:35:54.555+0000] {processor.py:157} INFO - Started process (PID=12948) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:54.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:35:54.557+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:35:54.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:54.576+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:35:54.572+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:35:54.577+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:35:54.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:36:24.987+0000] {processor.py:157} INFO - Started process (PID=13000) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:24.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:36:24.989+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:36:24.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:25.011+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:36:25.006+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:36:25.012+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:25.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T17:36:55.081+0000] {processor.py:157} INFO - Started process (PID=13052) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:55.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:36:55.083+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:36:55.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:55.107+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:36:55.098+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:36:55.108+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:36:55.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:37:25.528+0000] {processor.py:157} INFO - Started process (PID=13104) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:25.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:37:25.530+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:37:25.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:25.551+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:37:25.546+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:37:25.552+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:25.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:37:56.298+0000] {processor.py:157} INFO - Started process (PID=13150) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:56.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:37:56.300+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:37:56.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:56.321+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:37:56.316+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:37:56.322+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:37:56.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:38:26.471+0000] {processor.py:157} INFO - Started process (PID=13202) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:26.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:38:26.473+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:38:26.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:26.493+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:38:26.488+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:38:26.494+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:26.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:38:56.747+0000] {processor.py:157} INFO - Started process (PID=13254) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:56.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:38:56.749+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:38:56.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:56.769+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:38:56.764+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:38:56.770+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:38:56.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:39:27.355+0000] {processor.py:157} INFO - Started process (PID=13306) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:27.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:39:27.357+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:39:27.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:27.380+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:39:27.372+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:39:27.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:27.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:39:57.697+0000] {processor.py:157} INFO - Started process (PID=13358) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:57.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:39:57.699+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:39:57.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:57.719+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:39:57.714+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:39:57.721+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:39:57.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:40:28.010+0000] {processor.py:157} INFO - Started process (PID=13410) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:28.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:40:28.012+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:40:28.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:28.034+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:40:28.028+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:40:28.035+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:28.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:40:58.664+0000] {processor.py:157} INFO - Started process (PID=13456) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:58.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:40:58.667+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:40:58.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:58.692+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:40:58.685+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:40:58.693+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:40:58.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:41:29.008+0000] {processor.py:157} INFO - Started process (PID=13502) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:29.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:41:29.010+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:41:29.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:29.030+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:41:29.026+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:41:29.031+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:29.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:41:59.317+0000] {processor.py:157} INFO - Started process (PID=13548) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:59.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:41:59.319+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:41:59.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:59.339+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:41:59.335+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:41:59.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:41:59.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:42:29.509+0000] {processor.py:157} INFO - Started process (PID=13931) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:29.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:42:29.514+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:42:29.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:29.556+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:42:29.549+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:42:29.558+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:29.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.082 seconds
[2024-11-01T17:42:59.818+0000] {processor.py:157} INFO - Started process (PID=14084) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:59.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:42:59.822+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:42:59.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:59.882+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:42:59.873+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:42:59.883+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:42:59.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.094 seconds
[2024-11-01T17:43:30.610+0000] {processor.py:157} INFO - Started process (PID=14223) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:43:30.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:43:30.612+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:43:30.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:43:30.634+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:43:30.629+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:43:30.635+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:43:30.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:44:00.972+0000] {processor.py:157} INFO - Started process (PID=14274) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:00.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:44:00.974+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:44:00.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:00.995+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:44:00.990+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:44:00.996+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:01.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:44:31.356+0000] {processor.py:157} INFO - Started process (PID=14325) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:31.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:44:31.358+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:44:31.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:31.378+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:44:31.373+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:44:31.379+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:44:31.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:45:01.835+0000] {processor.py:157} INFO - Started process (PID=14376) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:01.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:45:01.837+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:45:01.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:01.858+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:45:01.853+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:45:01.859+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:01.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:45:32.190+0000] {processor.py:157} INFO - Started process (PID=14427) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:32.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:45:32.192+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:45:32.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:32.211+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:45:32.207+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:45:32.212+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:45:32.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:46:02.504+0000] {processor.py:157} INFO - Started process (PID=14478) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:02.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:46:02.507+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:46:02.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:02.528+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:46:02.523+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:46:02.529+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:02.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T17:46:32.794+0000] {processor.py:157} INFO - Started process (PID=14529) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:32.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:46:32.796+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:46:32.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:32.816+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:46:32.812+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:46:32.817+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:46:32.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:47:03.196+0000] {processor.py:157} INFO - Started process (PID=14580) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:03.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:47:03.198+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:47:03.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:03.218+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:47:03.214+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:47:03.219+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:03.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:47:33.713+0000] {processor.py:157} INFO - Started process (PID=14636) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:33.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:47:33.715+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:47:33.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:33.742+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:47:33.736+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:47:33.743+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:47:33.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T17:48:04.331+0000] {processor.py:157} INFO - Started process (PID=14692) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:04.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:48:04.333+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:48:04.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:04.358+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:48:04.353+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:48:04.360+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:04.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.051 seconds
[2024-11-01T17:48:34.858+0000] {processor.py:157} INFO - Started process (PID=14748) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:34.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:48:34.860+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:48:34.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:34.884+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:48:34.879+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:48:34.885+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:48:34.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.052 seconds
[2024-11-01T17:49:05.288+0000] {processor.py:157} INFO - Started process (PID=14804) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:05.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:49:05.290+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:49:05.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:05.312+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:49:05.307+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:49:05.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:05.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:49:35.925+0000] {processor.py:157} INFO - Started process (PID=14870) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:35.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:49:35.927+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:49:35.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:35.946+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:49:35.942+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:49:35.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:49:35.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:50:06.325+0000] {processor.py:157} INFO - Started process (PID=14926) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:06.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:50:06.327+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:50:06.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:06.348+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:50:06.343+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:50:06.349+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:06.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:50:36.714+0000] {processor.py:157} INFO - Started process (PID=14982) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:36.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:50:36.716+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:50:36.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:36.735+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:50:36.731+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:50:36.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:50:36.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:51:07.067+0000] {processor.py:157} INFO - Started process (PID=15038) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:07.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:51:07.069+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:51:07.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:07.089+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:51:07.085+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:51:07.090+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:07.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:51:37.441+0000] {processor.py:157} INFO - Started process (PID=15094) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:37.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:51:37.443+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:51:37.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:37.465+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:51:37.461+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:51:37.467+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:51:37.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:52:07.918+0000] {processor.py:157} INFO - Started process (PID=15150) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:07.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:52:07.919+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:52:07.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:07.940+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:52:07.935+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:52:07.941+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:07.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:52:38.275+0000] {processor.py:157} INFO - Started process (PID=15206) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:38.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:52:38.276+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:52:38.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:38.296+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:52:38.292+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:52:38.297+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:52:38.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:53:08.992+0000] {processor.py:157} INFO - Started process (PID=15287) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:08.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:53:08.994+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:53:08.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:09.017+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:53:09.011+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:53:09.018+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:09.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:53:39.882+0000] {processor.py:157} INFO - Started process (PID=15343) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:39.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:53:39.884+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:53:39.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:39.907+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:53:39.902+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:53:39.908+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:53:39.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T17:54:10.305+0000] {processor.py:157} INFO - Started process (PID=15404) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:10.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:54:10.307+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:54:10.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:10.326+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:54:10.322+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:54:10.327+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:10.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:54:40.648+0000] {processor.py:157} INFO - Started process (PID=15460) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:40.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:54:40.650+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:54:40.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:40.670+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:54:40.666+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:54:40.671+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:54:40.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:55:11.186+0000] {processor.py:157} INFO - Started process (PID=15516) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:11.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:55:11.187+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:55:11.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:11.207+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:55:11.203+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:55:11.208+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:11.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:55:41.585+0000] {processor.py:157} INFO - Started process (PID=15572) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:41.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:55:41.587+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:55:41.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:41.608+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:55:41.604+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:55:41.609+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:55:41.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:56:11.979+0000] {processor.py:157} INFO - Started process (PID=15628) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:11.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:56:11.981+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:56:11.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:12.006+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:56:12.000+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:56:12.007+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:12.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.050 seconds
[2024-11-01T17:56:42.371+0000] {processor.py:157} INFO - Started process (PID=15684) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:42.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:56:42.373+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:56:42.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:42.392+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:56:42.388+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:56:42.394+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:56:42.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T17:57:12.876+0000] {processor.py:157} INFO - Started process (PID=15740) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:12.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:57:12.878+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:57:12.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:12.899+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:57:12.895+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:57:12.901+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:12.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T17:57:43.200+0000] {processor.py:157} INFO - Started process (PID=15796) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:43.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:57:43.202+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:57:43.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:43.226+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:57:43.218+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:57:43.227+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:57:43.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.048 seconds
[2024-11-01T17:58:13.876+0000] {processor.py:157} INFO - Started process (PID=15852) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:13.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:58:13.878+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:58:13.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:13.897+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:58:13.893+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:58:13.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:13.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T17:58:44.260+0000] {processor.py:157} INFO - Started process (PID=15908) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:44.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:58:44.262+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:58:44.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:44.282+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:58:44.278+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:58:44.283+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:58:44.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T17:59:14.644+0000] {processor.py:157} INFO - Started process (PID=15964) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:14.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:59:14.646+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:59:14.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:14.666+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:59:14.662+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:59:14.667+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:14.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T17:59:45.409+0000] {processor.py:157} INFO - Started process (PID=16020) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:45.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T17:59:45.411+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:59:45.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:45.435+0000] {logging_mixin.py:151} INFO - [2024-11-01T17:59:45.427+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T17:59:45.436+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T17:59:45.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T18:00:16.284+0000] {processor.py:157} INFO - Started process (PID=16075) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:16.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:00:16.286+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:00:16.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:16.306+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:00:16.302+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:00:16.307+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:16.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:00:46.587+0000] {processor.py:157} INFO - Started process (PID=16131) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:46.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:00:46.589+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:00:46.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:46.610+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:00:46.606+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:00:46.611+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:00:46.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:01:16.923+0000] {processor.py:157} INFO - Started process (PID=16187) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:16.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:01:16.924+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:01:16.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:16.949+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:01:16.942+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:01:16.950+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:16.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T18:01:47.751+0000] {processor.py:157} INFO - Started process (PID=16243) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:47.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:01:47.757+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:01:47.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:47.809+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:01:47.804+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:01:47.810+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:01:47.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.083 seconds
[2024-11-01T18:02:18.181+0000] {processor.py:157} INFO - Started process (PID=16299) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:18.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:02:18.183+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:02:18.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:18.204+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:02:18.200+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:02:18.205+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:18.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:02:48.494+0000] {processor.py:157} INFO - Started process (PID=16355) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:48.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:02:48.496+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:02:48.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:48.518+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:02:48.512+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:02:48.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:02:48.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:03:19.359+0000] {processor.py:157} INFO - Started process (PID=16411) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:19.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:03:19.361+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:03:19.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:19.380+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:03:19.376+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:03:19.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:19.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:03:49.777+0000] {processor.py:157} INFO - Started process (PID=16467) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:49.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:03:49.779+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:03:49.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:49.800+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:03:49.795+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:03:49.801+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:03:49.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:04:20.180+0000] {processor.py:157} INFO - Started process (PID=16523) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:20.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:04:20.181+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:04:20.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:20.202+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:04:20.198+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:04:20.203+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:20.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:04:50.699+0000] {processor.py:157} INFO - Started process (PID=16579) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:50.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:04:50.700+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:04:50.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:50.720+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:04:50.716+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:04:50.721+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:04:50.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:05:21.111+0000] {processor.py:157} INFO - Started process (PID=16635) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:21.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:05:21.113+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:05:21.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:21.144+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:05:21.137+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:05:21.146+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:21.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.058 seconds
[2024-11-01T18:05:51.575+0000] {processor.py:157} INFO - Started process (PID=16691) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:51.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:05:51.577+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:05:51.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:51.602+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:05:51.597+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:05:51.603+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:05:51.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-01T18:06:21.879+0000] {processor.py:157} INFO - Started process (PID=16747) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:21.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:06:21.881+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:06:21.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:21.901+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:06:21.897+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:06:21.902+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:21.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:06:52.336+0000] {processor.py:157} INFO - Started process (PID=16803) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:52.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:06:52.338+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:06:52.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:52.359+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:06:52.354+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:06:52.360+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:06:52.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:07:22.892+0000] {processor.py:157} INFO - Started process (PID=16859) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:22.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:07:22.894+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:07:22.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:22.916+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:07:22.909+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:07:22.917+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:22.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:07:53.709+0000] {processor.py:157} INFO - Started process (PID=16915) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:53.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:07:53.711+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:07:53.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:53.731+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:07:53.727+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:07:53.732+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:07:53.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:08:24.063+0000] {processor.py:157} INFO - Started process (PID=16971) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:24.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:08:24.065+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:08:24.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:24.085+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:08:24.081+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:08:24.086+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:24.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:08:54.477+0000] {processor.py:157} INFO - Started process (PID=17027) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:54.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:08:54.479+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:08:54.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:54.500+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:08:54.495+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:08:54.501+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:08:54.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:09:24.932+0000] {processor.py:157} INFO - Started process (PID=17083) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:24.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:09:24.934+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:09:24.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:24.955+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:09:24.950+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:09:24.956+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:24.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:09:55.361+0000] {processor.py:157} INFO - Started process (PID=17139) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:55.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:09:55.363+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:09:55.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:55.384+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:09:55.379+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:09:55.385+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:09:55.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:10:25.811+0000] {processor.py:157} INFO - Started process (PID=17195) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:25.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:10:25.813+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:10:25.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:25.832+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:10:25.828+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:10:25.833+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:25.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:10:56.197+0000] {processor.py:157} INFO - Started process (PID=17251) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:56.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:10:56.199+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:10:56.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:56.218+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:10:56.215+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:10:56.219+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:10:56.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:11:26.661+0000] {processor.py:157} INFO - Started process (PID=17307) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:26.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:11:26.663+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:11:26.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:26.683+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:11:26.679+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:11:26.684+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:26.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:11:57.154+0000] {processor.py:157} INFO - Started process (PID=17363) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:57.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:11:57.157+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:11:57.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:57.178+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:11:57.173+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:11:57.179+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:11:57.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:12:27.794+0000] {processor.py:157} INFO - Started process (PID=17429) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:27.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:12:27.795+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:12:27.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:27.817+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:12:27.811+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:12:27.818+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:27.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:12:58.630+0000] {processor.py:157} INFO - Started process (PID=17485) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:58.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:12:58.633+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:12:58.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:58.667+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:12:58.657+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:12:58.669+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:12:58.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.067 seconds
[2024-11-01T18:13:29.230+0000] {processor.py:157} INFO - Started process (PID=17541) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:29.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:13:29.232+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:13:29.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:29.252+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:13:29.248+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:13:29.253+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:29.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:13:59.544+0000] {processor.py:157} INFO - Started process (PID=17597) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:59.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:13:59.546+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:13:59.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:59.566+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:13:59.562+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:13:59.571+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:13:59.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T18:14:29.963+0000] {processor.py:157} INFO - Started process (PID=17653) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:14:29.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:14:29.965+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:14:29.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:14:29.985+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:14:29.981+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:14:29.986+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:14:30.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:15:00.832+0000] {processor.py:157} INFO - Started process (PID=17709) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:00.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:15:00.834+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:15:00.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:00.855+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:15:00.849+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:15:00.856+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:00.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:15:31.222+0000] {processor.py:157} INFO - Started process (PID=17765) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:31.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:15:31.224+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:15:31.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:31.243+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:15:31.239+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:15:31.244+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:15:31.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:16:01.337+0000] {processor.py:157} INFO - Started process (PID=17819) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:01.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:16:01.339+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:16:01.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:01.362+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:16:01.355+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:16:01.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:01.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:16:31.440+0000] {processor.py:157} INFO - Started process (PID=17869) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:31.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:16:31.442+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:16:31.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:31.463+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:16:31.458+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:16:31.464+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:16:31.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:17:01.700+0000] {processor.py:157} INFO - Started process (PID=17917) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:01.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:17:01.702+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:17:01.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:01.724+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:17:01.717+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:17:01.725+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:01.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:17:32.608+0000] {processor.py:157} INFO - Started process (PID=17973) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:32.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:17:32.610+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:17:32.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:32.630+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:17:32.626+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:17:32.631+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:17:32.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:18:03.075+0000] {processor.py:157} INFO - Started process (PID=18029) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:03.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:18:03.077+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:18:03.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:03.096+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:18:03.092+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:18:03.097+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:03.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:18:33.535+0000] {processor.py:157} INFO - Started process (PID=18085) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:33.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:18:33.538+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:18:33.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:33.558+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:18:33.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:18:33.559+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:18:33.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:19:03.859+0000] {processor.py:157} INFO - Started process (PID=18141) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:03.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:19:03.861+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:19:03.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:03.881+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:19:03.876+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:19:03.882+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:03.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:19:34.268+0000] {processor.py:157} INFO - Started process (PID=18197) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:34.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:19:34.270+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:19:34.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:34.291+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:19:34.286+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:19:34.292+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:19:34.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:20:04.642+0000] {processor.py:157} INFO - Started process (PID=18253) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:04.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:20:04.644+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:20:04.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:04.665+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:20:04.660+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:20:04.666+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:04.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:20:35.024+0000] {processor.py:157} INFO - Started process (PID=18309) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:35.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:20:35.026+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:20:35.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:35.046+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:20:35.042+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:20:35.047+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:20:35.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:21:05.458+0000] {processor.py:157} INFO - Started process (PID=18365) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:05.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:21:05.460+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:21:05.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:05.480+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:21:05.476+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:21:05.481+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:05.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:21:35.960+0000] {processor.py:157} INFO - Started process (PID=18421) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:35.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:21:35.961+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:21:35.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:35.984+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:21:35.979+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:21:35.985+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:21:36.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:22:06.343+0000] {processor.py:157} INFO - Started process (PID=18477) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:06.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:22:06.345+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:22:06.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:06.365+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:22:06.361+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:22:06.366+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:06.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:22:36.799+0000] {processor.py:157} INFO - Started process (PID=18533) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:36.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:22:36.800+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:22:36.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:36.820+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:22:36.816+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:22:36.822+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:22:36.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:23:07.200+0000] {processor.py:157} INFO - Started process (PID=18783) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:07.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:23:07.202+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:23:07.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:07.223+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:23:07.219+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:23:07.224+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:07.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T18:23:37.779+0000] {processor.py:157} INFO - Started process (PID=18839) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:37.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:23:37.781+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:23:37.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:37.802+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:23:37.797+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:23:37.803+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:23:37.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:24:08.216+0000] {processor.py:157} INFO - Started process (PID=18895) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:08.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:24:08.218+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:24:08.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:08.239+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:24:08.235+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:24:08.240+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:08.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.046 seconds
[2024-11-01T18:24:38.581+0000] {processor.py:157} INFO - Started process (PID=18951) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:38.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:24:38.583+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:24:38.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:38.606+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:24:38.601+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:24:38.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:24:38.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.049 seconds
[2024-11-01T18:25:09.526+0000] {processor.py:157} INFO - Started process (PID=19012) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:09.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:25:09.528+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:25:09.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:09.548+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:25:09.544+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:25:09.549+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:09.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:25:39.906+0000] {processor.py:157} INFO - Started process (PID=19068) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:39.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:25:39.908+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:25:39.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:39.927+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:25:39.923+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:25:39.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:25:39.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:26:10.274+0000] {processor.py:157} INFO - Started process (PID=19124) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:10.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:26:10.276+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:26:10.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:10.296+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:26:10.291+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:26:10.297+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:10.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:26:40.712+0000] {processor.py:157} INFO - Started process (PID=19180) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:40.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:26:40.713+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:26:40.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:40.732+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:26:40.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:26:40.733+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:26:40.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:27:11.230+0000] {processor.py:157} INFO - Started process (PID=19236) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:11.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:27:11.232+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:27:11.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:11.251+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:27:11.247+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:27:11.252+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:11.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:27:41.653+0000] {processor.py:157} INFO - Started process (PID=19292) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:41.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:27:41.655+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:27:41.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:41.675+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:27:41.671+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:27:41.676+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:27:41.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:28:12.297+0000] {processor.py:157} INFO - Started process (PID=19581) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:12.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:28:12.299+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:28:12.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:12.319+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:28:12.315+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:28:12.320+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:12.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:28:42.696+0000] {processor.py:157} INFO - Started process (PID=19637) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:42.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:28:42.698+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:28:42.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:42.718+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:28:42.714+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:28:42.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:28:42.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
[2024-11-01T18:29:13.141+0000] {processor.py:157} INFO - Started process (PID=19693) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:13.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:29:13.142+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:29:13.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:13.163+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:29:13.158+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:29:13.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:13.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T18:29:43.445+0000] {processor.py:157} INFO - Started process (PID=19749) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:43.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:29:43.447+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:29:43.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:43.469+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:29:43.463+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:29:43.470+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:29:43.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:30:13.802+0000] {processor.py:157} INFO - Started process (PID=19805) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:13.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:30:13.803+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:30:13.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:13.823+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:30:13.819+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:30:13.824+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:13.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:30:44.134+0000] {processor.py:157} INFO - Started process (PID=19861) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:44.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:30:44.135+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:30:44.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:44.155+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:30:44.151+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:30:44.156+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:30:44.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:31:14.549+0000] {processor.py:157} INFO - Started process (PID=19917) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:14.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:31:14.551+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:31:14.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:14.571+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:31:14.567+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:31:14.572+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:14.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:31:44.965+0000] {processor.py:157} INFO - Started process (PID=19973) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:44.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:31:44.967+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:31:44.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:44.986+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:31:44.982+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:31:44.987+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:31:45.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.039 seconds
[2024-11-01T18:32:15.576+0000] {processor.py:157} INFO - Started process (PID=20029) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:15.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:32:15.578+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:32:15.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:15.598+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:32:15.594+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:32:15.599+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:15.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:32:46.024+0000] {processor.py:157} INFO - Started process (PID=20085) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:46.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:32:46.025+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:32:46.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:46.045+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:32:46.041+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:32:46.046+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:32:46.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:33:16.901+0000] {processor.py:157} INFO - Started process (PID=20135) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:16.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:33:16.903+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:33:16.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:16.923+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:33:16.918+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:33:16.924+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:16.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:33:47.147+0000] {processor.py:157} INFO - Started process (PID=20191) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:47.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:33:47.149+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:33:47.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:47.169+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:33:47.164+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:33:47.170+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:33:47.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:34:17.505+0000] {processor.py:157} INFO - Started process (PID=20247) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:17.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:34:17.506+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:34:17.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:17.527+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:34:17.522+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:34:17.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:17.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:34:48.267+0000] {processor.py:157} INFO - Started process (PID=20303) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:48.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:34:48.269+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:34:48.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:48.289+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:34:48.285+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:34:48.291+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:34:48.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T18:35:18.777+0000] {processor.py:157} INFO - Started process (PID=20359) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:18.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:35:18.779+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:35:18.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:18.799+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:35:18.795+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:35:18.800+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:18.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T18:35:49.204+0000] {processor.py:157} INFO - Started process (PID=20415) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:49.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:35:49.206+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:35:49.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:49.230+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:35:49.224+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:35:49.232+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:35:49.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.062 seconds
[2024-11-01T18:36:19.587+0000] {processor.py:157} INFO - Started process (PID=20471) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:19.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:36:19.589+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:36:19.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:19.615+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:36:19.611+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:36:19.616+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:19.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T18:36:49.953+0000] {processor.py:157} INFO - Started process (PID=20527) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:49.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:36:49.955+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:36:49.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:49.975+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:36:49.971+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:36:49.977+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:36:49.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:37:20.472+0000] {processor.py:157} INFO - Started process (PID=20583) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:20.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:37:20.473+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:37:20.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:20.493+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:37:20.489+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:37:20.494+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:20.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:37:50.810+0000] {processor.py:157} INFO - Started process (PID=20639) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:50.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:37:50.812+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:37:50.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:50.831+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:37:50.827+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:37:50.832+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:37:50.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:38:21.261+0000] {processor.py:157} INFO - Started process (PID=20695) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:21.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:38:21.263+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:38:21.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:21.283+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:38:21.278+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:38:21.284+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:21.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:38:51.684+0000] {processor.py:157} INFO - Started process (PID=20751) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:51.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:38:51.685+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:38:51.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:51.706+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:38:51.701+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:38:51.707+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:38:51.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:39:22.561+0000] {processor.py:157} INFO - Started process (PID=20807) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:22.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:39:22.563+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:39:22.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:22.582+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:39:22.578+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:39:22.583+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:22.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:39:52.956+0000] {processor.py:157} INFO - Started process (PID=20863) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:52.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:39:52.958+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:39:52.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:52.977+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:39:52.973+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:39:52.978+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:39:52.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:40:23.384+0000] {processor.py:157} INFO - Started process (PID=20919) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:23.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:40:23.386+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:40:23.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:23.406+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:40:23.401+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:40:23.407+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:23.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:40:53.775+0000] {processor.py:157} INFO - Started process (PID=20975) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:53.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:40:53.777+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:40:53.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:53.796+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:40:53.792+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:40:53.797+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:40:53.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:41:24.186+0000] {processor.py:157} INFO - Started process (PID=21031) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:24.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:41:24.188+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:41:24.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:24.209+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:41:24.205+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:41:24.211+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:24.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:41:54.633+0000] {processor.py:157} INFO - Started process (PID=21087) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:54.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:41:54.635+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:41:54.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:54.655+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:41:54.650+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:41:54.656+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:41:54.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:42:25.173+0000] {processor.py:157} INFO - Started process (PID=21143) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:25.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:42:25.175+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:42:25.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:25.194+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:42:25.190+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:42:25.195+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:25.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:42:55.549+0000] {processor.py:157} INFO - Started process (PID=21199) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:55.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:42:55.551+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:42:55.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:55.570+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:42:55.566+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:42:55.571+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:42:55.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:43:25.974+0000] {processor.py:157} INFO - Started process (PID=21255) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:25.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:43:25.976+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:43:25.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:25.996+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:43:25.992+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:43:25.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:26.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:43:56.384+0000] {processor.py:157} INFO - Started process (PID=21311) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:56.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:43:56.385+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:43:56.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:56.405+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:43:56.401+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:43:56.406+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:43:56.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:44:26.823+0000] {processor.py:157} INFO - Started process (PID=21367) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:26.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:44:26.826+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:44:26.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:26.845+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:44:26.841+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:44:26.846+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:26.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:44:57.293+0000] {processor.py:157} INFO - Started process (PID=21423) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:57.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:44:57.295+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:44:57.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:57.317+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:44:57.312+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:44:57.318+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:44:57.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.044 seconds
[2024-11-01T18:45:27.706+0000] {processor.py:157} INFO - Started process (PID=21479) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:27.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:45:27.707+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:45:27.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:27.727+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:45:27.723+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:45:27.728+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:27.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:45:58.100+0000] {processor.py:157} INFO - Started process (PID=21535) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:58.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:45:58.102+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:45:58.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:58.121+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:45:58.117+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:45:58.122+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:45:58.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:46:28.372+0000] {processor.py:157} INFO - Started process (PID=21591) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:28.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:46:28.374+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:46:28.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:28.394+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:46:28.390+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:46:28.395+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:28.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:46:58.705+0000] {processor.py:157} INFO - Started process (PID=21647) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:58.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:46:58.707+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:46:58.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:58.726+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:46:58.721+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:46:58.727+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:46:58.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:47:29.202+0000] {processor.py:157} INFO - Started process (PID=21703) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:29.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:47:29.204+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:47:29.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:29.224+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:47:29.219+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:47:29.225+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:29.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:47:59.615+0000] {processor.py:157} INFO - Started process (PID=21759) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:59.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:47:59.617+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:47:59.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:59.638+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:47:59.634+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:47:59.639+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:47:59.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:48:30.036+0000] {processor.py:157} INFO - Started process (PID=21815) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:48:30.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:48:30.038+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:48:30.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:48:30.058+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:48:30.054+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:48:30.059+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:48:30.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:49:00.504+0000] {processor.py:157} INFO - Started process (PID=21871) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:00.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:49:00.506+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:49:00.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:00.525+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:49:00.521+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:49:00.526+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:00.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:49:31.356+0000] {processor.py:157} INFO - Started process (PID=21921) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:31.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:49:31.358+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:49:31.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:31.377+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:49:31.373+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:49:31.379+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:49:31.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:50:01.612+0000] {processor.py:157} INFO - Started process (PID=21977) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:01.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:50:01.614+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:50:01.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:01.633+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:50:01.629+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:50:01.634+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:01.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:50:32.027+0000] {processor.py:157} INFO - Started process (PID=22033) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:32.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:50:32.029+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:50:32.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:32.048+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:50:32.044+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:50:32.049+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:50:32.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:51:02.425+0000] {processor.py:157} INFO - Started process (PID=22089) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:02.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:51:02.427+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:51:02.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:02.447+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:51:02.443+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:51:02.448+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:02.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:51:32.725+0000] {processor.py:157} INFO - Started process (PID=22145) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:32.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:51:32.727+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:51:32.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:32.746+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:51:32.742+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:51:32.747+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:51:32.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:52:03.179+0000] {processor.py:157} INFO - Started process (PID=22201) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:03.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:52:03.181+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:52:03.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:03.201+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:52:03.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:52:03.202+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:03.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:52:33.376+0000] {processor.py:157} INFO - Started process (PID=22257) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:33.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:52:33.378+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:52:33.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:33.399+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:52:33.395+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:52:33.400+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:52:33.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T18:53:03.991+0000] {processor.py:157} INFO - Started process (PID=22313) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:03.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:53:03.993+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:53:03.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:04.013+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:53:04.008+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:53:04.014+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:04.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:53:34.326+0000] {processor.py:157} INFO - Started process (PID=22369) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:34.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:53:34.328+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:53:34.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:34.347+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:53:34.343+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:53:34.348+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:53:34.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:54:04.789+0000] {processor.py:157} INFO - Started process (PID=22425) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:04.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:54:04.791+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:54:04.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:04.811+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:54:04.807+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:54:04.813+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:04.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:54:35.215+0000] {processor.py:157} INFO - Started process (PID=22481) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:35.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:54:35.217+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:54:35.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:35.236+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:54:35.232+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:54:35.238+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:54:35.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:55:05.637+0000] {processor.py:157} INFO - Started process (PID=22537) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:05.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:55:05.639+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:55:05.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:05.659+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:55:05.654+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:55:05.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:05.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T18:55:36.052+0000] {processor.py:157} INFO - Started process (PID=22593) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:36.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:55:36.054+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:55:36.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:36.074+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:55:36.069+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:55:36.075+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:55:36.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:56:06.456+0000] {processor.py:157} INFO - Started process (PID=22649) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:06.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:56:06.458+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:56:06.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:06.477+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:56:06.473+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:56:06.478+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:06.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T18:56:36.873+0000] {processor.py:157} INFO - Started process (PID=22705) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:36.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:56:36.875+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:56:36.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:36.894+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:56:36.890+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:56:36.895+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:56:36.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.039 seconds
[2024-11-01T18:57:07.228+0000] {processor.py:157} INFO - Started process (PID=22761) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:07.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:57:07.230+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:57:07.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:07.250+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:57:07.245+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:57:07.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:07.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:57:37.739+0000] {processor.py:157} INFO - Started process (PID=22817) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:37.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:57:37.741+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:57:37.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:37.761+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:57:37.757+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:57:37.762+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:57:37.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:58:08.129+0000] {processor.py:157} INFO - Started process (PID=22873) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:08.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:58:08.131+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:58:08.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:08.151+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:58:08.146+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:58:08.152+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:08.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:58:38.512+0000] {processor.py:157} INFO - Started process (PID=22929) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:38.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:58:38.514+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:58:38.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:38.534+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:58:38.529+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:58:38.535+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:58:38.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:59:08.877+0000] {processor.py:157} INFO - Started process (PID=22985) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:08.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:59:08.879+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:59:08.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:08.899+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:59:08.894+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:59:08.900+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:08.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T18:59:39.292+0000] {processor.py:157} INFO - Started process (PID=23041) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:39.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T18:59:39.293+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:59:39.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:39.313+0000] {logging_mixin.py:151} INFO - [2024-11-01T18:59:39.308+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T18:59:39.314+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T18:59:39.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.041 seconds
[2024-11-01T19:00:09.772+0000] {processor.py:157} INFO - Started process (PID=23097) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:09.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T19:00:09.774+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:00:09.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:09.795+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:00:09.790+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T19:00:09.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:09.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.043 seconds
[2024-11-01T19:00:40.156+0000] {processor.py:157} INFO - Started process (PID=23153) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:40.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T19:00:40.158+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:00:40.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:40.178+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:00:40.174+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T19:00:40.179+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T19:00:40.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.042 seconds
[2024-11-01T19:01:10.570+0000] {processor.py:157} INFO - Started process (PID=23209) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:10.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T19:01:10.573+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:01:10.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:10.595+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:01:10.590+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T19:01:10.596+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:10.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.047 seconds
[2024-11-01T19:01:41.009+0000] {processor.py:157} INFO - Started process (PID=23265) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:41.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T19:01:41.011+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:01:41.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:41.030+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:01:41.026+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T19:01:41.031+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T19:01:41.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.040 seconds
[2024-11-01T19:02:11.444+0000] {processor.py:157} INFO - Started process (PID=23321) to work on /opt/airflow/dags/test_flow.py
[2024-11-01T19:02:11.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/test_flow.py for tasks to queue
[2024-11-01T19:02:11.446+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:02:11.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/test_flow.py
[2024-11-01T19:02:11.469+0000] {logging_mixin.py:151} INFO - [2024-11-01T19:02:11.464+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/test_flow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/test_flow.py", line 138, in <module>
    merger_data = SparkSubmitOperator(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/task_group.py", line 230, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'clean_movies' has already been added to the DAG
[2024-11-01T19:02:11.470+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/test_flow.py
[2024-11-01T19:02:11.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/test_flow.py took 0.045 seconds
