[2024-11-14T16:24:26.823+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:24:25.126210+00:00 [queued]>
[2024-11-14T16:24:26.833+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:24:25.126210+00:00 [queued]>
[2024-11-14T16:24:26.834+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2024-11-14T16:24:26.852+0000] {taskinstance.py:1382} INFO - Executing <Task(SparkSubmitOperator): merge_id> on 2024-11-14 16:24:25.126210+00:00
[2024-11-14T16:24:26.859+0000] {standard_task_runner.py:57} INFO - Started process 6161 to run task
[2024-11-14T16:24:26.861+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'mergeeeee', 'merge_id', 'manual__2024-11-14T16:24:25.126210+00:00', '--job-id', '273', '--raw', '--subdir', 'DAGS_FOLDER/merge_hihi.py', '--cfg-path', '/tmp/tmpswj5y7p3']
[2024-11-14T16:24:26.864+0000] {standard_task_runner.py:85} INFO - Job 273: Subtask merge_id
[2024-11-14T16:24:26.912+0000] {task_command.py:416} INFO - Running <TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:24:25.126210+00:00 [running]> on host 7ea45ba85247
[2024-11-14T16:24:27.016+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='mergeeeee' AIRFLOW_CTX_TASK_ID='merge_id' AIRFLOW_CTX_EXECUTION_DATE='2024-11-14T16:24:25.126210+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-14T16:24:25.126210+00:00'
[2024-11-14T16:24:27.030+0000] {base.py:73} INFO - Using connection ID 'spark-conn' for task execution.
[2024-11-14T16:24:27.034+0000] {spark_submit.py:403} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog --jars /opt/***/jars/hadoop-aws-3.3.4.jar,/opt/***/jars/s3-2.18.41.jar,/opt/***/jars/aws-java-sdk-1.12.367.jar,/opt/***/jars/delta-core_2.12-2.2.0.jar,/opt/***/jars/delta-storage-2.2.0.jar, --packages org.apache.hadoop:hadoop-aws:3.3.4 --num-executors 2 --total-executor-cores 2 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode client /opt/***/jobs/python/test_merge.py s3a://lakehouse/bronze/keywords.parquet s3a://lakehouse/bronze/movies.parquet s3a://lakehouse/bronze/credits.parquet s3a://lakehouse/merge_data-movies/merged_data s3a://lakehouse/gold/gold_data
[2024-11-14T16:24:27.231+0000] {spark_submit.py:579} INFO - /home/***/.local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2024-11-14T16:24:29.362+0000] {spark_submit.py:579} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-11-14T16:24:29.470+0000] {spark_submit.py:579} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2024-11-14T16:24:29.470+0000] {spark_submit.py:579} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2024-11-14T16:24:29.475+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2024-11-14T16:24:29.477+0000] {spark_submit.py:579} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-39ca816b-b564-41b1-8fd0-50daac403cf2;1.0
[2024-11-14T16:24:29.477+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:24:29.623+0000] {spark_submit.py:579} INFO - found org.apache.hadoop#hadoop-aws;3.3.4 in spark-list
[2024-11-14T16:24:29.655+0000] {spark_submit.py:579} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2024-11-14T16:24:29.686+0000] {spark_submit.py:579} INFO - found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2024-11-14T16:24:29.716+0000] {spark_submit.py:579} INFO - :: resolution report :: resolve 228ms :: artifacts dl 11ms
[2024-11-14T16:24:29.717+0000] {spark_submit.py:579} INFO - :: modules in use:
[2024-11-14T16:24:29.718+0000] {spark_submit.py:579} INFO - com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2024-11-14T16:24:29.719+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws;3.3.4 from spark-list in [default]
[2024-11-14T16:24:29.720+0000] {spark_submit.py:579} INFO - org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2024-11-14T16:24:29.721+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:24:29.721+0000] {spark_submit.py:579} INFO - |                  |            modules            ||   artifacts   |
[2024-11-14T16:24:29.722+0000] {spark_submit.py:579} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-11-14T16:24:29.723+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:24:29.724+0000] {spark_submit.py:579} INFO - |      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
[2024-11-14T16:24:29.724+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:24:29.725+0000] {spark_submit.py:579} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-39ca816b-b564-41b1-8fd0-50daac403cf2
[2024-11-14T16:24:29.725+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:24:29.731+0000] {spark_submit.py:579} INFO - 0 artifacts copied, 3 already retrieved (0kB/7ms)
[2024-11-14T16:24:30.008+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-11-14T16:24:31.826+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO SparkContext: Running Spark version 3.3.2
[2024-11-14T16:24:31.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceUtils: ==============================================================
[2024-11-14T16:24:31.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-11-14T16:24:31.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceUtils: ==============================================================
[2024-11-14T16:24:31.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO SparkContext: Submitted application: MergeData
[2024-11-14T16:24:31.929+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-11-14T16:24:31.954+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
[2024-11-14T16:24:31.957+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-11-14T16:24:32.041+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SecurityManager: Changing view acls to: ***
[2024-11-14T16:24:32.042+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SecurityManager: Changing modify acls to: ***
[2024-11-14T16:24:32.043+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SecurityManager: Changing view acls groups to:
[2024-11-14T16:24:32.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SecurityManager: Changing modify acls groups to:
[2024-11-14T16:24:32.045+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2024-11-14T16:24:32.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO Utils: Successfully started service 'sparkDriver' on port 36721.
[2024-11-14T16:24:32.455+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkEnv: Registering MapOutputTracker
[2024-11-14T16:24:32.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkEnv: Registering BlockManagerMaster
[2024-11-14T16:24:32.513+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-11-14T16:24:32.514+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-11-14T16:24:32.519+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-11-14T16:24:32.547+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-158b8e0c-e774-426e-b449-7123b02cfab4
[2024-11-14T16:24:32.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-11-14T16:24:32.586+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-11-14T16:24:32.842+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-11-14T16:24:32.906+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///opt/***/jars/hadoop-aws-3.3.4.jar at spark://7ea45ba85247:36721/jars/hadoop-aws-3.3.4.jar with timestamp 1731601471813
[2024-11-14T16:24:32.908+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///opt/***/jars/s3-2.18.41.jar at spark://7ea45ba85247:36721/jars/s3-2.18.41.jar with timestamp 1731601471813
[2024-11-14T16:24:32.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///opt/***/jars/aws-java-sdk-1.12.367.jar at spark://7ea45ba85247:36721/jars/aws-java-sdk-1.12.367.jar with timestamp 1731601471813
[2024-11-14T16:24:32.911+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///opt/***/jars/delta-core_2.12-2.2.0.jar at spark://7ea45ba85247:36721/jars/delta-core_2.12-2.2.0.jar with timestamp 1731601471813
[2024-11-14T16:24:32.913+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///opt/***/jars/delta-storage-2.2.0.jar at spark://7ea45ba85247:36721/jars/delta-storage-2.2.0.jar with timestamp 1731601471813
[2024-11-14T16:24:32.913+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:36721/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601471813
[2024-11-14T16:24:32.914+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:36721/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601471813
[2024-11-14T16:24:32.915+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:36721/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601471813
[2024-11-14T16:24:32.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:36721/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601471813
[2024-11-14T16:24:32.920+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-a9f2f13e-d6fb-4740-a7c2-dc428f8d0f08/userFiles-13e71261-720a-4732-8ec5-604a8e9d1548/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2024-11-14T16:24:32.935+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:36721/files/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601471813
[2024-11-14T16:24:32.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:32 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-a9f2f13e-d6fb-4740-a7c2-dc428f8d0f08/userFiles-13e71261-720a-4732-8ec5-604a8e9d1548/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2024-11-14T16:24:33.377+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:36721/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601471813
[2024-11-14T16:24:33.378+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO Utils: Copying /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-a9f2f13e-d6fb-4740-a7c2-dc428f8d0f08/userFiles-13e71261-720a-4732-8ec5-604a8e9d1548/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2024-11-14T16:24:33.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-11-14T16:24:33.602+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.3:7077 after 55 ms (0 ms spent in bootstraps)
[2024-11-14T16:24:33.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241114162433-0007
[2024-11-14T16:24:33.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241114162433-0007/0 on worker-20241114153331-172.21.0.8-42023 (172.21.0.8:42023) with 2 core(s)
[2024-11-14T16:24:33.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20241114162433-0007/0 on hostPort 172.21.0.8:42023 with 2 core(s), 2.0 GiB RAM
[2024-11-14T16:24:33.776+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42445.
[2024-11-14T16:24:33.777+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO NettyBlockTransferService: Server created on 7ea45ba85247:42445
[2024-11-14T16:24:33.780+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-11-14T16:24:33.794+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7ea45ba85247, 42445, None)
[2024-11-14T16:24:33.801+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO BlockManagerMasterEndpoint: Registering block manager 7ea45ba85247:42445 with 434.4 MiB RAM, BlockManagerId(driver, 7ea45ba85247, 42445, None)
[2024-11-14T16:24:33.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7ea45ba85247, 42445, None)
[2024-11-14T16:24:33.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7ea45ba85247, 42445, None)
[2024-11-14T16:24:33.877+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241114162433-0007/0 is now RUNNING
[2024-11-14T16:24:34.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-11-14T16:24:34.336+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-11-14T16:24:34.341+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:34 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2024-11-14T16:24:35.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:35 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2024-11-14T16:24:35.831+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:35 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2024-11-14T16:24:35.831+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:35 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2024-11-14T16:24:36.728+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.8:37702) with ID 0,  ResourceProfileId 0
[2024-11-14T16:24:36.821+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.8:35179 with 1048.8 MiB RAM, BlockManagerId(0, 172.21.0.8, 35179, None)
[2024-11-14T16:24:37.677+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:37 INFO InMemoryFileIndex: It took 101 ms to list leaf files for 1 paths.
[2024-11-14T16:24:38.317+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:38.336+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:24:38.338+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:38.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:38.341+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:38.350+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:38.418+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 106.1 KiB, free 434.3 MiB)
[2024-11-14T16:24:38.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2024-11-14T16:24:38.497+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7ea45ba85247:42445 (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:24:38.503+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:38.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:24:38.530+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-11-14T16:24:39.721+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4591 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:40.125+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.8:35179 (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:41.812+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2130 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:24:41.814+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-11-14T16:24:41.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 3.453 s
[2024-11-14T16:24:41.827+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:24:41.827+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2024-11-14T16:24:41.831+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:41 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 3.513239 s
[2024-11-14T16:24:42.350+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:42 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 7ea45ba85247:42445 in memory (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:24:42.357+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:42 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.21.0.8:35179 in memory (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:44.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
[2024-11-14T16:24:44.579+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
[2024-11-14T16:24:44.613+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:44.614+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Got job 1 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:24:44.614+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Final stage: ResultStage 1 (load at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:44.615+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:44.616+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:44.616+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:44.626+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 106.3 KiB, free 434.3 MiB)
[2024-11-14T16:24:44.638+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2024-11-14T16:24:44.639+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7ea45ba85247:42445 (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:24:44.640+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:44.642+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:24:44.643+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2024-11-14T16:24:44.645+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4590 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:44.684+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.8:35179 (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:44.744+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 99 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:24:44.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2024-11-14T16:24:44.746+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: ResultStage 1 (load at NativeMethodAccessorImpl.java:0) finished in 0.128 s
[2024-11-14T16:24:44.747+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:24:44.748+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2024-11-14T16:24:44.748+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:44 INFO DAGScheduler: Job 1 finished: load at NativeMethodAccessorImpl.java:0, took 0.134489 s
[2024-11-14T16:24:45.364+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7ea45ba85247:42445 in memory (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:24:45.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.21.0.8:35179 in memory (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:45.513+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:24:45.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:24:45.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, id: bigint>
[2024-11-14T16:24:45.906+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO CodeGenerator: Code generated in 152.038864 ms
[2024-11-14T16:24:45.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO CodeGenerator: Code generated in 25.215333 ms
[2024-11-14T16:24:45.990+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 206.0 KiB, free 434.2 MiB)
[2024-11-14T16:24:46.004+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 434.2 MiB)
[2024-11-14T16:24:46.006+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7ea45ba85247:42445 (size: 36.1 KiB, free: 434.4 MiB)
[2024-11-14T16:24:46.008+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:46.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:24:46.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:46.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:24:46.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:46.081+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:46.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:46.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:46.162+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.9 KiB, free 434.1 MiB)
[2024-11-14T16:24:46.173+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 434.1 MiB)
[2024-11-14T16:24:46.173+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7ea45ba85247:42445 (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:24:46.174+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:46.175+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:24:46.176+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2024-11-14T16:24:46.183+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:46.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.8:35179 (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:46.861+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.8:35179 (size: 36.1 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:47.594+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1415 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:24:47.595+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-11-14T16:24:47.596+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.510 s
[2024-11-14T16:24:47.597+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:24:47.599+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2024-11-14T16:24:47.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 1.519166 s
[2024-11-14T16:24:47.642+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 INFO CodeGenerator: Code generated in 19.416438 ms
[2024-11-14T16:24:47.698+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:24:47.698+0000] {spark_submit.py:579} INFO - |id   |cast_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |director                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
[2024-11-14T16:24:47.699+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:24:47.700+0000] {spark_submit.py:579} INFO - |862  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.700+0000] {spark_submit.py:579} INFO - |8844 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.701+0000] {spark_submit.py:579} INFO - |15602|[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:24:47.702+0000] {spark_submit.py:579} INFO - |31357|[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |
[2024-11-14T16:24:47.703+0000] {spark_submit.py:579} INFO - |11862|[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |
[2024-11-14T16:24:47.703+0000] {spark_submit.py:579} INFO - |949  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.705+0000] {spark_submit.py:579} INFO - |11860|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.707+0000] {spark_submit.py:579} INFO - |45325|[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |
[2024-11-14T16:24:47.707+0000] {spark_submit.py:579} INFO - |9091 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.708+0000] {spark_submit.py:579} INFO - |710  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.709+0000] {spark_submit.py:579} INFO - |9087 |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |
[2024-11-14T16:24:47.710+0000] {spark_submit.py:579} INFO - |12110|[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:24:47.711+0000] {spark_submit.py:579} INFO - |21032|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.711+0000] {spark_submit.py:579} INFO - |10858|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|
[2024-11-14T16:24:47.712+0000] {spark_submit.py:579} INFO - |1408 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.713+0000] {spark_submit.py:579} INFO - |524  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.713+0000] {spark_submit.py:579} INFO - |4584 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.714+0000] {spark_submit.py:579} INFO - |5    |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.714+0000] {spark_submit.py:579} INFO - |9273 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.715+0000] {spark_submit.py:579} INFO - |11517|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:24:47.715+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:24:47.716+0000] {spark_submit.py:579} INFO - only showing top 20 rows
[2024-11-14T16:24:47.717+0000] {spark_submit.py:579} INFO - 
[2024-11-14T16:24:47.867+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:47 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2024-11-14T16:24:48.168+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty
[2024-11-14T16:24:48.202+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 7ea45ba85247:42445 in memory (size: 36.1 KiB, free: 434.4 MiB)
[2024-11-14T16:24:48.206+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.21.0.8:35179 in memory (size: 36.1 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:48.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 7ea45ba85247:42445 in memory (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:24:48.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.21.0.8:35179 in memory (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:48.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO InitialSnapshot: [tableId=3569058b-ea48-40d9-b80c-33bed7959b54] Created snapshot InitialSnapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=-1, metadata=Metadata(9612275a-79ea-49be-a8cd-2bd9bf688e5c,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601488423)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:24:48.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO DeltaLog: No delta log found for the Delta table at s3a://lakehouse/merge_data-movies/merged_data/_delta_log
[2024-11-14T16:24:48.567+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO InitialSnapshot: [tableId=9612275a-79ea-49be-a8cd-2bd9bf688e5c] Created snapshot InitialSnapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=-1, metadata=Metadata(35f78735-bc99-49b9-a070-ed52e53e7463,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601488566)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:24:48.614+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:48 INFO OptimisticTransaction: [tableId=35f78735,txnId=287943c3] Updated metadata from - to Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594))
[2024-11-14T16:24:49.511+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:24:49.511+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:24:49.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:24:49.564+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(keywords),IsNotNull(id)
[2024-11-14T16:24:49.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(keywords#1),isnotnull(id#0L)
[2024-11-14T16:24:49.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Output Data Schema: struct<id: bigint, keywords: string>
[2024-11-14T16:24:49.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:24:49.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(transform(from_json(ArrayType(StructType(StructField(name,StringType,true)),true), cast#322, Some(Etc/UTC)), lambdafunction(lambda x#334.name, lambda x#334, false))),isnotnull(id#324L)
[2024-11-14T16:24:49.572+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, crew: string, id: bigint ... 1 more fields>
[2024-11-14T16:24:49.731+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DeltaParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2024-11-14T16:24:49.819+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:24:49.876+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO CodeGenerator: Code generated in 36.947339 ms
[2024-11-14T16:24:49.881+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 206.0 KiB, free 434.2 MiB)
[2024-11-14T16:24:49.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 434.2 MiB)
[2024-11-14T16:24:49.901+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7ea45ba85247:42445 (size: 36.1 KiB, free: 434.4 MiB)
[2024-11-14T16:24:49.904+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO SparkContext: Created broadcast 4 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:49.908+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:24:49.971+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:24:49.972+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Registering RDD 13 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2024-11-14T16:24:49.977+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Got map stage job 3 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:24:49.977+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:49.978+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:49.979+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:49.981+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:49 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:50.000+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 31.5 KiB, free 434.1 MiB)
[2024-11-14T16:24:50.015+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 434.1 MiB)
[2024-11-14T16:24:50.017+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7ea45ba85247:42445 (size: 14.0 KiB, free: 434.4 MiB)
[2024-11-14T16:24:50.018+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:50.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:24:50.021+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2024-11-14T16:24:50.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4903 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:50.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO CodeGenerator: Code generated in 68.258045 ms
[2024-11-14T16:24:50.065+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.8:35179 (size: 14.0 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:50.081+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO CodeGenerator: Code generated in 19.850104 ms
[2024-11-14T16:24:50.085+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 206.1 KiB, free 433.9 MiB)
[2024-11-14T16:24:50.101+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 433.9 MiB)
[2024-11-14T16:24:50.103+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7ea45ba85247:42445 (size: 36.1 KiB, free: 434.3 MiB)
[2024-11-14T16:24:50.105+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO SparkContext: Created broadcast 6 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:50.107+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:24:50.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Registering RDD 21 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2024-11-14T16:24:50.146+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Got map stage job 4 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:24:50.147+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:50.148+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:50.148+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:50.149+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:50.163+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 49.7 KiB, free 433.8 MiB)
[2024-11-14T16:24:50.172+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 433.8 MiB)
[2024-11-14T16:24:50.175+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7ea45ba85247:42445 (size: 19.8 KiB, free: 434.3 MiB)
[2024-11-14T16:24:50.178+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:50.179+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[21] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:24:50.180+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0
[2024-11-14T16:24:50.182+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:50.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.8:35179 (size: 19.8 KiB, free: 1048.8 MiB)
[2024-11-14T16:24:50.358+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.8:35179 (size: 36.1 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:50.461+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.8:35179 (size: 36.1 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:51.104+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:51.108+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1085 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:24:51.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2024-11-14T16:24:51.111+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: ShuffleMapStage 3 (save at NativeMethodAccessorImpl.java:0) finished in 1.127 s
[2024-11-14T16:24:51.112+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:24:51.113+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: running: Set(ShuffleMapStage 4)
[2024-11-14T16:24:51.114+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:24:51.115+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: failed: Set()
[2024-11-14T16:24:51.157+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:24:51.158+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:24:51.159+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:24:51.185+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1480508, minimum partition size: 1048576
[2024-11-14T16:24:51.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 129 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:24:51.312+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:24:51.314+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:24:51.315+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:24:51.316+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
[2024-11-14T16:24:51.317+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:51.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:24:51.339+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.2 KiB, free 433.8 MiB)
[2024-11-14T16:24:51.349+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 433.8 MiB)
[2024-11-14T16:24:51.352+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7ea45ba85247:42445 (size: 13.8 KiB, free: 434.3 MiB)
[2024-11-14T16:24:51.353+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:51.354+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 7ea45ba85247:42445 in memory (size: 14.0 KiB, free: 434.3 MiB)
[2024-11-14T16:24:51.355+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:24:51.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
[2024-11-14T16:24:51.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.21.0.8:35179 in memory (size: 14.0 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:51.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:51.405+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.8:35179 (size: 13.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:51.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.8:37702
[2024-11-14T16:24:52.299+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Added taskresult_6 in memory on 172.21.0.8:35179 (size: 2.5 MiB, free: 1046.2 MiB)
[2024-11-14T16:24:52.310+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:52.348+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TransportClientFactory: Successfully created connection to /172.21.0.8:35179 after 3 ms (0 ms spent in bootstraps)
[2024-11-14T16:24:52.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 1054 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:24:52.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Removed taskresult_6 on 172.21.0.8:35179 in memory (size: 2.5 MiB, free: 1048.7 MiB)
[2024-11-14T16:24:52.693+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Added taskresult_7 in memory on 172.21.0.8:35179 (size: 2.5 MiB, free: 1046.2 MiB)
[2024-11-14T16:24:52.726+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 416 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:24:52.727+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2024-11-14T16:24:52.728+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO DAGScheduler: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.393 s
[2024-11-14T16:24:52.729+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:24:52.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2024-11-14T16:24:52.731+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.416879 s
[2024-11-14T16:24:52.732+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Removed taskresult_7 on 172.21.0.8:35179 in memory (size: 2.5 MiB, free: 1048.7 MiB)
[2024-11-14T16:24:52.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO CodeGenerator: Code generated in 22.814621 ms
[2024-11-14T16:24:52.854+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 7ea45ba85247:42445 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2024-11-14T16:24:52.856+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.8:35179 in memory (size: 13.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:52.937+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 18.0 MiB, free 415.9 MiB)
[2024-11-14T16:24:53.008+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 411.9 MiB)
[2024-11-14T16:24:53.012+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7ea45ba85247:42445 (size: 4.0 MiB, free: 430.3 MiB)
[2024-11-14T16:24:53.015+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_9_piece1 stored as bytes in memory (estimated size 1563.5 KiB, free 410.3 MiB)
[2024-11-14T16:24:53.019+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_9_piece1 in memory on 7ea45ba85247:42445 (size: 1563.5 KiB, free: 428.8 MiB)
[2024-11-14T16:24:53.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:24:53.046+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:24:53.047+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:24:53.048+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:24:53.128+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO CodeGenerator: Code generated in 22.068761 ms
[2024-11-14T16:24:53.163+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO CodeGenerator: Code generated in 22.257063 ms
[2024-11-14T16:24:53.168+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 208.0 KiB, free 410.1 MiB)
[2024-11-14T16:24:53.184+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 410.1 MiB)
[2024-11-14T16:24:53.187+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7ea45ba85247:42445 (size: 36.5 KiB, free: 428.7 MiB)
[2024-11-14T16:24:53.189+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO SparkContext: Created broadcast 10 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:53.191+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10691623 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:24:53.227+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Registering RDD 30 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2024-11-14T16:24:53.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Got map stage job 6 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:24:53.229+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:53.230+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:24:53.231+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:53.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:53.311+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 51.6 KiB, free 410.0 MiB)
[2024-11-14T16:24:53.322+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 410.0 MiB)
[2024-11-14T16:24:53.326+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7ea45ba85247:42445 (size: 19.5 KiB, free: 428.7 MiB)
[2024-11-14T16:24:53.327+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:53.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:24:53.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
[2024-11-14T16:24:53.331+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:53.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.21.0.8:35179 (size: 19.5 KiB, free: 1048.7 MiB)
[2024-11-14T16:24:53.627+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_9_piece1 in memory on 172.21.0.8:35179 (size: 1563.5 KiB, free: 1047.2 MiB)
[2024-11-14T16:24:53.656+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.21.0.8:35179 (size: 4.0 MiB, free: 1043.2 MiB)
[2024-11-14T16:24:53.712+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:53 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.21.0.8:35179 (size: 36.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:24:55.203+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:55.204+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5022 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:24:55.205+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2024-11-14T16:24:55.205+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: ShuffleMapStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 5.055 s
[2024-11-14T16:24:55.206+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:24:55.207+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: running: Set(ShuffleMapStage 7)
[2024-11-14T16:24:55.208+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:24:55.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: failed: Set()
[2024-11-14T16:24:55.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 5348362, minimum partition size: 1048576
[2024-11-14T16:24:55.253+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:24:55.307+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO CodeGenerator: Code generated in 45.978123 ms
[2024-11-14T16:24:55.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 117 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:24:55.326+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Registering RDD 33 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2024-11-14T16:24:55.327+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Got map stage job 7 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:24:55.327+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:55.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2024-11-14T16:24:55.329+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:55.330+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[33] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:55.345+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 49.8 KiB, free 410.0 MiB)
[2024-11-14T16:24:55.353+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.1 KiB, free 410.0 MiB)
[2024-11-14T16:24:55.354+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7ea45ba85247:42445 (size: 20.1 KiB, free: 428.7 MiB)
[2024-11-14T16:24:55.355+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:55.357+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[33] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:24:55.358+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
[2024-11-14T16:24:55.361+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:55.395+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.21.0.8:35179 (size: 20.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:24:55.401+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 7ea45ba85247:42445 in memory (size: 19.8 KiB, free: 428.7 MiB)
[2024-11-14T16:24:55.404+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.21.0.8:35179 in memory (size: 19.8 KiB, free: 1043.1 MiB)
[2024-11-14T16:24:55.415+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.21.0.8:37702
[2024-11-14T16:24:55.799+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 11) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:55.800+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 439 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:24:56.060+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 11) in 262 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:24:56.061+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2024-11-14T16:24:56.062+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO DAGScheduler: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0) finished in 0.722 s
[2024-11-14T16:24:56.063+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:24:56.064+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO DAGScheduler: running: Set(ShuffleMapStage 7)
[2024-11-14T16:24:56.065+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:24:56.066+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:56 INFO DAGScheduler: failed: Set()
[2024-11-14T16:24:57.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 3897 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:24:57.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2024-11-14T16:24:57.229+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: ShuffleMapStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 3.997 s
[2024-11-14T16:24:57.230+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:24:57.231+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: running: Set()
[2024-11-14T16:24:57.231+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:24:57.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: failed: Set()
[2024-11-14T16:24:57.253+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO ShufflePartitionsUtil: For shuffle(2, 3), advisory target size: 67108864, actual target size 19218441, minimum partition size: 1048576
[2024-11-14T16:24:57.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 7ea45ba85247:42445 in memory (size: 19.5 KiB, free: 428.7 MiB)
[2024-11-14T16:24:57.370+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.21.0.8:35179 in memory (size: 19.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:24:57.371+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO CodeGenerator: Code generated in 59.965996 ms
[2024-11-14T16:24:57.382+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 7ea45ba85247:42445 in memory (size: 20.1 KiB, free: 428.8 MiB)
[2024-11-14T16:24:57.385+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.21.0.8:35179 in memory (size: 20.1 KiB, free: 1043.2 MiB)
[2024-11-14T16:24:57.411+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO CodeGenerator: Code generated in 26.93572 ms
[2024-11-14T16:24:57.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO CodeGenerator: Code generated in 24.983519 ms
[2024-11-14T16:24:57.761+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:24:57.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Got job 8 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:24:57.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Final stage: ResultStage 13 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:24:57.768+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12, ShuffleMapStage 10)
[2024-11-14T16:24:57.769+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:24:57.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[39] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:24:57.822+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 434.8 KiB, free 409.7 MiB)
[2024-11-14T16:24:57.828+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 153.2 KiB, free 409.6 MiB)
[2024-11-14T16:24:57.832+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7ea45ba85247:42445 (size: 153.2 KiB, free: 428.6 MiB)
[2024-11-14T16:24:57.834+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:24:57.837+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[39] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:24:57.839+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks resource profile 0
[2024-11-14T16:24:57.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4739 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:57.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 13) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4739 bytes) taskResourceAssignments Map()
[2024-11-14T16:24:57.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:57 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.21.0.8:35179 (size: 153.2 KiB, free: 1043.0 MiB)
[2024-11-14T16:24:58.386+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.21.0.8:37702
[2024-11-14T16:24:58.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:24:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.21.0.8:37702
[2024-11-14T16:25:04.733+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 13) in 6886 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:04.734+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 6891 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:04.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2024-11-14T16:25:04.737+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO DAGScheduler: ResultStage 13 (save at NativeMethodAccessorImpl.java:0) finished in 6.958 s
[2024-11-14T16:25:04.738+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:04.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
[2024-11-14T16:25:04.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO DAGScheduler: Job 8 finished: save at NativeMethodAccessorImpl.java:0, took 6.977485 s
[2024-11-14T16:25:04.742+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO FileFormatWriter: Start to commit write Job b626d503-4d71-4c03-b6a7-d8f192f79fc0.
[2024-11-14T16:25:04.744+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO FileFormatWriter: Write Job b626d503-4d71-4c03-b6a7-d8f192f79fc0 committed. Elapsed time: 1 ms.
[2024-11-14T16:25:04.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO FileFormatWriter: Finished processing stats for write job b626d503-4d71-4c03-b6a7-d8f192f79fc0.
[2024-11-14T16:25:04.802+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 7ea45ba85247:42445 in memory (size: 153.2 KiB, free: 428.8 MiB)
[2024-11-14T16:25:04.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.21.0.8:35179 in memory (size: 153.2 KiB, free: 1043.2 MiB)
[2024-11-14T16:25:06.672+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:06 INFO CodeGenerator: Code generated in 264.473334 ms
[2024-11-14T16:25:06.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:06 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2024-11-14T16:25:06.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:06 INFO DAGScheduler: Job 9 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000462 s
[2024-11-14T16:25:06.836+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:06 INFO OptimisticTransaction: [tableId=35f78735,txnId=287943c3] Attempting to commit version 0 with 5 actions with Serializable isolation level
[2024-11-14T16:25:07.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO DeltaLog: Creating a new snapshot v0 for commit version 0
[2024-11-14T16:25:07.424+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO DeltaLog: Loading version 0.
[2024-11-14T16:25:07.533+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO Snapshot: [tableId=35f78735-bc99-49b9-a070-ed52e53e7463] DELTA: Compute snapshot for version: 0
[2024-11-14T16:25:07.604+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 204.4 KiB, free 410.0 MiB)
[2024-11-14T16:25:07.612+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 409.9 MiB)
[2024-11-14T16:25:07.613+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7ea45ba85247:42445 (size: 35.6 KiB, free: 428.7 MiB)
[2024-11-14T16:25:07.615+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO SparkContext: Created broadcast 14 from toString at String.java:2951
[2024-11-14T16:25:07.633+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 6809)
[2024-11-14T16:25:07.925+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:25:07.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:25:07.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:07 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:25:08.114+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO CodeGenerator: Code generated in 98.044776 ms
[2024-11-14T16:25:08.118+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 204.7 KiB, free 409.7 MiB)
[2024-11-14T16:25:08.124+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 409.7 MiB)
[2024-11-14T16:25:08.125+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7ea45ba85247:42445 (size: 35.7 KiB, free: 428.7 MiB)
[2024-11-14T16:25:08.126+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO SparkContext: Created broadcast 15 from toString at String.java:2951
[2024-11-14T16:25:08.155+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:25:08.195+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Registering RDD 47 (toString at String.java:2951) as input to shuffle 4
[2024-11-14T16:25:08.197+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Got map stage job 10 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:25:08.198+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (toString at String.java:2951)
[2024-11-14T16:25:08.199+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:25:08.199+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:08.201+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[47] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:08.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 124.3 KiB, free 409.6 MiB)
[2024-11-14T16:25:08.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 409.5 MiB)
[2024-11-14T16:25:08.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7ea45ba85247:42445 (size: 35.1 KiB, free: 428.7 MiB)
[2024-11-14T16:25:08.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:08.224+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[47] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:25:08.224+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2024-11-14T16:25:08.225+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:08.244+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.21.0.8:35179 (size: 35.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:08.530+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.21.0.8:35179 (size: 35.7 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:08.597+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 371 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:25:08.598+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2024-11-14T16:25:08.598+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: ShuffleMapStage 14 (toString at String.java:2951) finished in 0.400 s
[2024-11-14T16:25:08.599+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:08.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:08.601+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:08.602+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:08.628+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 7ea45ba85247:42445 in memory (size: 35.1 KiB, free: 428.7 MiB)
[2024-11-14T16:25:08.629+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.21.0.8:35179 in memory (size: 35.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:08.902+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 14899 bytes
[2024-11-14T16:25:08.903+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO CodeGenerator: Code generated in 203.978574 ms
[2024-11-14T16:25:08.969+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:08 INFO CodeGenerator: Code generated in 49.419425 ms
[2024-11-14T16:25:09.905+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO CodeGenerator: Code generated in 71.835673 ms
[2024-11-14T16:25:09.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Registering RDD 57 (toString at String.java:2951) as input to shuffle 5
[2024-11-14T16:25:09.919+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Got map stage job 11 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:25:09.920+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (toString at String.java:2951)
[2024-11-14T16:25:09.921+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
[2024-11-14T16:25:09.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:09.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:09 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:10.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 426.2 KiB, free 409.3 MiB)
[2024-11-14T16:25:10.035+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 102.6 KiB, free 409.2 MiB)
[2024-11-14T16:25:10.036+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7ea45ba85247:42445 (size: 102.6 KiB, free: 428.6 MiB)
[2024-11-14T16:25:10.037+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:10.038+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:25:10.039+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSchedulerImpl: Adding task set 16.0 with 50 tasks resource profile 0
[2024-11-14T16:25:10.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 15) (172.21.0.8, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 42.0 in stage 16.0 (TID 16) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.21.0.8:35179 (size: 102.6 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:10.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.21.0.8:37702
[2024-11-14T16:25:10.580+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_6 in memory on 172.21.0.8:35179 (size: 1348.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.581+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_42 in memory on 172.21.0.8:35179 (size: 806.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 47.0 in stage 16.0 (TID 17) (172.21.0.8, executor 0, partition 47, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.767+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 42.0 in stage 16.0 (TID 16) in 726 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:25:10.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.771+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 15) in 732 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:25:10.830+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_47 in memory on 172.21.0.8:35179 (size: 1364.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.837+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_0 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.860+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 19) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.861+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 47.0 in stage 16.0 (TID 17) in 95 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:25:10.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 20) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 101 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:25:10.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_1 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO BlockManagerInfo: Added rdd_54_2 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:10.966+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 21) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.967+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 19) in 108 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:25:10.970+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 22) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:10.972+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:10 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 20) in 103 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:25:11.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_3 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_4 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 23) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 22) in 87 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:25:11.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 24) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.059+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 21) in 92 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:25:11.103+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_7 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.105+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_5 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.134+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 8.0 in stage 16.0 (TID 25) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.135+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 24) in 77 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:25:11.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 9.0 in stage 16.0 (TID 26) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.138+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 23) in 82 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:25:11.202+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_9 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.204+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_8 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 10.0 in stage 16.0 (TID 27) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 9.0 in stage 16.0 (TID 26) in 100 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:25:11.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 11.0 in stage 16.0 (TID 28) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.237+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 8.0 in stage 16.0 (TID 25) in 104 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:25:11.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_11 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.293+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_10 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 12.0 in stage 16.0 (TID 29) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.320+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 11.0 in stage 16.0 (TID 28) in 83 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:25:11.329+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 13.0 in stage 16.0 (TID 30) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.331+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 10.0 in stage 16.0 (TID 27) in 96 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:25:11.398+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_12 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.404+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_13 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.454+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 14.0 in stage 16.0 (TID 31) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.456+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 12.0 in stage 16.0 (TID 29) in 138 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:25:11.458+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 15.0 in stage 16.0 (TID 32) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.460+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 13.0 in stage 16.0 (TID 30) in 131 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:25:11.529+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_14 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.531+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_15 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 16.0 in stage 16.0 (TID 33) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.562+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 14.0 in stage 16.0 (TID 31) in 108 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:25:11.563+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 17.0 in stage 16.0 (TID 34) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 15.0 in stage 16.0 (TID 32) in 107 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:25:11.615+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_16 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.619+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_17 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.649+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 18.0 in stage 16.0 (TID 35) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.650+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 16.0 in stage 16.0 (TID 33) in 90 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:25:11.656+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 19.0 in stage 16.0 (TID 36) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 17.0 in stage 16.0 (TID 34) in 93 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:25:11.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_18 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.719+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_19 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.760+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 20.0 in stage 16.0 (TID 37) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 18.0 in stage 16.0 (TID 35) in 112 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:25:11.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 21.0 in stage 16.0 (TID 38) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.769+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 19.0 in stage 16.0 (TID 36) in 111 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:25:11.816+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_21 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_20 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.842+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 22.0 in stage 16.0 (TID 39) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.843+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 20.0 in stage 16.0 (TID 37) in 84 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:25:11.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 23.0 in stage 16.0 (TID 40) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.846+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 21.0 in stage 16.0 (TID 38) in 81 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:25:11.890+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_22 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.893+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_23 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 24.0 in stage 16.0 (TID 41) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 22.0 in stage 16.0 (TID 39) in 76 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:25:11.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 25.0 in stage 16.0 (TID 42) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.925+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 23.0 in stage 16.0 (TID 40) in 80 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:25:11.966+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_24 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.972+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO BlockManagerInfo: Added rdd_54_25 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:11.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Starting task 26.0 in stage 16.0 (TID 43) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:11.998+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:11 INFO TaskSetManager: Finished task 24.0 in stage 16.0 (TID 41) in 80 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:25:12.004+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 27.0 in stage 16.0 (TID 44) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.005+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 25.0 in stage 16.0 (TID 42) in 82 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:25:12.049+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_26 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_27 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.075+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 28.0 in stage 16.0 (TID 45) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 26.0 in stage 16.0 (TID 43) in 80 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:25:12.084+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 29.0 in stage 16.0 (TID 46) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.085+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 27.0 in stage 16.0 (TID 44) in 82 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:25:12.131+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_28 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.134+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_29 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.156+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 30.0 in stage 16.0 (TID 47) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.157+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 28.0 in stage 16.0 (TID 45) in 82 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:25:12.161+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 31.0 in stage 16.0 (TID 48) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.163+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 29.0 in stage 16.0 (TID 46) in 79 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:25:12.206+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_30 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.207+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_31 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 32.0 in stage 16.0 (TID 49) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 31.0 in stage 16.0 (TID 48) in 74 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:25:12.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 33.0 in stage 16.0 (TID 50) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.237+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 30.0 in stage 16.0 (TID 47) in 82 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:25:12.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_33 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_32 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.315+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 34.0 in stage 16.0 (TID 51) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.316+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 32.0 in stage 16.0 (TID 49) in 82 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:25:12.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 35.0 in stage 16.0 (TID 52) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 33.0 in stage 16.0 (TID 50) in 82 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:25:12.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_35 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_34 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.390+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 36.0 in stage 16.0 (TID 53) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.391+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 35.0 in stage 16.0 (TID 52) in 74 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:25:12.396+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 37.0 in stage 16.0 (TID 54) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.397+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 34.0 in stage 16.0 (TID 51) in 81 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:25:12.436+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_36 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_37 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.462+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 38.0 in stage 16.0 (TID 55) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.463+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 36.0 in stage 16.0 (TID 53) in 73 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:25:12.465+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 39.0 in stage 16.0 (TID 56) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.466+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 37.0 in stage 16.0 (TID 54) in 71 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:25:12.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_39 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_38 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.539+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 40.0 in stage 16.0 (TID 57) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.540+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 39.0 in stage 16.0 (TID 56) in 75 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:25:12.544+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 41.0 in stage 16.0 (TID 58) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 38.0 in stage 16.0 (TID 55) in 83 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:25:12.601+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_40 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.603+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_41 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.626+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 43.0 in stage 16.0 (TID 59) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.627+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 40.0 in stage 16.0 (TID 57) in 88 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:25:12.634+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 44.0 in stage 16.0 (TID 60) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.635+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 41.0 in stage 16.0 (TID 58) in 90 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:25:12.677+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_44 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.678+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_43 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.708+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 45.0 in stage 16.0 (TID 61) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.709+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 43.0 in stage 16.0 (TID 59) in 83 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:25:12.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 46.0 in stage 16.0 (TID 62) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.711+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 44.0 in stage 16.0 (TID 60) in 77 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:25:12.755+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_46 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_45 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.787+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 48.0 in stage 16.0 (TID 63) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.788+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 45.0 in stage 16.0 (TID 61) in 81 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:25:12.791+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Starting task 49.0 in stage 16.0 (TID 64) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:12.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 46.0 in stage 16.0 (TID 62) in 82 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:25:12.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_48 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO BlockManagerInfo: Added rdd_54_49 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:25:12.903+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 49.0 in stage 16.0 (TID 64) in 113 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:25:12.935+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSetManager: Finished task 48.0 in stage 16.0 (TID 63) in 117 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:25:12.941+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2024-11-14T16:25:12.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: ShuffleMapStage 16 (toString at String.java:2951) finished in 2.973 s
[2024-11-14T16:25:12.946+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:12.948+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:12.949+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:12.950+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:12.995+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:25:12.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: Got job 12 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:25:12.998+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: Final stage: ResultStage 19 (toString at String.java:2951)
[2024-11-14T16:25:12.999+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2024-11-14T16:25:13.000+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:13.001+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:12 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[60] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:13.010+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 372.3 KiB, free 408.8 MiB)
[2024-11-14T16:25:13.018+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 408.7 MiB)
[2024-11-14T16:25:13.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7ea45ba85247:42445 (size: 91.6 KiB, free: 428.5 MiB)
[2024-11-14T16:25:13.021+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:13.022+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[60] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:25:13.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2024-11-14T16:25:13.024+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 65) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:13.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.21.0.8:35179 (size: 91.6 KiB, free: 1042.9 MiB)
[2024-11-14T16:25:13.062+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.21.0.8:37702
[2024-11-14T16:25:13.148+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 65) in 125 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:25:13.149+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2024-11-14T16:25:13.150+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: ResultStage 19 (toString at String.java:2951) finished in 0.149 s
[2024-11-14T16:25:13.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:13.152+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
[2024-11-14T16:25:13.153+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Job 12 finished: toString at String.java:2951, took 0.155732 s
[2024-11-14T16:25:13.205+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO CodeGenerator: Code generated in 39.788185 ms
[2024-11-14T16:25:13.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO Snapshot: [tableId=35f78735-bc99-49b9-a070-ed52e53e7463] DELTA: Done
[2024-11-14T16:25:13.210+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO Snapshot: [tableId=35f78735-bc99-49b9-a070-ed52e53e7463] Created snapshot Snapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=0, metadata=Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000000.json; isDirectory=false; length=6809; replication=1; blocksize=33554432; modification_time=1731601507300; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=04fb253b333c0b6de82c46856b1fb2da versionId=null),List(),None,1731601507300), checksumOpt=None)
[2024-11-14T16:25:13.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=0, metadata=Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000000.json; isDirectory=false; length=6809; replication=1; blocksize=33554432; modification_time=1731601507300; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=04fb253b333c0b6de82c46856b1fb2da versionId=null),List(),None,1731601507300), checksumOpt=None)
[2024-11-14T16:25:13.242+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO OptimisticTransaction: [tableId=35f78735,txnId=287943c3] Committed delta #0 to s3a://lakehouse/merge_data-movies/merged_data/_delta_log
[2024-11-14T16:25:13.354+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty
[2024-11-14T16:25:13.355+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO InitialSnapshot: [tableId=1616f9f4-84af-4887-af69-e423f82721de] Created snapshot InitialSnapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=-1, metadata=Metadata(14c101fe-2943-4f1e-989c-57c0b5b21e30,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601513354)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:25:13.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DeltaLog: No delta log found for the Delta table at s3a://lakehouse/gold/gold_data/_delta_log
[2024-11-14T16:25:13.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO InitialSnapshot: [tableId=14c101fe-2943-4f1e-989c-57c0b5b21e30] Created snapshot InitialSnapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=-1, metadata=Metadata(fce8cba3-1f66-4ded-bc6f-732f35db79eb,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601513368)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:25:13.374+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO OptimisticTransaction: [tableId=fce8cba3,txnId=d8952a91] Updated metadata from - to Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370))
[2024-11-14T16:25:13.568+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:25:13.569+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:25:13.569+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:25:13.570+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(keywords),IsNotNull(id)
[2024-11-14T16:25:13.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(keywords#1),isnotnull(id#0L)
[2024-11-14T16:25:13.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Output Data Schema: struct<id: bigint, keywords: string>
[2024-11-14T16:25:13.578+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:25:13.578+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(transform(from_json(ArrayType(StructType(StructField(name,StringType,true)),true), cast#322, Some(Etc/UTC)), lambdafunction(lambda x#334.name, lambda x#334, false))),isnotnull(id#324L)
[2024-11-14T16:25:13.579+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, crew: string, id: bigint ... 1 more fields>
[2024-11-14T16:25:13.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DeltaParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2024-11-14T16:25:13.640+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:25:13.649+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 206.2 KiB, free 408.5 MiB)
[2024-11-14T16:25:13.663+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 7ea45ba85247:42445 in memory (size: 91.6 KiB, free: 428.6 MiB)
[2024-11-14T16:25:13.666+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.21.0.8:35179 in memory (size: 91.6 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:13.667+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 408.9 MiB)
[2024-11-14T16:25:13.669+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 7ea45ba85247:42445 (size: 36.1 KiB, free: 428.6 MiB)
[2024-11-14T16:25:13.671+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO SparkContext: Created broadcast 19 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:25:13.672+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:25:13.686+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 7ea45ba85247:42445 in memory (size: 102.6 KiB, free: 428.7 MiB)
[2024-11-14T16:25:13.687+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.21.0.8:35179 in memory (size: 102.6 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:13.688+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Registering RDD 64 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2024-11-14T16:25:13.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Got map stage job 13 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:25:13.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:25:13.694+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:25:13.695+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:25:13.696+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:13.697+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[64] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:25:13.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 31.5 KiB, free 409.4 MiB)
[2024-11-14T16:25:13.703+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 409.4 MiB)
[2024-11-14T16:25:13.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 7ea45ba85247:42445 (size: 13.9 KiB, free: 428.6 MiB)
[2024-11-14T16:25:13.706+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:13.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[64] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:25:13.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2024-11-14T16:25:13.709+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 66) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4903 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:13.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 206.3 KiB, free 409.2 MiB)
[2024-11-14T16:25:13.719+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 409.2 MiB)
[2024-11-14T16:25:13.722+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 7ea45ba85247:42445 (size: 36.1 KiB, free: 428.6 MiB)
[2024-11-14T16:25:13.723+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO SparkContext: Created broadcast 21 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:25:13.725+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:25:13.726+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.21.0.8:35179 (size: 13.9 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:13.746+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Registering RDD 72 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2024-11-14T16:25:13.747+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Got map stage job 14 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:25:13.748+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:25:13.749+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:25:13.750+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:13.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[72] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:25:13.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.21.0.8:35179 (size: 36.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:13.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 49.7 KiB, free 409.1 MiB)
[2024-11-14T16:25:13.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 409.1 MiB)
[2024-11-14T16:25:13.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 7ea45ba85247:42445 (size: 19.8 KiB, free: 428.6 MiB)
[2024-11-14T16:25:13.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:13.760+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[72] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:13.761+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks resource profile 0
[2024-11-14T16:25:13.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 67) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:13.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.21.0.8:35179 (size: 19.8 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:13.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.21.0.8:35179 (size: 36.1 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:13.993+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 68) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:13.994+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 66) in 285 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:25:13.995+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2024-11-14T16:25:13.996+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: ShuffleMapStage 20 (save at NativeMethodAccessorImpl.java:0) finished in 0.299 s
[2024-11-14T16:25:13.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:13.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: running: Set(ShuffleMapStage 21)
[2024-11-14T16:25:13.999+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:14.000+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:13 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:14.009+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:25:14.010+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:25:14.011+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:25:14.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1480508, minimum partition size: 1048576
[2024-11-14T16:25:14.051+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:25:14.075+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO CodeGenerator: Code generated in 20.084934 ms
[2024-11-14T16:25:14.102+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:25:14.104+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:25:14.106+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Final stage: ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:25:14.111+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
[2024-11-14T16:25:14.113+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:14.114+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:25:14.116+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 68) in 122 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:14.117+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 32.7 KiB, free 409.1 MiB)
[2024-11-14T16:25:14.121+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 409.1 MiB)
[2024-11-14T16:25:14.133+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 7ea45ba85247:42445 (size: 15.2 KiB, free: 428.6 MiB)
[2024-11-14T16:25:14.135+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:14.136+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:14.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0
[2024-11-14T16:25:14.140+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 69) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:14.158+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.21.0.8:35179 (size: 15.2 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:14.169+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.21.0.8:37702
[2024-11-14T16:25:14.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 70) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:14.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 69) in 97 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:14.284+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 70) in 50 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:14.285+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2024-11-14T16:25:14.286+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.172 s
[2024-11-14T16:25:14.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:14.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
[2024-11-14T16:25:14.289+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.184212 s
[2024-11-14T16:25:14.333+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 7ea45ba85247:42445 in memory (size: 13.9 KiB, free: 428.6 MiB)
[2024-11-14T16:25:14.336+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.21.0.8:35179 in memory (size: 13.9 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:14.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 4.0 MiB, free 405.1 MiB)
[2024-11-14T16:25:14.357+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.21.0.8:35179 in memory (size: 15.2 KiB, free: 1043.0 MiB)
[2024-11-14T16:25:14.377+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 7ea45ba85247:42445 in memory (size: 15.2 KiB, free: 428.6 MiB)
[2024-11-14T16:25:14.385+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 814.1 KiB, free 404.4 MiB)
[2024-11-14T16:25:14.387+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 7ea45ba85247:42445 (size: 814.1 KiB, free: 427.8 MiB)
[2024-11-14T16:25:14.389+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:25:14.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 7ea45ba85247:42445 in memory (size: 36.5 KiB, free: 427.8 MiB)
[2024-11-14T16:25:14.417+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.21.0.8:35179 in memory (size: 36.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:14.435+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:25:14.436+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7ea45ba85247:42445 in memory (size: 36.1 KiB, free: 427.9 MiB)
[2024-11-14T16:25:14.437+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:25:14.439+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:25:14.440+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.21.0.8:35179 in memory (size: 36.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:14.461+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.21.0.8:35179 in memory (size: 36.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:25:14.462+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 7ea45ba85247:42445 in memory (size: 36.1 KiB, free: 427.9 MiB)
[2024-11-14T16:25:14.478+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_9_piece1 on 7ea45ba85247:42445 in memory (size: 1563.5 KiB, free: 429.4 MiB)
[2024-11-14T16:25:14.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_9_piece1 on 172.21.0.8:35179 in memory (size: 1563.5 KiB, free: 1044.7 MiB)
[2024-11-14T16:25:14.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 7ea45ba85247:42445 in memory (size: 4.0 MiB, free: 433.4 MiB)
[2024-11-14T16:25:14.490+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.21.0.8:35179 in memory (size: 4.0 MiB, free: 1048.7 MiB)
[2024-11-14T16:25:14.534+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO CodeGenerator: Code generated in 32.880982 ms
[2024-11-14T16:25:14.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO CodeGenerator: Code generated in 27.121346 ms
[2024-11-14T16:25:14.577+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 207.5 KiB, free 428.4 MiB)
[2024-11-14T16:25:14.618+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 428.4 MiB)
[2024-11-14T16:25:14.619+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 7ea45ba85247:42445 (size: 36.4 KiB, free: 433.4 MiB)
[2024-11-14T16:25:14.620+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO SparkContext: Created broadcast 25 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:25:14.623+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10691623 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:25:14.634+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Registering RDD 81 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2024-11-14T16:25:14.635+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Got map stage job 16 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:25:14.636+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:25:14.637+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:25:14.638+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:14.638+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:25:14.653+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 45.6 KiB, free 428.3 MiB)
[2024-11-14T16:25:14.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 428.3 MiB)
[2024-11-14T16:25:14.658+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 7ea45ba85247:42445 (size: 18.6 KiB, free: 433.4 MiB)
[2024-11-14T16:25:14.659+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:14.661+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:14.662+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks resource profile 0
[2024-11-14T16:25:14.664+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 71) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:14.675+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.21.0.8:35179 (size: 18.6 KiB, free: 1048.7 MiB)
[2024-11-14T16:25:14.747+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.21.0.8:35179 (size: 814.1 KiB, free: 1047.9 MiB)
[2024-11-14T16:25:14.767+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.21.0.8:35179 (size: 36.4 KiB, free: 1047.8 MiB)
[2024-11-14T16:25:16.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 72) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:16.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 71) in 1702 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:16.426+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 72) in 62 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:16.427+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2024-11-14T16:25:16.428+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: ShuffleMapStage 24 (save at NativeMethodAccessorImpl.java:0) finished in 1.790 s
[2024-11-14T16:25:16.428+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:16.429+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: running: Set(ShuffleMapStage 21)
[2024-11-14T16:25:16.430+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:16.430+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:16.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 67) in 3168 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:16.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2024-11-14T16:25:16.931+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: ShuffleMapStage 21 (save at NativeMethodAccessorImpl.java:0) finished in 3.180 s
[2024-11-14T16:25:16.932+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:16.933+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:16.933+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:16.934+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:16.938+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:16 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 5348362, minimum partition size: 1048576
[2024-11-14T16:25:17.012+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:25:17.038+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO CodeGenerator: Code generated in 20.832724 ms
[2024-11-14T16:25:17.051+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Registering RDD 84 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2024-11-14T16:25:17.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Got map stage job 17 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:25:17.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Final stage: ShuffleMapStage 26 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:25:17.054+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
[2024-11-14T16:25:17.055+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:17.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[84] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:25:17.061+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 47.4 KiB, free 428.2 MiB)
[2024-11-14T16:25:17.095+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 428.2 MiB)
[2024-11-14T16:25:17.096+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 7ea45ba85247:42445 (size: 19.7 KiB, free: 433.4 MiB)
[2024-11-14T16:25:17.096+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:17.097+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[84] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:17.098+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks resource profile 0
[2024-11-14T16:25:17.098+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 73) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.099+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 74) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.21.0.8:35179 (size: 19.7 KiB, free: 1047.8 MiB)
[2024-11-14T16:25:17.116+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.21.0.8:37702
[2024-11-14T16:25:17.261+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 73) in 162 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:17.267+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 74) in 168 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:17.267+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool
[2024-11-14T16:25:17.268+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: ShuffleMapStage 26 (save at NativeMethodAccessorImpl.java:0) finished in 0.210 s
[2024-11-14T16:25:17.269+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:17.270+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:17.271+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:17.272+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:17.286+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1239972, minimum partition size: 1048576
[2024-11-14T16:25:17.338+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:25:17.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Got job 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:25:17.341+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:25:17.342+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2024-11-14T16:25:17.342+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:17.343+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[86] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:25:17.347+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.2 KiB, free 428.2 MiB)
[2024-11-14T16:25:17.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 428.2 MiB)
[2024-11-14T16:25:17.372+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 7ea45ba85247:42445 (size: 3.9 KiB, free: 433.4 MiB)
[2024-11-14T16:25:17.376+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:17.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 7ea45ba85247:42445 in memory (size: 19.8 KiB, free: 433.4 MiB)
[2024-11-14T16:25:17.381+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 29 (MapPartitionsRDD[86] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:17.382+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks resource profile 0
[2024-11-14T16:25:17.383+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.21.0.8:35179 in memory (size: 19.8 KiB, free: 1047.8 MiB)
[2024-11-14T16:25:17.387+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 75) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.388+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 76) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 7ea45ba85247:42445 in memory (size: 18.6 KiB, free: 433.4 MiB)
[2024-11-14T16:25:17.394+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.21.0.8:35179 in memory (size: 18.6 KiB, free: 1047.8 MiB)
[2024-11-14T16:25:17.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.21.0.8:35179 (size: 3.9 KiB, free: 1047.8 MiB)
[2024-11-14T16:25:17.407+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 7ea45ba85247:42445 in memory (size: 19.7 KiB, free: 433.4 MiB)
[2024-11-14T16:25:17.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.21.0.8:35179 in memory (size: 19.7 KiB, free: 1047.9 MiB)
[2024-11-14T16:25:17.413+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.21.0.8:37702
[2024-11-14T16:25:17.457+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added taskresult_76 in memory on 172.21.0.8:35179 (size: 1130.2 KiB, free: 1046.8 MiB)
[2024-11-14T16:25:17.464+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added taskresult_75 in memory on 172.21.0.8:35179 (size: 1116.1 KiB, free: 1045.7 MiB)
[2024-11-14T16:25:17.500+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 76) in 126 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:17.505+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 75) in 132 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:17.507+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2024-11-14T16:25:17.509+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed taskresult_76 on 172.21.0.8:35179 in memory (size: 1130.2 KiB, free: 1046.8 MiB)
[2024-11-14T16:25:17.510+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.161 s
[2024-11-14T16:25:17.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:17.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
[2024-11-14T16:25:17.521+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Job 18 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.169822 s
[2024-11-14T16:25:17.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed taskresult_75 on 172.21.0.8:35179 in memory (size: 1116.1 KiB, free: 1047.9 MiB)
[2024-11-14T16:25:17.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 8.5 MiB, free 419.9 MiB)
[2024-11-14T16:25:17.586+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 MiB, free 417.6 MiB)
[2024-11-14T16:25:17.587+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 7ea45ba85247:42445 (size: 2.4 MiB, free: 431.1 MiB)
[2024-11-14T16:25:17.587+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Created broadcast 29 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:25:17.594+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 7929966, minimum partition size: 1048576
[2024-11-14T16:25:17.632+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO CodeGenerator: Code generated in 15.023321 ms
[2024-11-14T16:25:17.675+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:25:17.677+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Got job 19 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:25:17.678+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Final stage: ResultStage 31 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:25:17.679+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
[2024-11-14T16:25:17.680+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:17.682+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[88] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:25:17.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 359.7 KiB, free 417.2 MiB)
[2024-11-14T16:25:17.712+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 127.0 KiB, free 417.1 MiB)
[2024-11-14T16:25:17.715+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 7ea45ba85247:42445 (size: 127.0 KiB, free: 430.9 MiB)
[2024-11-14T16:25:17.717+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 7ea45ba85247:42445 in memory (size: 3.9 KiB, free: 430.9 MiB)
[2024-11-14T16:25:17.719+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:17.720+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[88] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:25:17.721+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks resource profile 0
[2024-11-14T16:25:17.722+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 77) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.723+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.21.0.8:35179 in memory (size: 3.9 KiB, free: 1047.9 MiB)
[2024-11-14T16:25:17.724+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 78) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:17.742+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.21.0.8:35179 (size: 127.0 KiB, free: 1047.7 MiB)
[2024-11-14T16:25:17.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.21.0.8:37702
[2024-11-14T16:25:17.891+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:17 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.21.0.8:35179 (size: 2.4 MiB, free: 1045.4 MiB)
[2024-11-14T16:25:18.035+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:18 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 78) in 313 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:25:19.140+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 77) in 1418 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:25:19.140+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2024-11-14T16:25:19.141+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: ResultStage 31 (save at NativeMethodAccessorImpl.java:0) finished in 1.457 s
[2024-11-14T16:25:19.142+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:19.142+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
[2024-11-14T16:25:19.143+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Job 19 finished: save at NativeMethodAccessorImpl.java:0, took 1.466099 s
[2024-11-14T16:25:19.144+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileFormatWriter: Start to commit write Job 5c64d607-8039-47c5-9d18-16fcc0169d05.
[2024-11-14T16:25:19.144+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileFormatWriter: Write Job 5c64d607-8039-47c5-9d18-16fcc0169d05 committed. Elapsed time: 0 ms.
[2024-11-14T16:25:19.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileFormatWriter: Finished processing stats for write job 5c64d607-8039-47c5-9d18-16fcc0169d05.
[2024-11-14T16:25:19.403+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2024-11-14T16:25:19.403+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Job 20 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000278 s
[2024-11-14T16:25:19.417+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO OptimisticTransaction: [tableId=fce8cba3,txnId=d8952a91] Attempting to commit version 0 with 4 actions with Serializable isolation level
[2024-11-14T16:25:19.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DeltaLog: Creating a new snapshot v0 for commit version 0
[2024-11-14T16:25:19.548+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DeltaLog: Loading version 0.
[2024-11-14T16:25:19.554+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO Snapshot: [tableId=fce8cba3-1f66-4ded-bc6f-732f35db79eb] DELTA: Compute snapshot for version: 0
[2024-11-14T16:25:19.558+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 204.4 KiB, free 416.9 MiB)
[2024-11-14T16:25:19.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 416.9 MiB)
[2024-11-14T16:25:19.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 7ea45ba85247:42445 (size: 35.6 KiB, free: 430.9 MiB)
[2024-11-14T16:25:19.568+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO SparkContext: Created broadcast 31 from toString at String.java:2951
[2024-11-14T16:25:19.569+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3008)
[2024-11-14T16:25:19.715+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 7ea45ba85247:42445 in memory (size: 127.0 KiB, free: 431.0 MiB)
[2024-11-14T16:25:19.716+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.21.0.8:35179 in memory (size: 127.0 KiB, free: 1045.5 MiB)
[2024-11-14T16:25:19.816+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:25:19.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:25:19.818+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:25:19.889+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 204.7 KiB, free 417.1 MiB)
[2024-11-14T16:25:19.897+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 417.1 MiB)
[2024-11-14T16:25:19.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 7ea45ba85247:42445 (size: 35.7 KiB, free: 431.0 MiB)
[2024-11-14T16:25:19.899+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO SparkContext: Created broadcast 32 from toString at String.java:2951
[2024-11-14T16:25:19.900+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:25:19.915+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Registering RDD 96 (toString at String.java:2951) as input to shuffle 10
[2024-11-14T16:25:19.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Got map stage job 21 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:25:19.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (toString at String.java:2951)
[2024-11-14T16:25:19.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:25:19.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:19.919+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[96] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:19.921+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 124.3 KiB, free 417.0 MiB)
[2024-11-14T16:25:19.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 416.9 MiB)
[2024-11-14T16:25:19.925+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 7ea45ba85247:42445 (size: 35.1 KiB, free: 431.0 MiB)
[2024-11-14T16:25:19.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:19.934+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[96] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:25:19.935+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2024-11-14T16:25:19.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 79) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4931 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:19.953+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.21.0.8:35179 (size: 35.1 KiB, free: 1045.5 MiB)
[2024-11-14T16:25:19.987+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.21.0.8:35179 (size: 35.7 KiB, free: 1045.4 MiB)
[2024-11-14T16:25:20.022+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 79) in 86 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:25:20.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2024-11-14T16:25:20.024+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: ShuffleMapStage 32 (toString at String.java:2951) finished in 0.106 s
[2024-11-14T16:25:20.025+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:20.026+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:20.027+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:20.028+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:20.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 7ea45ba85247:42445 in memory (size: 35.1 KiB, free: 431.0 MiB)
[2024-11-14T16:25:20.094+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.21.0.8:35179 in memory (size: 35.1 KiB, free: 1045.5 MiB)
[2024-11-14T16:25:20.302+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Registering RDD 106 (toString at String.java:2951) as input to shuffle 11
[2024-11-14T16:25:20.303+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Got map stage job 22 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:25:20.304+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (toString at String.java:2951)
[2024-11-14T16:25:20.305+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2024-11-14T16:25:20.306+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:20.307+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[106] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:20.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 426.2 KiB, free 416.7 MiB)
[2024-11-14T16:25:20.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 102.5 KiB, free 416.6 MiB)
[2024-11-14T16:25:20.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 7ea45ba85247:42445 (size: 102.5 KiB, free: 430.9 MiB)
[2024-11-14T16:25:20.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:20.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[106] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:25:20.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSchedulerImpl: Adding task set 34.0 with 50 tasks resource profile 0
[2024-11-14T16:25:20.370+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 22.0 in stage 34.0 (TID 80) (172.21.0.8, executor 0, partition 22, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.371+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 42.0 in stage 34.0 (TID 81) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.21.0.8:35179 (size: 102.5 KiB, free: 1045.4 MiB)
[2024-11-14T16:25:20.392+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.21.0.8:37702
[2024-11-14T16:25:20.419+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_42 in memory on 172.21.0.8:35179 (size: 683.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_22 in memory on 172.21.0.8:35179 (size: 879.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.442+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 82) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.443+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 42.0 in stage 34.0 (TID 81) in 72 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:25:20.444+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 83) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.444+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 22.0 in stage 34.0 (TID 80) in 74 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:25:20.473+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_1 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.475+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_0 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 84) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.493+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 82) in 52 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:25:20.495+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 85) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.496+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 83) in 52 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:25:20.527+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_3 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_2 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 4.0 in stage 34.0 (TID 86) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.547+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 84) in 54 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:25:20.548+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 5.0 in stage 34.0 (TID 87) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.549+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 85) in 55 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:25:20.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_4 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_5 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.604+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 6.0 in stage 34.0 (TID 88) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.604+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 4.0 in stage 34.0 (TID 86) in 59 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:25:20.605+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 7.0 in stage 34.0 (TID 89) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.606+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 5.0 in stage 34.0 (TID 87) in 58 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:25:20.634+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_6 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.635+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_7 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.651+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 8.0 in stage 34.0 (TID 90) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.651+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 6.0 in stage 34.0 (TID 88) in 48 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:25:20.652+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 9.0 in stage 34.0 (TID 91) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.653+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 7.0 in stage 34.0 (TID 89) in 47 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:25:20.684+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_9 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.684+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_8 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 10.0 in stage 34.0 (TID 92) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.702+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 8.0 in stage 34.0 (TID 90) in 51 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:25:20.702+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 11.0 in stage 34.0 (TID 93) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.703+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 9.0 in stage 34.0 (TID 91) in 51 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:25:20.734+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_11 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_10 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 12.0 in stage 34.0 (TID 94) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 10.0 in stage 34.0 (TID 92) in 51 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:25:20.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 13.0 in stage 34.0 (TID 95) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 11.0 in stage 34.0 (TID 93) in 50 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:25:20.786+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_12 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.788+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_13 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 14.0 in stage 34.0 (TID 96) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 12.0 in stage 34.0 (TID 94) in 54 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:25:20.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 15.0 in stage 34.0 (TID 97) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 13.0 in stage 34.0 (TID 95) in 55 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:25:20.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_14 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.848+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_15 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.866+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 16.0 in stage 34.0 (TID 98) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.867+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 14.0 in stage 34.0 (TID 96) in 63 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:25:20.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 17.0 in stage 34.0 (TID 99) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 15.0 in stage 34.0 (TID 97) in 65 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:25:20.903+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_16 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.905+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_17 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.923+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 18.0 in stage 34.0 (TID 100) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.923+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 16.0 in stage 34.0 (TID 98) in 58 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:25:20.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 19.0 in stage 34.0 (TID 101) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.925+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 17.0 in stage 34.0 (TID 99) in 54 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:25:20.966+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_19 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.973+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO BlockManagerInfo: Added rdd_103_18 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:20.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Starting task 20.0 in stage 34.0 (TID 102) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:20.998+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:20 INFO TaskSetManager: Finished task 19.0 in stage 34.0 (TID 101) in 74 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:25:21.001+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 21.0 in stage 34.0 (TID 103) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.001+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 18.0 in stage 34.0 (TID 100) in 79 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:25:21.036+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_20 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.039+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_21 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 23.0 in stage 34.0 (TID 104) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.058+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 20.0 in stage 34.0 (TID 102) in 61 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:25:21.059+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 24.0 in stage 34.0 (TID 105) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.060+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 21.0 in stage 34.0 (TID 103) in 60 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:25:21.101+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_23 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.102+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_24 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.126+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 25.0 in stage 34.0 (TID 106) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.127+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 23.0 in stage 34.0 (TID 104) in 69 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:25:21.128+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 26.0 in stage 34.0 (TID 107) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.129+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 24.0 in stage 34.0 (TID 105) in 69 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:25:21.177+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_26 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.178+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_25 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.201+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 27.0 in stage 34.0 (TID 108) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.202+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 25.0 in stage 34.0 (TID 106) in 77 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:25:21.203+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 28.0 in stage 34.0 (TID 109) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.204+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 26.0 in stage 34.0 (TID 107) in 77 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:25:21.242+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_27 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.242+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_28 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.263+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 29.0 in stage 34.0 (TID 110) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.264+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 28.0 in stage 34.0 (TID 109) in 60 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:25:21.264+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 30.0 in stage 34.0 (TID 111) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.265+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 27.0 in stage 34.0 (TID 108) in 64 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:25:21.296+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_29 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.300+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_30 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.320+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 31.0 in stage 34.0 (TID 112) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.322+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 29.0 in stage 34.0 (TID 110) in 59 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:25:21.330+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 32.0 in stage 34.0 (TID 113) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.331+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 30.0 in stage 34.0 (TID 111) in 67 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:25:21.376+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_31 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_32 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.409+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 33.0 in stage 34.0 (TID 114) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 31.0 in stage 34.0 (TID 112) in 89 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:25:21.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 34.0 in stage 34.0 (TID 115) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 32.0 in stage 34.0 (TID 113) in 92 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:25:21.478+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_33 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_34 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.511+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 35.0 in stage 34.0 (TID 116) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 33.0 in stage 34.0 (TID 114) in 103 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:25:21.527+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 36.0 in stage 34.0 (TID 117) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 34.0 in stage 34.0 (TID 115) in 108 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:25:21.575+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_35 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_36 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.602+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 37.0 in stage 34.0 (TID 118) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.603+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 35.0 in stage 34.0 (TID 116) in 92 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:25:21.608+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 38.0 in stage 34.0 (TID 119) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 36.0 in stage 34.0 (TID 117) in 83 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:25:21.643+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_37 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.653+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_38 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.671+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 39.0 in stage 34.0 (TID 120) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.672+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 37.0 in stage 34.0 (TID 118) in 70 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:25:21.680+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 40.0 in stage 34.0 (TID 121) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.681+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 38.0 in stage 34.0 (TID 119) in 72 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:25:21.718+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_39 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.727+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_40 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.746+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 41.0 in stage 34.0 (TID 122) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.747+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 39.0 in stage 34.0 (TID 120) in 76 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:25:21.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 43.0 in stage 34.0 (TID 123) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.754+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 40.0 in stage 34.0 (TID 121) in 75 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:25:21.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_41 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_43 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.820+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 44.0 in stage 34.0 (TID 124) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.821+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 41.0 in stage 34.0 (TID 122) in 75 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:25:21.830+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 45.0 in stage 34.0 (TID 125) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.832+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 43.0 in stage 34.0 (TID 123) in 79 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:25:21.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_44 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.875+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_45 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.891+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 46.0 in stage 34.0 (TID 126) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.892+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 44.0 in stage 34.0 (TID 124) in 72 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:25:21.895+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 47.0 in stage 34.0 (TID 127) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.896+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 45.0 in stage 34.0 (TID 125) in 66 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:25:21.931+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_46 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO BlockManagerInfo: Added rdd_103_47 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:21.952+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 48.0 in stage 34.0 (TID 128) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.953+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 46.0 in stage 34.0 (TID 126) in 63 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:25:21.964+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Starting task 49.0 in stage 34.0 (TID 129) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:21.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:21 INFO TaskSetManager: Finished task 47.0 in stage 34.0 (TID 127) in 71 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:25:22.005+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManagerInfo: Added rdd_103_48 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:22.019+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManagerInfo: Added rdd_103_49 in memory on 172.21.0.8:35179 (size: 46.0 B, free: 1045.4 MiB)
[2024-11-14T16:25:22.033+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSetManager: Finished task 48.0 in stage 34.0 (TID 128) in 80 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:25:22.050+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSetManager: Finished task 49.0 in stage 34.0 (TID 129) in 87 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:25:22.051+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2024-11-14T16:25:22.055+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: ShuffleMapStage 34 (toString at String.java:2951) finished in 1.743 s
[2024-11-14T16:25:22.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:25:22.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: running: Set()
[2024-11-14T16:25:22.059+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:25:22.060+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: failed: Set()
[2024-11-14T16:25:22.105+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:25:22.108+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Got job 23 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:25:22.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Final stage: ResultStage 37 (toString at String.java:2951)
[2024-11-14T16:25:22.110+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2024-11-14T16:25:22.111+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:25:22.112+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[109] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:25:22.118+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 372.2 KiB, free 416.2 MiB)
[2024-11-14T16:25:22.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 416.1 MiB)
[2024-11-14T16:25:22.121+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 7ea45ba85247:42445 (size: 91.6 KiB, free: 430.8 MiB)
[2024-11-14T16:25:22.122+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:25:22.123+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[109] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:25:22.123+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2024-11-14T16:25:22.124+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 130) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:25:22.138+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.21.0.8:35179 (size: 91.6 KiB, free: 1045.3 MiB)
[2024-11-14T16:25:22.154+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.21.0.8:37702
[2024-11-14T16:25:22.194+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 130) in 70 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:25:22.195+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2024-11-14T16:25:22.196+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: ResultStage 37 (toString at String.java:2951) finished in 0.084 s
[2024-11-14T16:25:22.197+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:25:22.198+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
[2024-11-14T16:25:22.199+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DAGScheduler: Job 23 finished: toString at String.java:2951, took 0.091438 s
[2024-11-14T16:25:22.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO Snapshot: [tableId=fce8cba3-1f66-4ded-bc6f-732f35db79eb] DELTA: Done
[2024-11-14T16:25:22.210+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO Snapshot: [tableId=fce8cba3-1f66-4ded-bc6f-732f35db79eb] Created snapshot Snapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=0, metadata=Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000000.json; isDirectory=false; length=3008; replication=1; blocksize=33554432; modification_time=1731601519475; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=a595743531ef21bf02a54d4e253d1147 versionId=null),List(),None,1731601519475), checksumOpt=None)
[2024-11-14T16:25:22.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=0, metadata=Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000000.json; isDirectory=false; length=3008; replication=1; blocksize=33554432; modification_time=1731601519475; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=a595743531ef21bf02a54d4e253d1147 versionId=null),List(),None,1731601519475), checksumOpt=None)
[2024-11-14T16:25:22.212+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO OptimisticTransaction: [tableId=fce8cba3,txnId=d8952a91] Committed delta #0 to s3a://lakehouse/gold/gold_data/_delta_log
[2024-11-14T16:25:22.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO SparkUI: Stopped Spark web UI at http://7ea45ba85247:4040
[2024-11-14T16:25:22.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO StandaloneSchedulerBackend: Shutting down all executors
[2024-11-14T16:25:22.237+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2024-11-14T16:25:22.276+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-11-14T16:25:22.303+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MemoryStore: MemoryStore cleared
[2024-11-14T16:25:22.305+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManager: BlockManager stopped
[2024-11-14T16:25:22.317+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-11-14T16:25:22.325+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-11-14T16:25:22.354+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO SparkContext: Successfully stopped SparkContext
[2024-11-14T16:25:22.761+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO ShutdownHookManager: Shutdown hook called
[2024-11-14T16:25:22.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9f2f13e-d6fb-4740-a7c2-dc428f8d0f08
[2024-11-14T16:25:22.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9f2f13e-d6fb-4740-a7c2-dc428f8d0f08/pyspark-f86b9f7b-cca0-4866-be3f-7889040d6fc8
[2024-11-14T16:25:22.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-92a37101-2e1d-4b5c-a1a3-158659fb1556
[2024-11-14T16:25:22.777+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2024-11-14T16:25:22.778+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2024-11-14T16:25:22.778+0000] {spark_submit.py:579} INFO - 24/11/14 16:25:22 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2024-11-14T16:25:22.870+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=mergeeeee, task_id=merge_id, execution_date=20241114T162425, start_date=20241114T162426, end_date=20241114T162522
[2024-11-14T16:25:22.915+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-11-14T16:25:22.932+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
