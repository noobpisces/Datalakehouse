[2024-11-14T16:26:46.769+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:21:12.744457+00:00 [queued]>
[2024-11-14T16:26:46.779+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:21:12.744457+00:00 [queued]>
[2024-11-14T16:26:46.780+0000] {taskinstance.py:1361} INFO - Starting attempt 2 of 2
[2024-11-14T16:26:46.797+0000] {taskinstance.py:1382} INFO - Executing <Task(SparkSubmitOperator): merge_id> on 2024-11-14 16:21:12.744457+00:00
[2024-11-14T16:26:46.802+0000] {standard_task_runner.py:57} INFO - Started process 6787 to run task
[2024-11-14T16:26:46.804+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'mergeeeee', 'merge_id', 'manual__2024-11-14T16:21:12.744457+00:00', '--job-id', '274', '--raw', '--subdir', 'DAGS_FOLDER/merge_hihi.py', '--cfg-path', '/tmp/tmpky85rxcq']
[2024-11-14T16:26:46.806+0000] {standard_task_runner.py:85} INFO - Job 274: Subtask merge_id
[2024-11-14T16:26:46.854+0000] {task_command.py:416} INFO - Running <TaskInstance: mergeeeee.merge_id manual__2024-11-14T16:21:12.744457+00:00 [running]> on host 7ea45ba85247
[2024-11-14T16:26:46.940+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='mergeeeee' AIRFLOW_CTX_TASK_ID='merge_id' AIRFLOW_CTX_EXECUTION_DATE='2024-11-14T16:21:12.744457+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-14T16:21:12.744457+00:00'
[2024-11-14T16:26:46.949+0000] {base.py:73} INFO - Using connection ID 'spark-conn' for task execution.
[2024-11-14T16:26:46.952+0000] {spark_submit.py:403} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog --jars /opt/***/jars/hadoop-aws-3.3.4.jar,/opt/***/jars/s3-2.18.41.jar,/opt/***/jars/aws-java-sdk-1.12.367.jar,/opt/***/jars/delta-core_2.12-2.2.0.jar,/opt/***/jars/delta-storage-2.2.0.jar, --packages org.apache.hadoop:hadoop-aws:3.3.4 --num-executors 2 --total-executor-cores 2 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode client /opt/***/jobs/python/test_merge.py s3a://lakehouse/bronze/keywords.parquet s3a://lakehouse/bronze/movies.parquet s3a://lakehouse/bronze/credits.parquet s3a://lakehouse/merge_data-movies/merged_data s3a://lakehouse/gold/gold_data
[2024-11-14T16:26:47.147+0000] {spark_submit.py:579} INFO - /home/***/.local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2024-11-14T16:26:49.740+0000] {spark_submit.py:579} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-11-14T16:26:49.880+0000] {spark_submit.py:579} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2024-11-14T16:26:49.881+0000] {spark_submit.py:579} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2024-11-14T16:26:49.887+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2024-11-14T16:26:49.888+0000] {spark_submit.py:579} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-047dc5a5-3e93-4b70-93c0-5d6e48e9d367;1.0
[2024-11-14T16:26:49.889+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:26:50.034+0000] {spark_submit.py:579} INFO - found org.apache.hadoop#hadoop-aws;3.3.4 in spark-list
[2024-11-14T16:26:50.069+0000] {spark_submit.py:579} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2024-11-14T16:26:50.094+0000] {spark_submit.py:579} INFO - found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2024-11-14T16:26:50.118+0000] {spark_submit.py:579} INFO - :: resolution report :: resolve 221ms :: artifacts dl 9ms
[2024-11-14T16:26:50.119+0000] {spark_submit.py:579} INFO - :: modules in use:
[2024-11-14T16:26:50.120+0000] {spark_submit.py:579} INFO - com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2024-11-14T16:26:50.121+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws;3.3.4 from spark-list in [default]
[2024-11-14T16:26:50.122+0000] {spark_submit.py:579} INFO - org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2024-11-14T16:26:50.123+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:26:50.124+0000] {spark_submit.py:579} INFO - |                  |            modules            ||   artifacts   |
[2024-11-14T16:26:50.124+0000] {spark_submit.py:579} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-11-14T16:26:50.125+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:26:50.126+0000] {spark_submit.py:579} INFO - |      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
[2024-11-14T16:26:50.126+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:26:50.127+0000] {spark_submit.py:579} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-047dc5a5-3e93-4b70-93c0-5d6e48e9d367
[2024-11-14T16:26:50.128+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:26:50.132+0000] {spark_submit.py:579} INFO - 0 artifacts copied, 3 already retrieved (0kB/6ms)
[2024-11-14T16:26:50.404+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-11-14T16:26:52.341+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkContext: Running Spark version 3.3.2
[2024-11-14T16:26:52.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceUtils: ==============================================================
[2024-11-14T16:26:52.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-11-14T16:26:52.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceUtils: ==============================================================
[2024-11-14T16:26:52.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkContext: Submitted application: MergeData
[2024-11-14T16:26:52.387+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-11-14T16:26:52.401+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
[2024-11-14T16:26:52.402+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-11-14T16:26:52.459+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SecurityManager: Changing view acls to: ***
[2024-11-14T16:26:52.459+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SecurityManager: Changing modify acls to: ***
[2024-11-14T16:26:52.460+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SecurityManager: Changing view acls groups to:
[2024-11-14T16:26:52.461+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SecurityManager: Changing modify acls groups to:
[2024-11-14T16:26:52.461+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2024-11-14T16:26:52.759+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO Utils: Successfully started service 'sparkDriver' on port 44345.
[2024-11-14T16:26:52.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkEnv: Registering MapOutputTracker
[2024-11-14T16:26:52.833+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkEnv: Registering BlockManagerMaster
[2024-11-14T16:26:52.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-11-14T16:26:52.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-11-14T16:26:52.856+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-11-14T16:26:52.890+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-416dadbd-0d55-41ad-aa40-a5ae25eebacb
[2024-11-14T16:26:52.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-11-14T16:26:52.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:52 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-11-14T16:26:53.166+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-11-14T16:26:53.214+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///opt/***/jars/hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44345/jars/hadoop-aws-3.3.4.jar with timestamp 1731601612330
[2024-11-14T16:26:53.216+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///opt/***/jars/s3-2.18.41.jar at spark://7ea45ba85247:44345/jars/s3-2.18.41.jar with timestamp 1731601612330
[2024-11-14T16:26:53.217+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///opt/***/jars/aws-java-sdk-1.12.367.jar at spark://7ea45ba85247:44345/jars/aws-java-sdk-1.12.367.jar with timestamp 1731601612330
[2024-11-14T16:26:53.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///opt/***/jars/delta-core_2.12-2.2.0.jar at spark://7ea45ba85247:44345/jars/delta-core_2.12-2.2.0.jar with timestamp 1731601612330
[2024-11-14T16:26:53.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///opt/***/jars/delta-storage-2.2.0.jar at spark://7ea45ba85247:44345/jars/delta-storage-2.2.0.jar with timestamp 1731601612330
[2024-11-14T16:26:53.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44345/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601612330
[2024-11-14T16:26:53.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:44345/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601612330
[2024-11-14T16:26:53.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:44345/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601612330
[2024-11-14T16:26:53.225+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44345/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601612330
[2024-11-14T16:26:53.226+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-a0bdfce2-ee26-4e28-ace8-f2cdbe1e8d70/userFiles-69784a4d-0b67-402e-9a9c-c1c65910c428/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2024-11-14T16:26:53.241+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:44345/files/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601612330
[2024-11-14T16:26:53.242+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:53 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-a0bdfce2-ee26-4e28-ace8-f2cdbe1e8d70/userFiles-69784a4d-0b67-402e-9a9c-c1c65910c428/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2024-11-14T16:26:54.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:44345/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601612330
[2024-11-14T16:26:54.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO Utils: Copying /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-a0bdfce2-ee26-4e28-ace8-f2cdbe1e8d70/userFiles-69784a4d-0b67-402e-9a9c-c1c65910c428/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2024-11-14T16:26:54.321+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-11-14T16:26:54.371+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.3:7077 after 31 ms (0 ms spent in bootstraps)
[2024-11-14T16:26:54.507+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241114162654-0008
[2024-11-14T16:26:54.511+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241114162654-0008/0 on worker-20241114153331-172.21.0.8-42023 (172.21.0.8:42023) with 2 core(s)
[2024-11-14T16:26:54.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20241114162654-0008/0 on hostPort 172.21.0.8:42023 with 2 core(s), 2.0 GiB RAM
[2024-11-14T16:26:54.522+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33227.
[2024-11-14T16:26:54.522+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO NettyBlockTransferService: Server created on 7ea45ba85247:33227
[2024-11-14T16:26:54.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-11-14T16:26:54.534+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7ea45ba85247, 33227, None)
[2024-11-14T16:26:54.542+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO BlockManagerMasterEndpoint: Registering block manager 7ea45ba85247:33227 with 434.4 MiB RAM, BlockManagerId(driver, 7ea45ba85247, 33227, None)
[2024-11-14T16:26:54.547+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7ea45ba85247, 33227, None)
[2024-11-14T16:26:54.549+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7ea45ba85247, 33227, None)
[2024-11-14T16:26:54.586+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241114162654-0008/0 is now RUNNING
[2024-11-14T16:26:54.813+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:54 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-11-14T16:26:55.086+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-11-14T16:26:55.091+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:55 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2024-11-14T16:26:56.641+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:56 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2024-11-14T16:26:56.656+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:56 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2024-11-14T16:26:56.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:56 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2024-11-14T16:26:57.581+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.8:60634) with ID 0,  ResourceProfileId 0
[2024-11-14T16:26:57.666+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.8:35711 with 1048.8 MiB RAM, BlockManagerId(0, 172.21.0.8, 35711, None)
[2024-11-14T16:26:58.398+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:58 INFO InMemoryFileIndex: It took 110 ms to list leaf files for 1 paths.
[2024-11-14T16:26:59.119+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2024-11-14T16:26:59.153+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:26:59.154+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:26:59.155+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:26:59.158+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:26:59.167+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:26:59.272+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 106.1 KiB, free 434.3 MiB)
[2024-11-14T16:26:59.353+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2024-11-14T16:26:59.360+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7ea45ba85247:33227 (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:26:59.373+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:26:59.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:26:59.402+0000] {spark_submit.py:579} INFO - 24/11/14 16:26:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-11-14T16:27:00.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4591 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:00.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.8:35711 (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:02.013+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1743 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:02.015+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-11-14T16:27:02.024+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 2.828 s
[2024-11-14T16:27:02.027+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:02.028+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2024-11-14T16:27:02.030+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 2.909891 s
[2024-11-14T16:27:02.210+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 7ea45ba85247:33227 in memory (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:27:02.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:02 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.21.0.8:35711 in memory (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:04.047+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 1 paths.
[2024-11-14T16:27:04.440+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
[2024-11-14T16:27:04.483+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:04.484+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Got job 1 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:27:04.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Final stage: ResultStage 1 (load at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:04.486+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:04.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:04.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:04.497+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 106.3 KiB, free 434.3 MiB)
[2024-11-14T16:27:04.509+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2024-11-14T16:27:04.510+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7ea45ba85247:33227 (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:27:04.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:04.513+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:04.514+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2024-11-14T16:27:04.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4590 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:04.550+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.8:35711 (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:04.596+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 80 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:04.597+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2024-11-14T16:27:04.598+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: ResultStage 1 (load at NativeMethodAccessorImpl.java:0) finished in 0.108 s
[2024-11-14T16:27:04.599+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:04.599+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2024-11-14T16:27:04.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO DAGScheduler: Job 1 finished: load at NativeMethodAccessorImpl.java:0, took 0.115986 s
[2024-11-14T16:27:04.907+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7ea45ba85247:33227 in memory (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:27:04.911+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.21.0.8:35711 in memory (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:05.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:27:05.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:27:05.238+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, id: bigint>
[2024-11-14T16:27:05.558+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO CodeGenerator: Code generated in 130.353375 ms
[2024-11-14T16:27:05.592+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO CodeGenerator: Code generated in 23.5935 ms
[2024-11-14T16:27:05.616+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 206.0 KiB, free 434.2 MiB)
[2024-11-14T16:27:05.635+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 434.2 MiB)
[2024-11-14T16:27:05.637+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7ea45ba85247:33227 (size: 36.1 KiB, free: 434.4 MiB)
[2024-11-14T16:27:05.638+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:05.658+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:05.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:05.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:27:05.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:05.708+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:05.709+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:05.709+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:05.783+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.9 KiB, free 434.1 MiB)
[2024-11-14T16:27:05.791+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 434.1 MiB)
[2024-11-14T16:27:05.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7ea45ba85247:33227 (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:27:05.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:05.794+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:05.795+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2024-11-14T16:27:05.799+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:05.832+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.8:35711 (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:06.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.8:35711 (size: 36.1 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:06.908+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1111 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:06.908+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-11-14T16:27:06.909+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.197 s
[2024-11-14T16:27:06.909+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:06.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2024-11-14T16:27:06.911+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 1.203818 s
[2024-11-14T16:27:06.939+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:06 INFO CodeGenerator: Code generated in 11.530238 ms
[2024-11-14T16:27:06.992+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:27:06.993+0000] {spark_submit.py:579} INFO - |id   |cast_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |director                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
[2024-11-14T16:27:06.994+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:27:06.994+0000] {spark_submit.py:579} INFO - |862  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:06.995+0000] {spark_submit.py:579} INFO - |8844 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:06.995+0000] {spark_submit.py:579} INFO - |15602|[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:27:06.996+0000] {spark_submit.py:579} INFO - |31357|[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |
[2024-11-14T16:27:06.996+0000] {spark_submit.py:579} INFO - |11862|[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |
[2024-11-14T16:27:06.997+0000] {spark_submit.py:579} INFO - |949  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:06.998+0000] {spark_submit.py:579} INFO - |11860|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:06.998+0000] {spark_submit.py:579} INFO - |45325|[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |
[2024-11-14T16:27:06.999+0000] {spark_submit.py:579} INFO - |9091 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:06.999+0000] {spark_submit.py:579} INFO - |710  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.000+0000] {spark_submit.py:579} INFO - |9087 |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |
[2024-11-14T16:27:07.001+0000] {spark_submit.py:579} INFO - |12110|[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:27:07.001+0000] {spark_submit.py:579} INFO - |21032|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.002+0000] {spark_submit.py:579} INFO - |10858|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|
[2024-11-14T16:27:07.003+0000] {spark_submit.py:579} INFO - |1408 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.003+0000] {spark_submit.py:579} INFO - |524  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.004+0000] {spark_submit.py:579} INFO - |4584 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.005+0000] {spark_submit.py:579} INFO - |5    |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.005+0000] {spark_submit.py:579} INFO - |9273 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.006+0000] {spark_submit.py:579} INFO - |11517|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:27:07.006+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:27:07.007+0000] {spark_submit.py:579} INFO - only showing top 20 rows
[2024-11-14T16:27:07.007+0000] {spark_submit.py:579} INFO - 
[2024-11-14T16:27:07.127+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2024-11-14T16:27:07.186+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 7ea45ba85247:33227 in memory (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:27:07.190+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.21.0.8:35711 in memory (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:07.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 7ea45ba85247:33227 in memory (size: 36.1 KiB, free: 434.4 MiB)
[2024-11-14T16:27:07.435+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.21.0.8:35711 in memory (size: 36.1 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:07.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO DeltaLog: Loading version 0.
[2024-11-14T16:27:07.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO Snapshot: [tableId=d808df40-9801-42e4-85d5-963b3b7a5726] DELTA: Compute snapshot for version: 0
[2024-11-14T16:27:07.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 204.3 KiB, free 434.2 MiB)
[2024-11-14T16:27:07.720+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 434.2 MiB)
[2024-11-14T16:27:07.722+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7ea45ba85247:33227 (size: 35.5 KiB, free: 434.4 MiB)
[2024-11-14T16:27:07.723+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO SparkContext: Created broadcast 4 from toString at String.java:2951
[2024-11-14T16:27:07.795+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:07 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 6809)
[2024-11-14T16:27:08.873+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:08 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:27:08.874+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:08 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:27:08.875+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:08 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:27:09.218+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO CodeGenerator: Code generated in 170.373379 ms
[2024-11-14T16:27:09.222+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 204.6 KiB, free 434.0 MiB)
[2024-11-14T16:27:09.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 433.9 MiB)
[2024-11-14T16:27:09.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7ea45ba85247:33227 (size: 35.6 KiB, free: 434.3 MiB)
[2024-11-14T16:27:09.238+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO SparkContext: Created broadcast 5 from toString at String.java:2951
[2024-11-14T16:27:09.261+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:09.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Registering RDD 13 (toString at String.java:2951) as input to shuffle 0
[2024-11-14T16:27:09.344+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Got map stage job 3 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:09.344+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (toString at String.java:2951)
[2024-11-14T16:27:09.345+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:09.346+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:09.347+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:09.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 124.3 KiB, free 433.8 MiB)
[2024-11-14T16:27:09.388+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 433.8 MiB)
[2024-11-14T16:27:09.389+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7ea45ba85247:33227 (size: 35.2 KiB, free: 434.3 MiB)
[2024-11-14T16:27:09.390+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:09.392+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:09.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2024-11-14T16:27:09.395+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:09.426+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.21.0.8:35711 (size: 35.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:09.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.8:35711 (size: 35.6 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:11.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1646 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:11.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2024-11-14T16:27:11.042+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: ShuffleMapStage 3 (toString at String.java:2951) finished in 1.692 s
[2024-11-14T16:27:11.043+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:11.043+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:11.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:11.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:11.124+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 7ea45ba85247:33227 in memory (size: 35.2 KiB, free: 434.3 MiB)
[2024-11-14T16:27:11.127+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.21.0.8:35711 in memory (size: 35.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:11.358+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 14899 bytes
[2024-11-14T16:27:11.359+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO CodeGenerator: Code generated in 162.064938 ms
[2024-11-14T16:27:11.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO CodeGenerator: Code generated in 52.45652 ms
[2024-11-14T16:27:11.868+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO CodeGenerator: Code generated in 64.172216 ms
[2024-11-14T16:27:11.881+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Registering RDD 23 (toString at String.java:2951) as input to shuffle 1
[2024-11-14T16:27:11.882+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Got map stage job 4 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:27:11.883+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (toString at String.java:2951)
[2024-11-14T16:27:11.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2024-11-14T16:27:11.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:11.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:11 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:12.019+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 426.2 KiB, free 433.5 MiB)
[2024-11-14T16:27:12.022+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 102.5 KiB, free 433.4 MiB)
[2024-11-14T16:27:12.023+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7ea45ba85247:33227 (size: 102.5 KiB, free: 434.2 MiB)
[2024-11-14T16:27:12.024+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:12.025+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:12.025+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0
[2024-11-14T16:27:12.030+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 4) (172.21.0.8, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:12.031+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 5) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:12.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.8:35711 (size: 102.5 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:12.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.8:60634
[2024-11-14T16:27:12.856+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO BlockManagerInfo: Added rdd_20_6 in memory on 172.21.0.8:35711 (size: 1348.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:12.958+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:12 INFO BlockManagerInfo: Added rdd_20_42 in memory on 172.21.0.8:35711 (size: 806.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.094+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 6) (172.21.0.8, executor 0, partition 47, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.095+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 5) in 1064 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:13.097+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.098+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 4) in 1069 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:13.175+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_0 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.179+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_47 in memory on 172.21.0.8:35711 (size: 1364.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.223+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.224+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 127 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:13.227+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 9) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 6) in 135 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:13.293+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_1 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.297+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_2 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.336+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 10) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.337+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 9) in 111 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:13.339+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 11) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 117 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:13.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_4 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_3 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.464+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 12) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.465+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 11) in 127 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:13.466+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 13) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.467+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 10) in 131 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:13.527+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_5 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.533+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_7 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.564+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 14) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 12) in 100 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:13.568+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 15) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.569+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 13) in 103 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:13.624+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_8 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.631+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_9 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.660+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 16) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.661+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 14) in 98 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:13.663+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 17) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.664+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 15) in 95 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:13.724+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_10 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.725+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_11 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.755+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 18) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 17) in 93 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:13.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 19) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.759+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 16) in 99 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:13.814+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_12 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_13 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 20) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.846+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 18) in 91 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:13.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 21) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.848+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 19) in 91 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:13.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_15 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO BlockManagerInfo: Added rdd_20_14 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:13.959+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 22) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.960+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 21) in 113 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:13.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 23) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:13.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:13 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 20) in 121 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:14.021+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_16 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_17 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 24) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 22) in 100 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:14.069+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 25) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.070+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 23) in 105 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:14.116+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_18 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.123+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_19 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 26) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.146+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 24) in 90 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:14.153+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 27) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.154+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 25) in 85 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:14.200+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_20 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.205+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_21 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.227+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 28) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 26) in 83 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:14.233+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 29) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 27) in 81 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:14.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_22 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.290+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_23 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.317+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 30) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 28) in 90 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:14.325+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 31) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.326+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 29) in 94 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:14.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_24 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_25 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 32) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 30) in 84 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:14.409+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 33) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 31) in 84 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:14.460+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_26 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.463+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_27 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.495+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 34) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.495+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 32) in 96 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:14.497+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 35) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.498+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 33) in 89 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:14.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_28 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.575+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_29 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 36) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.601+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 34) in 107 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:14.608+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 37) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 35) in 112 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:14.671+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_30 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.673+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_31 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.702+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 38) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.703+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 36) in 103 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:14.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 39) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.708+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 37) in 100 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:14.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_32 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_33 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.791+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 40) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 39) in 85 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:14.795+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 41) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 38) in 95 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:14.838+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_34 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_35 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 42) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.872+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 40) in 81 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:14.881+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 43) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.882+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 41) in 86 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:14.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_36 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO BlockManagerInfo: Added rdd_20_37 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:14.964+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 44) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 42) in 95 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:14.979+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 45) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:14.980+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:14 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 43) in 99 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:15.014+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_38 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_39 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 46) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.041+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 44) in 78 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:15.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 47) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.058+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 45) in 80 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:15.083+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_40 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.117+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 48) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.117+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 46) in 78 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:15.122+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_41 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.149+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 49) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.150+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 47) in 94 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:15.157+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_43 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.182+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 50) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.183+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 48) in 66 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:15.193+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_44 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.220+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 51) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 49) in 71 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:15.243+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_45 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.266+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_46 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.268+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 52) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.269+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 50) in 86 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:15.297+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 53) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.298+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 51) in 78 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:15.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_48 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.341+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 52) in 76 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:15.346+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added rdd_20_49 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.7 MiB)
[2024-11-14T16:27:15.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 53) in 69 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:15.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2024-11-14T16:27:15.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: ShuffleMapStage 5 (toString at String.java:2951) finished in 3.463 s
[2024-11-14T16:27:15.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:15.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:15.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:15.370+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:15.408+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:27:15.409+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Got job 5 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:15.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Final stage: ResultStage 8 (toString at String.java:2951)
[2024-11-14T16:27:15.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2024-11-14T16:27:15.411+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:15.412+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:15.417+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 372.2 KiB, free 433.1 MiB)
[2024-11-14T16:27:15.419+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 91.5 KiB, free 433.0 MiB)
[2024-11-14T16:27:15.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7ea45ba85247:33227 (size: 91.5 KiB, free: 434.1 MiB)
[2024-11-14T16:27:15.421+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:15.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:15.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2024-11-14T16:27:15.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 54) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:15.435+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.8:35711 (size: 91.5 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:15.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.21.0.8:60634
[2024-11-14T16:27:15.516+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 54) in 93 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:15.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2024-11-14T16:27:15.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: ResultStage 8 (toString at String.java:2951) finished in 0.105 s
[2024-11-14T16:27:15.518+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:15.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2024-11-14T16:27:15.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO DAGScheduler: Job 5 finished: toString at String.java:2951, took 0.110074 s
[2024-11-14T16:27:15.589+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO CodeGenerator: Code generated in 39.857734 ms
[2024-11-14T16:27:15.591+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 7ea45ba85247:33227 in memory (size: 102.5 KiB, free: 434.2 MiB)
[2024-11-14T16:27:15.593+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.21.0.8:35711 in memory (size: 102.5 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:15.595+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO Snapshot: [tableId=f7b17352-9906-47ed-9026-e90b2d8bc72d] DELTA: Done
[2024-11-14T16:27:15.596+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO Snapshot: [tableId=7a36e4c8-a99b-4c5f-86d2-45a01f959a20] Created snapshot Snapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=0, metadata=Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000000.json; isDirectory=false; length=6809; replication=1; blocksize=33554432; modification_time=1731601507300; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=04fb253b333c0b6de82c46856b1fb2da versionId=null),List(),None,1731601507300), checksumOpt=None)
[2024-11-14T16:27:15.604+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 7ea45ba85247:33227 in memory (size: 91.5 KiB, free: 434.3 MiB)
[2024-11-14T16:27:15.605+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:15 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.8:35711 in memory (size: 91.5 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:16.103+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:16.104+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:16.104+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:27:16.114+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(keywords),IsNotNull(id)
[2024-11-14T16:27:16.114+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(keywords#1),isnotnull(id#0L)
[2024-11-14T16:27:16.115+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Output Data Schema: struct<id: bigint, keywords: string>
[2024-11-14T16:27:16.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:16.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(transform(from_json(ArrayType(StructType(StructField(name,StringType,true)),true), cast#322, Some(Etc/UTC)), lambdafunction(lambda x#334.name, lambda x#334, false))),isnotnull(id#324L)
[2024-11-14T16:27:16.121+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, crew: string, id: bigint ... 1 more fields>
[2024-11-14T16:27:16.212+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DeltaParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2024-11-14T16:27:16.253+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:16.283+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO CodeGenerator: Code generated in 17.019664 ms
[2024-11-14T16:27:16.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 206.0 KiB, free 433.7 MiB)
[2024-11-14T16:27:16.297+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 433.7 MiB)
[2024-11-14T16:27:16.299+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7ea45ba85247:33227 (size: 36.1 KiB, free: 434.3 MiB)
[2024-11-14T16:27:16.300+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO SparkContext: Created broadcast 9 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:16.301+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:16.313+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Registering RDD 30 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2024-11-14T16:27:16.313+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Got map stage job 6 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:27:16.314+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:16.315+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:16.315+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:16.316+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:16.317+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[30] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:16.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 31.5 KiB, free 433.7 MiB)
[2024-11-14T16:27:16.322+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 433.7 MiB)
[2024-11-14T16:27:16.324+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7ea45ba85247:33227 (size: 13.9 KiB, free: 434.3 MiB)
[2024-11-14T16:27:16.324+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:16.325+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[30] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:16.326+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2024-11-14T16:27:16.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 55) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4903 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:16.343+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.21.0.8:35711 (size: 13.9 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:16.344+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO CodeGenerator: Code generated in 21.85029 ms
[2024-11-14T16:27:16.353+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO CodeGenerator: Code generated in 6.447839 ms
[2024-11-14T16:27:16.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 206.1 KiB, free 433.4 MiB)
[2024-11-14T16:27:16.364+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 433.4 MiB)
[2024-11-14T16:27:16.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7ea45ba85247:33227 (size: 36.1 KiB, free: 434.2 MiB)
[2024-11-14T16:27:16.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO SparkContext: Created broadcast 11 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:16.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:16.383+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Registering RDD 38 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2024-11-14T16:27:16.384+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Got map stage job 7 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:16.385+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:16.385+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:16.386+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:16.387+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:16.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 49.7 KiB, free 433.4 MiB)
[2024-11-14T16:27:16.396+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 433.3 MiB)
[2024-11-14T16:27:16.398+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7ea45ba85247:33227 (size: 19.8 KiB, free: 434.2 MiB)
[2024-11-14T16:27:16.399+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:16.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[38] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:16.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks resource profile 0
[2024-11-14T16:27:16.402+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 56) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:16.415+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.21.0.8:35711 (size: 19.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:16.424+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.21.0.8:35711 (size: 36.1 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:16.527+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.21.0.8:35711 (size: 36.1 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:16.939+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 57) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:16.940+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 55) in 612 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:16.941+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2024-11-14T16:27:16.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: ShuffleMapStage 9 (save at NativeMethodAccessorImpl.java:0) finished in 0.625 s
[2024-11-14T16:27:16.943+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:16.943+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: running: Set(ShuffleMapStage 10)
[2024-11-14T16:27:16.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:16.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:16.958+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:16.959+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:16.960+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:27:16.977+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:16 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1480508, minimum partition size: 1048576
[2024-11-14T16:27:17.005+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 57) in 66 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:17.060+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 7ea45ba85247:33227 in memory (size: 13.9 KiB, free: 434.2 MiB)
[2024-11-14T16:27:17.062+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.21.0.8:35711 in memory (size: 13.9 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:17.073+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:17.075+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:27:17.076+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:27:17.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
[2024-11-14T16:27:17.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:17.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:27:17.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 29.2 KiB, free 433.4 MiB)
[2024-11-14T16:27:17.095+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 433.3 MiB)
[2024-11-14T16:27:17.097+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7ea45ba85247:33227 (size: 13.8 KiB, free: 434.2 MiB)
[2024-11-14T16:27:17.098+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:17.098+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:17.099+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks resource profile 0
[2024-11-14T16:27:17.101+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 58) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:17.115+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.21.0.8:35711 (size: 13.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:17.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.21.0.8:60634
[2024-11-14T16:27:17.655+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Added taskresult_58 in memory on 172.21.0.8:35711 (size: 2.5 MiB, free: 1046.2 MiB)
[2024-11-14T16:27:17.661+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 59) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:17.695+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TransportClientFactory: Successfully created connection to /172.21.0.8:35711 after 3 ms (0 ms spent in bootstraps)
[2024-11-14T16:27:17.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 58) in 650 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:17.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:17 INFO BlockManagerInfo: Removed taskresult_58 on 172.21.0.8:35711 in memory (size: 2.5 MiB, free: 1048.7 MiB)
[2024-11-14T16:27:18.168+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added taskresult_59 in memory on 172.21.0.8:35711 (size: 2.5 MiB, free: 1046.1 MiB)
[2024-11-14T16:27:18.192+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 59) in 530 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:18.193+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2024-11-14T16:27:18.194+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.103 s
[2024-11-14T16:27:18.195+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:18.195+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2024-11-14T16:27:18.196+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.120089 s
[2024-11-14T16:27:18.197+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Removed taskresult_59 on 172.21.0.8:35711 in memory (size: 2.5 MiB, free: 1048.7 MiB)
[2024-11-14T16:27:18.243+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO CodeGenerator: Code generated in 23.245642 ms
[2024-11-14T16:27:18.289+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 7ea45ba85247:33227 in memory (size: 13.8 KiB, free: 434.2 MiB)
[2024-11-14T16:27:18.292+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.21.0.8:35711 in memory (size: 13.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:18.355+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.0 MiB, free 415.4 MiB)
[2024-11-14T16:27:18.425+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 411.4 MiB)
[2024-11-14T16:27:18.426+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7ea45ba85247:33227 (size: 4.0 MiB, free: 430.2 MiB)
[2024-11-14T16:27:18.428+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_14_piece1 stored as bytes in memory (estimated size 1563.5 KiB, free 409.9 MiB)
[2024-11-14T16:27:18.429+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_14_piece1 in memory on 7ea45ba85247:33227 (size: 1563.5 KiB, free: 428.7 MiB)
[2024-11-14T16:27:18.430+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:18.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:18.442+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:18.443+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 15 more fields>
[2024-11-14T16:27:18.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO CodeGenerator: Code generated in 14.30626 ms
[2024-11-14T16:27:18.541+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO CodeGenerator: Code generated in 18.433574 ms
[2024-11-14T16:27:18.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 208.0 KiB, free 409.7 MiB)
[2024-11-14T16:27:18.560+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 409.6 MiB)
[2024-11-14T16:27:18.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7ea45ba85247:33227 (size: 36.5 KiB, free: 428.7 MiB)
[2024-11-14T16:27:18.563+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO SparkContext: Created broadcast 15 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:18.564+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10691623 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:18.582+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Registering RDD 47 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2024-11-14T16:27:18.583+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Got map stage job 9 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:18.583+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:18.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:18.585+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:18.586+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[47] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:18.660+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 51.6 KiB, free 409.6 MiB)
[2024-11-14T16:27:18.671+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 409.6 MiB)
[2024-11-14T16:27:18.671+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7ea45ba85247:33227 (size: 19.5 KiB, free: 428.7 MiB)
[2024-11-14T16:27:18.673+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:18.673+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[47] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:18.674+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks resource profile 0
[2024-11-14T16:27:18.676+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 60) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:18.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.21.0.8:35711 (size: 19.5 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:18.846+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.21.0.8:35711 (size: 4.0 MiB, free: 1044.7 MiB)
[2024-11-14T16:27:18.865+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_14_piece1 in memory on 172.21.0.8:35711 (size: 1563.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:18.913+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.21.0.8:35711 (size: 36.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:21.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 61) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:21.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 56) in 4736 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:21.138+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2024-11-14T16:27:21.139+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: ShuffleMapStage 10 (save at NativeMethodAccessorImpl.java:0) finished in 4.753 s
[2024-11-14T16:27:21.140+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:21.141+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: running: Set(ShuffleMapStage 13)
[2024-11-14T16:27:21.142+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:21.143+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:21.150+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 5348362, minimum partition size: 1048576
[2024-11-14T16:27:21.179+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:21.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 61) in 73 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:21.217+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO CodeGenerator: Code generated in 32.745823 ms
[2024-11-14T16:27:21.233+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Registering RDD 50 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2024-11-14T16:27:21.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Got map stage job 10 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:21.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:21.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2024-11-14T16:27:21.237+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:21.237+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[50] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:21.245+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 49.8 KiB, free 409.5 MiB)
[2024-11-14T16:27:21.254+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.1 KiB, free 409.5 MiB)
[2024-11-14T16:27:21.255+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7ea45ba85247:33227 (size: 20.1 KiB, free: 428.6 MiB)
[2024-11-14T16:27:21.256+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:21.256+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[50] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:21.257+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks resource profile 0
[2024-11-14T16:27:21.259+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 62) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:21.273+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.21.0.8:35711 (size: 20.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:21.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.21.0.8:60634
[2024-11-14T16:27:21.308+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 7ea45ba85247:33227 in memory (size: 19.8 KiB, free: 428.7 MiB)
[2024-11-14T16:27:21.310+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.21.0.8:35711 in memory (size: 19.8 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:21.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 63) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:21.369+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 60) in 2694 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:21.370+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2024-11-14T16:27:21.371+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: ShuffleMapStage 13 (save at NativeMethodAccessorImpl.java:0) finished in 2.785 s
[2024-11-14T16:27:21.372+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:21.373+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: running: Set(ShuffleMapStage 15)
[2024-11-14T16:27:21.374+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:21.375+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:21.477+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 62) in 218 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:21.521+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 63) in 152 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:21.521+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2024-11-14T16:27:21.522+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: ShuffleMapStage 15 (save at NativeMethodAccessorImpl.java:0) finished in 0.279 s
[2024-11-14T16:27:21.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:21.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:21.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:21.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:21.536+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO ShufflePartitionsUtil: For shuffle(4, 5), advisory target size: 67108864, actual target size 19218441, minimum partition size: 1048576
[2024-11-14T16:27:21.602+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO CodeGenerator: Code generated in 40.573906 ms
[2024-11-14T16:27:21.603+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 7ea45ba85247:33227 in memory (size: 20.1 KiB, free: 428.7 MiB)
[2024-11-14T16:27:21.606+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.21.0.8:35711 in memory (size: 20.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:21.612+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 7ea45ba85247:33227 in memory (size: 19.5 KiB, free: 428.7 MiB)
[2024-11-14T16:27:21.614+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.21.0.8:35711 in memory (size: 19.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:21.616+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO CodeGenerator: Code generated in 10.177069 ms
[2024-11-14T16:27:21.636+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO CodeGenerator: Code generated in 6.783532 ms
[2024-11-14T16:27:21.728+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:21.729+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Got job 11 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:21.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Final stage: ResultStage 19 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:21.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17, ShuffleMapStage 18)
[2024-11-14T16:27:21.731+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:21.732+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[56] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:21.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 434.7 KiB, free 409.3 MiB)
[2024-11-14T16:27:21.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 153.1 KiB, free 409.1 MiB)
[2024-11-14T16:27:21.767+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7ea45ba85247:33227 (size: 153.1 KiB, free: 428.5 MiB)
[2024-11-14T16:27:21.768+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:21.769+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 19 (MapPartitionsRDD[56] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:21.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
[2024-11-14T16:27:21.775+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 64) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4739 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:21.776+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 65) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4739 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:21.790+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.21.0.8:35711 (size: 153.1 KiB, free: 1043.0 MiB)
[2024-11-14T16:27:21.914+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.21.0.8:60634
[2024-11-14T16:27:21.940+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.21.0.8:60634
[2024-11-14T16:27:24.073+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 65) in 2298 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:24.074+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 64) in 2302 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:24.075+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2024-11-14T16:27:24.076+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: ResultStage 19 (save at NativeMethodAccessorImpl.java:0) finished in 2.339 s
[2024-11-14T16:27:24.076+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:24.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
[2024-11-14T16:27:24.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Job 11 finished: save at NativeMethodAccessorImpl.java:0, took 2.348824 s
[2024-11-14T16:27:24.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO FileFormatWriter: Start to commit write Job be52c61d-66f3-4357-9032-c2c46bfb1f05.
[2024-11-14T16:27:24.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO FileFormatWriter: Write Job be52c61d-66f3-4357-9032-c2c46bfb1f05 committed. Elapsed time: 1 ms.
[2024-11-14T16:27:24.086+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO FileFormatWriter: Finished processing stats for write job be52c61d-66f3-4357-9032-c2c46bfb1f05.
[2024-11-14T16:27:24.155+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 7ea45ba85247:33227 in memory (size: 153.1 KiB, free: 428.7 MiB)
[2024-11-14T16:27:24.156+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.21.0.8:35711 in memory (size: 153.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:24.351+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO CodeGenerator: Code generated in 78.47563 ms
[2024-11-14T16:27:24.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2024-11-14T16:27:24.395+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Got job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2024-11-14T16:27:24.396+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Final stage: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2024-11-14T16:27:24.396+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
[2024-11-14T16:27:24.397+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:24.398+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[58] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2024-11-14T16:27:24.403+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 475.0 KiB, free 409.2 MiB)
[2024-11-14T16:27:24.413+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 112.4 KiB, free 409.1 MiB)
[2024-11-14T16:27:24.415+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 7ea45ba85247:33227 (size: 112.4 KiB, free: 428.6 MiB)
[2024-11-14T16:27:24.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:24.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 21 (MapPartitionsRDD[58] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:24.417+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSchedulerImpl: Adding task set 21.0 with 50 tasks resource profile 0
[2024-11-14T16:27:24.421+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 66) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.421+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 67) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.21.0.8:35711 (size: 112.4 KiB, free: 1043.0 MiB)
[2024-11-14T16:27:24.628+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 68) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.629+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 67) in 207 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:24.630+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 69) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.631+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 66) in 209 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:24.643+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 70) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.644+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 68) in 16 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:24.645+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 71) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.646+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 69) in 16 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:24.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 72) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.658+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 70) in 14 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:24.659+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 73) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.660+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 71) in 15 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:24.672+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 8.0 in stage 21.0 (TID 74) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.673+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 72) in 15 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:24.674+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 9.0 in stage 21.0 (TID 75) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.675+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 73) in 16 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:24.687+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 10.0 in stage 21.0 (TID 76) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.687+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 8.0 in stage 21.0 (TID 74) in 16 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:24.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 11.0 in stage 21.0 (TID 77) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 9.0 in stage 21.0 (TID 75) in 17 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:24.700+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 12.0 in stage 21.0 (TID 78) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 10.0 in stage 21.0 (TID 76) in 14 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:24.703+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 13.0 in stage 21.0 (TID 79) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.704+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 11.0 in stage 21.0 (TID 77) in 15 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:24.718+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 14.0 in stage 21.0 (TID 80) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.719+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 12.0 in stage 21.0 (TID 78) in 19 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:24.721+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 15.0 in stage 21.0 (TID 81) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.722+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 13.0 in stage 21.0 (TID 79) in 19 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:24.734+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 16.0 in stage 21.0 (TID 82) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 14.0 in stage 21.0 (TID 80) in 18 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:24.736+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 17.0 in stage 21.0 (TID 83) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.737+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 15.0 in stage 21.0 (TID 81) in 15 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:24.748+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 18.0 in stage 21.0 (TID 84) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.749+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 16.0 in stage 21.0 (TID 82) in 15 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:24.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 19.0 in stage 21.0 (TID 85) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 17.0 in stage 21.0 (TID 83) in 15 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:24.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 20.0 in stage 21.0 (TID 86) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 19.0 in stage 21.0 (TID 85) in 15 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:24.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 21.0 in stage 21.0 (TID 87) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.767+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 18.0 in stage 21.0 (TID 84) in 18 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:24.778+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 22.0 in stage 21.0 (TID 88) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 20.0 in stage 21.0 (TID 86) in 14 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:24.780+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 23.0 in stage 21.0 (TID 89) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.781+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 21.0 in stage 21.0 (TID 87) in 15 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:24.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 24.0 in stage 21.0 (TID 90) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.794+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 22.0 in stage 21.0 (TID 88) in 16 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:24.795+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 25.0 in stage 21.0 (TID 91) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 23.0 in stage 21.0 (TID 89) in 16 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:24.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 26.0 in stage 21.0 (TID 92) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 24.0 in stage 21.0 (TID 90) in 14 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:24.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 27.0 in stage 21.0 (TID 93) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.809+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 25.0 in stage 21.0 (TID 91) in 15 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:24.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 28.0 in stage 21.0 (TID 94) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.824+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 27.0 in stage 21.0 (TID 93) in 15 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:24.824+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 29.0 in stage 21.0 (TID 95) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.825+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 26.0 in stage 21.0 (TID 92) in 19 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:24.836+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 30.0 in stage 21.0 (TID 96) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.837+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 28.0 in stage 21.0 (TID 94) in 15 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:24.838+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 31.0 in stage 21.0 (TID 97) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.839+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 29.0 in stage 21.0 (TID 95) in 14 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:24.856+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 32.0 in stage 21.0 (TID 98) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.857+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 30.0 in stage 21.0 (TID 96) in 20 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:24.857+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 33.0 in stage 21.0 (TID 99) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.858+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 31.0 in stage 21.0 (TID 97) in 21 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:24.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 34.0 in stage 21.0 (TID 100) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 32.0 in stage 21.0 (TID 98) in 14 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:24.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 35.0 in stage 21.0 (TID 101) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 33.0 in stage 21.0 (TID 99) in 14 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:24.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 36.0 in stage 21.0 (TID 102) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 34.0 in stage 21.0 (TID 100) in 17 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:24.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 37.0 in stage 21.0 (TID 103) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 35.0 in stage 21.0 (TID 101) in 16 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:24.901+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 38.0 in stage 21.0 (TID 104) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.902+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 36.0 in stage 21.0 (TID 102) in 17 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:24.905+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 39.0 in stage 21.0 (TID 105) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.906+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 37.0 in stage 21.0 (TID 103) in 19 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:24.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 40.0 in stage 21.0 (TID 106) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 38.0 in stage 21.0 (TID 104) in 15 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:24.921+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 41.0 in stage 21.0 (TID 107) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.922+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 39.0 in stage 21.0 (TID 105) in 17 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:24.933+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 42.0 in stage 21.0 (TID 108) (172.21.0.8, executor 0, partition 42, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.934+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 41.0 in stage 21.0 (TID 107) in 14 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:24.935+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 43.0 in stage 21.0 (TID 109) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 40.0 in stage 21.0 (TID 106) in 20 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:24.948+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 44.0 in stage 21.0 (TID 110) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.948+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 42.0 in stage 21.0 (TID 108) in 15 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:24.949+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 45.0 in stage 21.0 (TID 111) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.950+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 43.0 in stage 21.0 (TID 109) in 15 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:24.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 46.0 in stage 21.0 (TID 112) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.966+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 44.0 in stage 21.0 (TID 110) in 18 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:24.967+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 47.0 in stage 21.0 (TID 113) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.968+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 45.0 in stage 21.0 (TID 111) in 19 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:24.977+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 48.0 in stage 21.0 (TID 114) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.978+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 47.0 in stage 21.0 (TID 113) in 12 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:24.979+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Starting task 49.0 in stage 21.0 (TID 115) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:24.980+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:24 INFO TaskSetManager: Finished task 46.0 in stage 21.0 (TID 112) in 14 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:25.001+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Finished task 48.0 in stage 21.0 (TID 114) in 24 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:25.002+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Finished task 49.0 in stage 21.0 (TID 115) in 24 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:25.003+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2024-11-14T16:27:25.003+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.604 s
[2024-11-14T16:27:25.004+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:25.005+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
[2024-11-14T16:27:25.006+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Job 12 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.609980 s
[2024-11-14T16:27:25.036+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO CodeGenerator: Code generated in 27.816906 ms
[2024-11-14T16:27:25.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO OptimisticTransaction: [tableId=8cec6fce,txnId=52baa3d5] Attempting to commit version 1 with 5 actions with Serializable isolation level
[2024-11-14T16:27:25.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DeltaLog: Creating a new snapshot v1 for commit version 1
[2024-11-14T16:27:25.434+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DeltaLog: Loading version 1.
[2024-11-14T16:27:25.438+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO Snapshot: [tableId=8cec6fce-9efc-43ac-80a3-ad3c71f057c8] DELTA: Compute snapshot for version: 1
[2024-11-14T16:27:25.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 204.4 KiB, free 408.9 MiB)
[2024-11-14T16:27:25.453+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 408.9 MiB)
[2024-11-14T16:27:25.455+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 7ea45ba85247:33227 (size: 35.6 KiB, free: 428.6 MiB)
[2024-11-14T16:27:25.456+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO SparkContext: Created broadcast 20 from toString at String.java:2951
[2024-11-14T16:27:25.457+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 11604)
[2024-11-14T16:27:25.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 7ea45ba85247:33227 in memory (size: 112.4 KiB, free: 428.7 MiB)
[2024-11-14T16:27:25.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.21.0.8:35711 in memory (size: 112.4 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:25.666+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:27:25.667+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:27:25.668+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:27:25.726+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 204.7 KiB, free 409.3 MiB)
[2024-11-14T16:27:25.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 409.2 MiB)
[2024-11-14T16:27:25.749+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 7ea45ba85247:33227 (size: 35.7 KiB, free: 428.6 MiB)
[2024-11-14T16:27:25.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO SparkContext: Created broadcast 21 from toString at String.java:2951
[2024-11-14T16:27:25.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4200106 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:25.767+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Registering RDD 62 (toString at String.java:2951) as input to shuffle 6
[2024-11-14T16:27:25.768+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Got map stage job 13 (toString at String.java:2951) with 2 output partitions
[2024-11-14T16:27:25.769+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (toString at String.java:2951)
[2024-11-14T16:27:25.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:25.771+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:25.771+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[62] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:25.776+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 124.3 KiB, free 409.1 MiB)
[2024-11-14T16:27:25.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 409.1 MiB)
[2024-11-14T16:27:25.780+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 7ea45ba85247:33227 (size: 35.1 KiB, free: 428.6 MiB)
[2024-11-14T16:27:25.781+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:25.781+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[62] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:25.782+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks resource profile 0
[2024-11-14T16:27:25.783+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 116) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:25.783+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 117) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:25.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.21.0.8:35711 (size: 35.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:25.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.21.0.8:35711 (size: 35.7 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:25.850+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 116) in 67 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:25.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 117) in 68 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:25.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2024-11-14T16:27:25.852+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: ShuffleMapStage 22 (toString at String.java:2951) finished in 0.081 s
[2024-11-14T16:27:25.853+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:25.853+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:25.854+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:25.854+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:25.895+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 7ea45ba85247:33227 in memory (size: 35.1 KiB, free: 428.6 MiB)
[2024-11-14T16:27:25.896+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:25 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.21.0.8:35711 in memory (size: 35.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:26.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Registering RDD 72 (toString at String.java:2951) as input to shuffle 7
[2024-11-14T16:27:26.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Got map stage job 14 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:27:26.054+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (toString at String.java:2951)
[2024-11-14T16:27:26.054+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2024-11-14T16:27:26.055+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:26.056+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[72] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:26.106+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 426.3 KiB, free 408.8 MiB)
[2024-11-14T16:27:26.108+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 102.5 KiB, free 408.7 MiB)
[2024-11-14T16:27:26.117+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 7ea45ba85247:33227 (size: 102.5 KiB, free: 428.5 MiB)
[2024-11-14T16:27:26.117+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:26.118+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[72] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:26.119+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSchedulerImpl: Adding task set 24.0 with 50 tasks resource profile 0
[2024-11-14T16:27:26.119+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 6.0 in stage 24.0 (TID 118) (172.21.0.8, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 41.0 in stage 24.0 (TID 119) (172.21.0.8, executor 0, partition 41, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.130+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.21.0.8:35711 (size: 102.5 KiB, free: 1043.0 MiB)
[2024-11-14T16:27:26.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.21.0.8:60634
[2024-11-14T16:27:26.180+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_41 in memory on 172.21.0.8:35711 (size: 1364.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.181+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_6 in memory on 172.21.0.8:35711 (size: 293.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.215+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 42.0 in stage 24.0 (TID 120) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.216+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 41.0 in stage 24.0 (TID 119) in 96 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:26.231+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 46.0 in stage 24.0 (TID 121) (172.21.0.8, executor 0, partition 46, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 6.0 in stage 24.0 (TID 118) in 113 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:26.258+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_42 in memory on 172.21.0.8:35711 (size: 806.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.269+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_46 in memory on 172.21.0.8:35711 (size: 1348.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.275+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 47.0 in stage 24.0 (TID 122) (172.21.0.8, executor 0, partition 47, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.276+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 42.0 in stage 24.0 (TID 120) in 62 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:26.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 123) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 46.0 in stage 24.0 (TID 121) in 57 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:26.310+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_47 in memory on 172.21.0.8:35711 (size: 294.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.320+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_0 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.327+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 124) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 47.0 in stage 24.0 (TID 122) in 52 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:26.338+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 125) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.338+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 123) in 51 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:26.360+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_1 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.370+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_2 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.377+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 126) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.378+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 124) in 50 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:26.391+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 4.0 in stage 24.0 (TID 127) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.392+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 125) in 54 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:26.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_3 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.428+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_4 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.432+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 5.0 in stage 24.0 (TID 128) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 126) in 56 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:26.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 7.0 in stage 24.0 (TID 129) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.448+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 4.0 in stage 24.0 (TID 127) in 58 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:26.467+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_5 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.480+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_7 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.484+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 8.0 in stage 24.0 (TID 130) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 5.0 in stage 24.0 (TID 128) in 52 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:26.501+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 9.0 in stage 24.0 (TID 131) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.502+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 7.0 in stage 24.0 (TID 129) in 55 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:26.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_8 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.538+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_9 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.544+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 10.0 in stage 24.0 (TID 132) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 8.0 in stage 24.0 (TID 130) in 62 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:26.567+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 11.0 in stage 24.0 (TID 133) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.568+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 9.0 in stage 24.0 (TID 131) in 67 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:26.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_10 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_11 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.603+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 12.0 in stage 24.0 (TID 134) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.604+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 10.0 in stage 24.0 (TID 132) in 61 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:26.618+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 13.0 in stage 24.0 (TID 135) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.619+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 11.0 in stage 24.0 (TID 133) in 51 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:26.640+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_12 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.649+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_13 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.655+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 14.0 in stage 24.0 (TID 136) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.656+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 12.0 in stage 24.0 (TID 134) in 52 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:26.666+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 15.0 in stage 24.0 (TID 137) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.667+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 13.0 in stage 24.0 (TID 135) in 49 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:26.686+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_14 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.697+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_15 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.706+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 16.0 in stage 24.0 (TID 138) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 14.0 in stage 24.0 (TID 136) in 52 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:26.716+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 17.0 in stage 24.0 (TID 139) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.717+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 15.0 in stage 24.0 (TID 137) in 51 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:26.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_16 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_17 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.759+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 18.0 in stage 24.0 (TID 140) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.759+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 16.0 in stage 24.0 (TID 138) in 54 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:26.774+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 19.0 in stage 24.0 (TID 141) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.775+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 17.0 in stage 24.0 (TID 139) in 59 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:26.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_18 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.810+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_19 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.813+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 20.0 in stage 24.0 (TID 142) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.814+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 18.0 in stage 24.0 (TID 140) in 56 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:26.827+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 21.0 in stage 24.0 (TID 143) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.828+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 19.0 in stage 24.0 (TID 141) in 54 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:26.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_20 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.862+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_21 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.863+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 22.0 in stage 24.0 (TID 144) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.864+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 20.0 in stage 24.0 (TID 142) in 51 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:26.883+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 23.0 in stage 24.0 (TID 145) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 21.0 in stage 24.0 (TID 143) in 56 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:26.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_22 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.920+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 24.0 in stage 24.0 (TID 146) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.921+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 22.0 in stage 24.0 (TID 144) in 57 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:26.929+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_23 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.951+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 25.0 in stage 24.0 (TID 147) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.952+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 23.0 in stage 24.0 (TID 145) in 68 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:26.956+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_24 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:26.973+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Starting task 26.0 in stage 24.0 (TID 148) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:26.974+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO TaskSetManager: Finished task 24.0 in stage 24.0 (TID 146) in 54 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:26.990+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:26 INFO BlockManagerInfo: Added rdd_69_25 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.013+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_26 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.016+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 27.0 in stage 24.0 (TID 149) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.017+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 25.0 in stage 24.0 (TID 147) in 67 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:27.038+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 28.0 in stage 24.0 (TID 150) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.040+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 26.0 in stage 24.0 (TID 148) in 66 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:27.066+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_27 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.083+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_28 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.095+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 29.0 in stage 24.0 (TID 151) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.096+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 27.0 in stage 24.0 (TID 149) in 79 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:27.108+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 30.0 in stage 24.0 (TID 152) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 28.0 in stage 24.0 (TID 150) in 70 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:27.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_29 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.164+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_30 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.179+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 31.0 in stage 24.0 (TID 153) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.180+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 29.0 in stage 24.0 (TID 151) in 85 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:27.196+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 32.0 in stage 24.0 (TID 154) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.197+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 30.0 in stage 24.0 (TID 152) in 90 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:27.232+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_31 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.243+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_32 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.257+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 33.0 in stage 24.0 (TID 155) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.258+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 31.0 in stage 24.0 (TID 153) in 79 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:27.267+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 34.0 in stage 24.0 (TID 156) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.268+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 32.0 in stage 24.0 (TID 154) in 71 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:27.305+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_33 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.311+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_34 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.327+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 35.0 in stage 24.0 (TID 157) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.328+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 33.0 in stage 24.0 (TID 155) in 72 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:27.332+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 36.0 in stage 24.0 (TID 158) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.333+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 34.0 in stage 24.0 (TID 156) in 67 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:27.364+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_35 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.372+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_36 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.382+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 37.0 in stage 24.0 (TID 159) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.383+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 35.0 in stage 24.0 (TID 157) in 56 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:27.395+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 38.0 in stage 24.0 (TID 160) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.396+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 36.0 in stage 24.0 (TID 158) in 63 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:27.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_37 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_38 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.441+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 39.0 in stage 24.0 (TID 161) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.442+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 37.0 in stage 24.0 (TID 159) in 60 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:27.455+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 40.0 in stage 24.0 (TID 162) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.456+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 38.0 in stage 24.0 (TID 160) in 62 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:27.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_39 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.496+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_40 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 43.0 in stage 24.0 (TID 163) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.516+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 39.0 in stage 24.0 (TID 161) in 74 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:27.519+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 44.0 in stage 24.0 (TID 164) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.521+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 40.0 in stage 24.0 (TID 162) in 65 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:27.552+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_43 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_44 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.574+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 45.0 in stage 24.0 (TID 165) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.575+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 43.0 in stage 24.0 (TID 163) in 61 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:27.587+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 48.0 in stage 24.0 (TID 166) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.588+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 44.0 in stage 24.0 (TID 164) in 68 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:27.620+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_45 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.637+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_48 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.641+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 49.0 in stage 24.0 (TID 167) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.642+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 45.0 in stage 24.0 (TID 165) in 67 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:27.654+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 48.0 in stage 24.0 (TID 166) in 68 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:27.672+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added rdd_69_49 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1043.0 MiB)
[2024-11-14T16:27:27.687+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 49.0 in stage 24.0 (TID 167) in 46 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:27.688+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2024-11-14T16:27:27.689+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: ShuffleMapStage 24 (toString at String.java:2951) finished in 1.632 s
[2024-11-14T16:27:27.689+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:27.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:27.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:27.692+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:27.725+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:27:27.727+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Got job 15 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:27.728+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 7ea45ba85247:33227 in memory (size: 102.5 KiB, free: 428.6 MiB)
[2024-11-14T16:27:27.729+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Final stage: ResultStage 27 (toString at String.java:2951)
[2024-11-14T16:27:27.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2024-11-14T16:27:27.731+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:27.732+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[75] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:27.733+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.21.0.8:35711 in memory (size: 102.5 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:27.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 372.4 KiB, free 408.9 MiB)
[2024-11-14T16:27:27.738+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 408.8 MiB)
[2024-11-14T16:27:27.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 7ea45ba85247:33227 (size: 91.6 KiB, free: 428.5 MiB)
[2024-11-14T16:27:27.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:27.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[75] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:27.741+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2024-11-14T16:27:27.742+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 168) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:27.754+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.21.0.8:35711 (size: 91.6 KiB, free: 1043.0 MiB)
[2024-11-14T16:27:27.770+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.21.0.8:60634
[2024-11-14T16:27:27.803+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 168) in 62 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:27.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2024-11-14T16:27:27.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: ResultStage 27 (toString at String.java:2951) finished in 0.074 s
[2024-11-14T16:27:27.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:27.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2024-11-14T16:27:27.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DAGScheduler: Job 15 finished: toString at String.java:2951, took 0.080089 s
[2024-11-14T16:27:27.816+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO Snapshot: [tableId=8cec6fce-9efc-43ac-80a3-ad3c71f057c8] DELTA: Done
[2024-11-14T16:27:27.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO Snapshot: [tableId=8cec6fce-9efc-43ac-80a3-ad3c71f057c8] Created snapshot Snapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=1, metadata=Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000000.json; isDirectory=false; length=6809; replication=1; blocksize=33554432; modification_time=1731601507300; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=04fb253b333c0b6de82c46856b1fb2da versionId=null, S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000001.json; isDirectory=false; length=4795; replication=1; blocksize=33554432; modification_time=1731601645383; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=e83f27b2d8832c609a1928b25b8469e5 versionId=null),List(),None,1731601645383), checksumOpt=None)
[2024-11-14T16:27:27.818+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log, version=1, metadata=Metadata(8cec6fce-9efc-43ac-80a3-ad3c71f057c8,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres","type":"string","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"original_title","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"popularity","type":"string","nullable":true,"metadata":{}},{"name":"poster_path","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"tagline","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"keywords","type":"string","nullable":true,"metadata":{}},{"name":"keyword_convert","type":"string","nullable":true,"metadata":{}},{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601488594)), logSegment=LogSegment(s3a://lakehouse/merge_data-movies/merged_data/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000000.json; isDirectory=false; length=6809; replication=1; blocksize=33554432; modification_time=1731601507300; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=04fb253b333c0b6de82c46856b1fb2da versionId=null, S3AFileStatus{path=s3a://lakehouse/merge_data-movies/merged_data/_delta_log/00000000000000000001.json; isDirectory=false; length=4795; replication=1; blocksize=33554432; modification_time=1731601645383; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=e83f27b2d8832c609a1928b25b8469e5 versionId=null),List(),None,1731601645383), checksumOpt=None)
[2024-11-14T16:27:27.820+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MapPartitionsRDD: Removing RDD 20 from persistence list
[2024-11-14T16:27:27.829+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManager: Removing RDD 20
[2024-11-14T16:27:27.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO OptimisticTransaction: [tableId=8cec6fce,txnId=52baa3d5] Committed delta #1 to s3a://lakehouse/merge_data-movies/merged_data/_delta_log
[2024-11-14T16:27:27.960+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DeltaLog: Loading version 0.
[2024-11-14T16:27:27.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO Snapshot: [tableId=bd77b65e-46ef-4c0f-bd48-7d65a7793a99] DELTA: Compute snapshot for version: 0
[2024-11-14T16:27:27.968+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 204.4 KiB, free 408.6 MiB)
[2024-11-14T16:27:27.983+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 7ea45ba85247:33227 in memory (size: 91.6 KiB, free: 428.6 MiB)
[2024-11-14T16:27:27.984+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.21.0.8:35711 in memory (size: 91.6 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:27.985+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 409.0 MiB)
[2024-11-14T16:27:27.986+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 7ea45ba85247:33227 (size: 35.6 KiB, free: 428.6 MiB)
[2024-11-14T16:27:27.987+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO SparkContext: Created broadcast 25 from toString at String.java:2951
[2024-11-14T16:27:27.988+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:27 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3008)
[2024-11-14T16:27:28.026+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 7ea45ba85247:33227 in memory (size: 36.1 KiB, free: 428.6 MiB)
[2024-11-14T16:27:28.027+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.21.0.8:35711 in memory (size: 36.1 KiB, free: 1043.1 MiB)
[2024-11-14T16:27:28.035+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManager: Removing RDD 20
[2024-11-14T16:27:28.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7ea45ba85247:33227 in memory (size: 35.5 KiB, free: 428.7 MiB)
[2024-11-14T16:27:28.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 7ea45ba85247:33227 in memory (size: 36.1 KiB, free: 428.7 MiB)
[2024-11-14T16:27:28.060+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.21.0.8:35711 in memory (size: 36.1 KiB, free: 1043.2 MiB)
[2024-11-14T16:27:28.065+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 7ea45ba85247:33227 in memory (size: 35.6 KiB, free: 428.7 MiB)
[2024-11-14T16:27:28.067+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.21.0.8:35711 in memory (size: 35.6 KiB, free: 1043.2 MiB)
[2024-11-14T16:27:28.072+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_14_piece1 on 7ea45ba85247:33227 in memory (size: 1563.5 KiB, free: 430.3 MiB)
[2024-11-14T16:27:28.074+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 7ea45ba85247:33227 in memory (size: 4.0 MiB, free: 434.3 MiB)
[2024-11-14T16:27:28.075+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_14_piece1 on 172.21.0.8:35711 in memory (size: 1563.5 KiB, free: 1044.7 MiB)
[2024-11-14T16:27:28.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.21.0.8:35711 in memory (size: 4.0 MiB, free: 1048.7 MiB)
[2024-11-14T16:27:28.083+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 7ea45ba85247:33227 in memory (size: 36.5 KiB, free: 434.3 MiB)
[2024-11-14T16:27:28.085+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.21.0.8:35711 in memory (size: 36.5 KiB, free: 1048.8 MiB)
[2024-11-14T16:27:28.210+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:27:28.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:27:28.212+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:27:28.261+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 204.7 KiB, free 433.5 MiB)
[2024-11-14T16:27:28.268+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 433.5 MiB)
[2024-11-14T16:27:28.269+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 7ea45ba85247:33227 (size: 35.7 KiB, free: 434.3 MiB)
[2024-11-14T16:27:28.270+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO SparkContext: Created broadcast 26 from toString at String.java:2951
[2024-11-14T16:27:28.271+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:28.281+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Registering RDD 79 (toString at String.java:2951) as input to shuffle 8
[2024-11-14T16:27:28.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Got map stage job 16 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:28.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (toString at String.java:2951)
[2024-11-14T16:27:28.283+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:28.284+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:28.284+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[79] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:28.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 124.3 KiB, free 433.3 MiB)
[2024-11-14T16:27:28.291+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 433.3 MiB)
[2024-11-14T16:27:28.292+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 7ea45ba85247:33227 (size: 35.2 KiB, free: 434.2 MiB)
[2024-11-14T16:27:28.293+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:28.293+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[79] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:28.294+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2024-11-14T16:27:28.295+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 169) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4931 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.305+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.21.0.8:35711 (size: 35.2 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:28.324+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.21.0.8:35711 (size: 35.7 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:28.363+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 169) in 69 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:28.364+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2024-11-14T16:27:28.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: ShuffleMapStage 28 (toString at String.java:2951) finished in 0.081 s
[2024-11-14T16:27:28.365+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:28.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:28.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:28.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:28.411+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 7ea45ba85247:33227 in memory (size: 35.2 KiB, free: 434.3 MiB)
[2024-11-14T16:27:28.412+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.21.0.8:35711 in memory (size: 35.2 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:28.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Registering RDD 89 (toString at String.java:2951) as input to shuffle 9
[2024-11-14T16:27:28.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Got map stage job 17 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:27:28.525+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Final stage: ShuffleMapStage 30 (toString at String.java:2951)
[2024-11-14T16:27:28.525+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2024-11-14T16:27:28.526+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:28.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[89] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:28.575+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 426.2 KiB, free 433.0 MiB)
[2024-11-14T16:27:28.577+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 102.5 KiB, free 432.9 MiB)
[2024-11-14T16:27:28.578+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 7ea45ba85247:33227 (size: 102.5 KiB, free: 434.2 MiB)
[2024-11-14T16:27:28.579+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:28.579+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[89] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:28.580+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 50 tasks resource profile 0
[2024-11-14T16:27:28.581+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 22.0 in stage 30.0 (TID 170) (172.21.0.8, executor 0, partition 22, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.581+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 42.0 in stage 30.0 (TID 171) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.590+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.21.0.8:35711 (size: 102.5 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:28.602+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.21.0.8:60634
[2024-11-14T16:27:28.629+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_22 in memory on 172.21.0.8:35711 (size: 879.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.630+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_42 in memory on 172.21.0.8:35711 (size: 683.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.648+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 172) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.649+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 42.0 in stage 30.0 (TID 171) in 67 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:28.650+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 173) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.650+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 22.0 in stage 30.0 (TID 170) in 70 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:28.679+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_0 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.681+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_1 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.697+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 174) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.697+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 173) in 48 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:28.698+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 175) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 172) in 50 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:28.726+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_2 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_3 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 176) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.741+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 174) in 45 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:28.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 5.0 in stage 30.0 (TID 177) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.746+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 175) in 47 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:28.773+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_4 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.777+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_5 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.789+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 6.0 in stage 30.0 (TID 178) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.789+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 176) in 49 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:28.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 7.0 in stage 30.0 (TID 179) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.793+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 5.0 in stage 30.0 (TID 177) in 48 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:28.827+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_6 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.828+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_7 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 8.0 in stage 30.0 (TID 180) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.846+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 7.0 in stage 30.0 (TID 179) in 54 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:28.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 9.0 in stage 30.0 (TID 181) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.848+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 6.0 in stage 30.0 (TID 178) in 60 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:28.879+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_8 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.879+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_9 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.893+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 10.0 in stage 30.0 (TID 182) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.894+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 8.0 in stage 30.0 (TID 180) in 48 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:28.895+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 11.0 in stage 30.0 (TID 183) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.896+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 9.0 in stage 30.0 (TID 181) in 48 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:28.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_10 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_11 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 12.0 in stage 30.0 (TID 184) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.943+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 10.0 in stage 30.0 (TID 182) in 50 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:28.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 13.0 in stage 30.0 (TID 185) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 11.0 in stage 30.0 (TID 183) in 50 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:28.974+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_13 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.976+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO BlockManagerInfo: Added rdd_86_12 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:28.991+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 14.0 in stage 30.0 (TID 186) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.992+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 13.0 in stage 30.0 (TID 185) in 49 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:28.996+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Starting task 15.0 in stage 30.0 (TID 187) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:28.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:28 INFO TaskSetManager: Finished task 12.0 in stage 30.0 (TID 184) in 54 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:29.030+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_14 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_15 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.048+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 16.0 in stage 30.0 (TID 188) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.049+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 14.0 in stage 30.0 (TID 186) in 58 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:29.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 17.0 in stage 30.0 (TID 189) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 15.0 in stage 30.0 (TID 187) in 57 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:29.084+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_16 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.086+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_17 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.100+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 18.0 in stage 30.0 (TID 190) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.101+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 17.0 in stage 30.0 (TID 189) in 48 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:29.102+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 19.0 in stage 30.0 (TID 191) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.103+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 16.0 in stage 30.0 (TID 188) in 55 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:29.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_18 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.139+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_19 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.155+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 20.0 in stage 30.0 (TID 192) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.156+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 18.0 in stage 30.0 (TID 190) in 57 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:29.158+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 21.0 in stage 30.0 (TID 193) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.159+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 19.0 in stage 30.0 (TID 191) in 57 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:29.190+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_20 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.193+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_21 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 23.0 in stage 30.0 (TID 194) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.210+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 21.0 in stage 30.0 (TID 193) in 53 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:29.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 24.0 in stage 30.0 (TID 195) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 20.0 in stage 30.0 (TID 192) in 56 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:29.241+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_24 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.241+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_23 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.256+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 25.0 in stage 30.0 (TID 196) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.257+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 24.0 in stage 30.0 (TID 195) in 47 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:29.258+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 26.0 in stage 30.0 (TID 197) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.259+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 23.0 in stage 30.0 (TID 194) in 50 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:29.285+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_26 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.291+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_25 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.301+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 27.0 in stage 30.0 (TID 198) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.301+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 26.0 in stage 30.0 (TID 197) in 44 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:29.311+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 28.0 in stage 30.0 (TID 199) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.312+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 25.0 in stage 30.0 (TID 196) in 55 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:29.333+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_27 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.340+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_28 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.347+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 29.0 in stage 30.0 (TID 200) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.348+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 27.0 in stage 30.0 (TID 198) in 47 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:29.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 30.0 in stage 30.0 (TID 201) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.357+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 28.0 in stage 30.0 (TID 199) in 46 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:29.377+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_29 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.386+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_30 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.392+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 31.0 in stage 30.0 (TID 202) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 29.0 in stage 30.0 (TID 200) in 45 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:29.402+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 32.0 in stage 30.0 (TID 203) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.403+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 30.0 in stage 30.0 (TID 201) in 47 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:29.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_31 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.431+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_32 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.438+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 33.0 in stage 30.0 (TID 204) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.439+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 31.0 in stage 30.0 (TID 202) in 47 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:29.446+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 34.0 in stage 30.0 (TID 205) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 32.0 in stage 30.0 (TID 203) in 44 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:29.472+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_33 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.478+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_34 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.488+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 35.0 in stage 30.0 (TID 206) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.489+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 33.0 in stage 30.0 (TID 204) in 52 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:29.497+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 36.0 in stage 30.0 (TID 207) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.498+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 34.0 in stage 30.0 (TID 205) in 51 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:29.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_35 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.533+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_36 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 37.0 in stage 30.0 (TID 208) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 35.0 in stage 30.0 (TID 206) in 58 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:29.550+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 38.0 in stage 30.0 (TID 209) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.551+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 36.0 in stage 30.0 (TID 207) in 54 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:29.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_37 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.592+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_38 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.600+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 39.0 in stage 30.0 (TID 210) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.601+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 37.0 in stage 30.0 (TID 208) in 55 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:29.610+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 40.0 in stage 30.0 (TID 211) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.611+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 38.0 in stage 30.0 (TID 209) in 62 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:29.632+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_39 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.642+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_40 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.646+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 41.0 in stage 30.0 (TID 212) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.647+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 39.0 in stage 30.0 (TID 210) in 47 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:29.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 43.0 in stage 30.0 (TID 213) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.658+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 40.0 in stage 30.0 (TID 211) in 47 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:29.676+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_41 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.688+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_43 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.693+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 44.0 in stage 30.0 (TID 214) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.694+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 41.0 in stage 30.0 (TID 212) in 48 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:29.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 45.0 in stage 30.0 (TID 215) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.706+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 43.0 in stage 30.0 (TID 213) in 49 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:29.722+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_44 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.732+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_45 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 46.0 in stage 30.0 (TID 216) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 44.0 in stage 30.0 (TID 214) in 47 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:29.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 47.0 in stage 30.0 (TID 217) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.746+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 45.0 in stage 30.0 (TID 215) in 42 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:29.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_46 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.773+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_47 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 48.0 in stage 30.0 (TID 218) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.780+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 46.0 in stage 30.0 (TID 216) in 40 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:29.790+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 49.0 in stage 30.0 (TID 219) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.791+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 47.0 in stage 30.0 (TID 217) in 45 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:29.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_48 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added rdd_86_49 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:27:29.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 48.0 in stage 30.0 (TID 218) in 39 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:29.829+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 49.0 in stage 30.0 (TID 219) in 39 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:29.829+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2024-11-14T16:27:29.830+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: ShuffleMapStage 30 (toString at String.java:2951) finished in 1.300 s
[2024-11-14T16:27:29.831+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:29.832+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:29.832+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:29.833+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:29.856+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:27:29.857+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Got job 18 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:29.858+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Final stage: ResultStage 33 (toString at String.java:2951)
[2024-11-14T16:27:29.859+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
[2024-11-14T16:27:29.860+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:29.860+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[92] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:29.865+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 372.2 KiB, free 432.6 MiB)
[2024-11-14T16:27:29.868+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 91.5 KiB, free 432.5 MiB)
[2024-11-14T16:27:29.868+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 7ea45ba85247:33227 (size: 91.5 KiB, free: 434.1 MiB)
[2024-11-14T16:27:29.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:29.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[92] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:29.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
[2024-11-14T16:27:29.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 220) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:29.883+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.21.0.8:35711 (size: 91.5 KiB, free: 1048.5 MiB)
[2024-11-14T16:27:29.893+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.21.0.8:60634
[2024-11-14T16:27:29.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 220) in 44 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:29.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2024-11-14T16:27:29.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: ResultStage 33 (toString at String.java:2951) finished in 0.056 s
[2024-11-14T16:27:29.918+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:29.919+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
[2024-11-14T16:27:29.919+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO DAGScheduler: Job 18 finished: toString at String.java:2951, took 0.061252 s
[2024-11-14T16:27:29.929+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO Snapshot: [tableId=4f4450ea-55c9-46e5-8617-80d091eb1d5b] DELTA: Done
[2024-11-14T16:27:29.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:29 INFO Snapshot: [tableId=d58fc25e-d61d-4007-952a-d2939ac9818f] Created snapshot Snapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=0, metadata=Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000000.json; isDirectory=false; length=3008; replication=1; blocksize=33554432; modification_time=1731601519475; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=a595743531ef21bf02a54d4e253d1147 versionId=null),List(),None,1731601519475), checksumOpt=None)
[2024-11-14T16:27:30.062+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:30.063+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:30.063+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:27:30.064+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(keywords),IsNotNull(id)
[2024-11-14T16:27:30.064+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(keywords#1),isnotnull(id#0L)
[2024-11-14T16:27:30.065+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Output Data Schema: struct<id: bigint, keywords: string>
[2024-11-14T16:27:30.069+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:30.069+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(transform(from_json(ArrayType(StructType(StructField(name,StringType,true)),true), cast#322, Some(Etc/UTC)), lambdafunction(lambda x#334.name, lambda x#334, false))),isnotnull(id#324L)
[2024-11-14T16:27:30.070+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, crew: string, id: bigint ... 1 more fields>
[2024-11-14T16:27:30.085+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DeltaParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2024-11-14T16:27:30.103+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:30.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 206.2 KiB, free 432.3 MiB)
[2024-11-14T16:27:30.115+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 432.3 MiB)
[2024-11-14T16:27:30.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 7ea45ba85247:33227 (size: 36.1 KiB, free: 434.0 MiB)
[2024-11-14T16:27:30.121+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 30 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:30.122+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:30.130+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Registering RDD 96 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2024-11-14T16:27:30.131+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Got map stage job 19 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:27:30.132+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:30.132+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:30.133+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:30.134+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:30.134+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[96] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:30.135+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.5 KiB, free 432.2 MiB)
[2024-11-14T16:27:30.143+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 432.2 MiB)
[2024-11-14T16:27:30.144+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 7ea45ba85247:33227 (size: 13.9 KiB, free: 434.0 MiB)
[2024-11-14T16:27:30.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 7ea45ba85247:33227 in memory (size: 91.5 KiB, free: 434.1 MiB)
[2024-11-14T16:27:30.146+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:30.146+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.21.0.8:35711 in memory (size: 91.5 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:30.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[96] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:30.152+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2024-11-14T16:27:30.153+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 221) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4903 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.155+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 7ea45ba85247:33227 in memory (size: 102.5 KiB, free: 434.2 MiB)
[2024-11-14T16:27:30.156+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 206.3 KiB, free 433.0 MiB)
[2024-11-14T16:27:30.157+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.21.0.8:35711 in memory (size: 102.5 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:30.164+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 432.9 MiB)
[2024-11-14T16:27:30.165+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.21.0.8:35711 (size: 13.9 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:30.166+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 7ea45ba85247:33227 (size: 36.1 KiB, free: 434.2 MiB)
[2024-11-14T16:27:30.167+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 32 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:30.168+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:30.187+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.21.0.8:35711 (size: 36.1 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:30.190+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Registering RDD 104 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2024-11-14T16:27:30.191+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Got map stage job 20 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:30.192+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Final stage: ShuffleMapStage 35 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:30.193+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:30.194+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:30.194+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[104] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:30.209+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 49.7 KiB, free 432.9 MiB)
[2024-11-14T16:27:30.211+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 432.9 MiB)
[2024-11-14T16:27:30.212+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 7ea45ba85247:33227 (size: 19.8 KiB, free: 434.2 MiB)
[2024-11-14T16:27:30.213+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:30.213+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[104] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:30.214+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks resource profile 0
[2024-11-14T16:27:30.215+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 222) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.229+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.21.0.8:35711 (size: 19.8 KiB, free: 1048.7 MiB)
[2024-11-14T16:27:30.250+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.21.0.8:35711 (size: 36.1 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:30.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 223) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.417+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 221) in 264 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:30.418+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2024-11-14T16:27:30.419+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: ShuffleMapStage 34 (save at NativeMethodAccessorImpl.java:0) finished in 0.286 s
[2024-11-14T16:27:30.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:30.421+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: running: Set(ShuffleMapStage 35)
[2024-11-14T16:27:30.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:30.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:30.428+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:30.429+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:30.430+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:27:30.437+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1480508, minimum partition size: 1048576
[2024-11-14T16:27:30.462+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:30.482+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO CodeGenerator: Code generated in 15.902983 ms
[2024-11-14T16:27:30.486+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 223) in 69 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:30.501+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:30.502+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Got job 21 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:27:30.504+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Final stage: ResultStage 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:27:30.505+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2024-11-14T16:27:30.505+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:30.506+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[107] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:27:30.508+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 32.7 KiB, free 432.8 MiB)
[2024-11-14T16:27:30.511+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 432.8 MiB)
[2024-11-14T16:27:30.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 7ea45ba85247:33227 (size: 15.2 KiB, free: 434.1 MiB)
[2024-11-14T16:27:30.513+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:30.514+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[107] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:30.516+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Adding task set 37.0 with 2 tasks resource profile 0
[2024-11-14T16:27:30.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 224) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.538+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.21.0.8:35711 (size: 15.2 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:30.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.21.0.8:60634
[2024-11-14T16:27:30.616+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 225) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.617+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 224) in 100 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:30.655+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 225) in 39 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:30.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2024-11-14T16:27:30.657+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: ResultStage 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.150 s
[2024-11-14T16:27:30.658+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:30.659+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
[2024-11-14T16:27:30.659+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Job 21 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.155365 s
[2024-11-14T16:27:30.682+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 4.0 MiB, free 428.8 MiB)
[2024-11-14T16:27:30.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 814.1 KiB, free 428.0 MiB)
[2024-11-14T16:27:30.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 7ea45ba85247:33227 (size: 814.1 KiB, free: 433.3 MiB)
[2024-11-14T16:27:30.692+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:30.698+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(id)
[2024-11-14T16:27:30.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(id#15)
[2024-11-14T16:27:30.700+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceStrategy: Output Data Schema: struct<budget: string, genres: string, id: string, imdb_id: string, original_language: string ... 10 more fields>
[2024-11-14T16:27:30.733+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO CodeGenerator: Code generated in 13.632114 ms
[2024-11-14T16:27:30.750+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO CodeGenerator: Code generated in 13.023635 ms
[2024-11-14T16:27:30.754+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 207.5 KiB, free 427.8 MiB)
[2024-11-14T16:27:30.760+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 427.8 MiB)
[2024-11-14T16:27:30.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 7ea45ba85247:33227 (size: 36.4 KiB, free: 433.3 MiB)
[2024-11-14T16:27:30.763+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 36 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:30.764+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10691623 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:30.776+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Registering RDD 113 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2024-11-14T16:27:30.777+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Got map stage job 22 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:30.778+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:30.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:30.779+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:30.780+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[113] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:30.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 45.6 KiB, free 427.8 MiB)
[2024-11-14T16:27:30.794+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 427.7 MiB)
[2024-11-14T16:27:30.795+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 7ea45ba85247:33227 (size: 18.5 KiB, free: 433.3 MiB)
[2024-11-14T16:27:30.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:30.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[113] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:30.798+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks resource profile 0
[2024-11-14T16:27:30.799+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 226) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:30.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.21.0.8:35711 (size: 18.5 KiB, free: 1048.6 MiB)
[2024-11-14T16:27:30.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.21.0.8:35711 (size: 814.1 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:30.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:30 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.21.0.8:35711 (size: 36.4 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:32.037+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 227) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4901 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.037+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 226) in 1240 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:32.089+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 227) in 53 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:32.090+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2024-11-14T16:27:32.090+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: ShuffleMapStage 38 (save at NativeMethodAccessorImpl.java:0) finished in 1.312 s
[2024-11-14T16:27:32.091+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:32.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: running: Set(ShuffleMapStage 35)
[2024-11-14T16:27:32.093+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:32.094+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:32.498+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 222) in 2282 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:32.498+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2024-11-14T16:27:32.499+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: ShuffleMapStage 35 (save at NativeMethodAccessorImpl.java:0) finished in 2.306 s
[2024-11-14T16:27:32.500+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:32.501+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:32.502+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:32.502+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:32.506+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 5348362, minimum partition size: 1048576
[2024-11-14T16:27:32.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:27:32.534+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO CodeGenerator: Code generated in 14.201085 ms
[2024-11-14T16:27:32.542+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Registering RDD 116 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2024-11-14T16:27:32.542+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Got map stage job 23 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:32.543+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:32.544+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
[2024-11-14T16:27:32.544+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:32.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[116] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:32.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 47.4 KiB, free 427.7 MiB)
[2024-11-14T16:27:32.548+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 427.7 MiB)
[2024-11-14T16:27:32.549+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 7ea45ba85247:33227 (size: 19.7 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.550+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:32.550+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[116] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:32.551+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks resource profile 0
[2024-11-14T16:27:32.552+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 228) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.552+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 229) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.21.0.8:35711 (size: 19.7 KiB, free: 1047.7 MiB)
[2024-11-14T16:27:32.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.21.0.8:60634
[2024-11-14T16:27:32.695+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 228) in 144 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:32.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 229) in 147 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:32.699+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2024-11-14T16:27:32.700+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: ShuffleMapStage 40 (save at NativeMethodAccessorImpl.java:0) finished in 0.155 s
[2024-11-14T16:27:32.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:32.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:32.702+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:32.703+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:32.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1239972, minimum partition size: 1048576
[2024-11-14T16:27:32.732+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:32.733+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Got job 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2024-11-14T16:27:32.733+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Final stage: ResultStage 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2024-11-14T16:27:32.734+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
[2024-11-14T16:27:32.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:32.736+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2024-11-14T16:27:32.737+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.2 KiB, free 427.7 MiB)
[2024-11-14T16:27:32.738+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 427.7 MiB)
[2024-11-14T16:27:32.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 7ea45ba85247:33227 (size: 3.9 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:32.740+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:32.741+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
[2024-11-14T16:27:32.741+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 230) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.742+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 231) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.21.0.8:35711 (size: 3.9 KiB, free: 1047.7 MiB)
[2024-11-14T16:27:32.755+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.21.0.8:60634
[2024-11-14T16:27:32.786+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added taskresult_231 in memory on 172.21.0.8:35711 (size: 1130.2 KiB, free: 1046.6 MiB)
[2024-11-14T16:27:32.787+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added taskresult_230 in memory on 172.21.0.8:35711 (size: 1116.1 KiB, free: 1045.5 MiB)
[2024-11-14T16:27:32.789+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 7ea45ba85247:33227 in memory (size: 19.8 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.791+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.21.0.8:35711 in memory (size: 19.8 KiB, free: 1045.6 MiB)
[2024-11-14T16:27:32.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 7ea45ba85247:33227 in memory (size: 19.7 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.798+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 231) in 56 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:32.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed taskresult_231 on 172.21.0.8:35711 in memory (size: 1130.2 KiB, free: 1046.7 MiB)
[2024-11-14T16:27:32.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.21.0.8:35711 in memory (size: 19.7 KiB, free: 1046.7 MiB)
[2024-11-14T16:27:32.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 230) in 66 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:32.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2024-11-14T16:27:32.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: ResultStage 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.071 s
[2024-11-14T16:27:32.809+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:32.810+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
[2024-11-14T16:27:32.811+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 7ea45ba85247:33227 in memory (size: 18.5 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.812+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Job 24 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.077322 s
[2024-11-14T16:27:32.813+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed taskresult_230 on 172.21.0.8:35711 in memory (size: 1116.1 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:32.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.21.0.8:35711 in memory (size: 18.5 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:32.817+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 7ea45ba85247:33227 in memory (size: 15.2 KiB, free: 433.3 MiB)
[2024-11-14T16:27:32.819+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.21.0.8:35711 in memory (size: 15.2 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:32.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 7ea45ba85247:33227 in memory (size: 13.9 KiB, free: 433.4 MiB)
[2024-11-14T16:27:32.825+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.21.0.8:35711 in memory (size: 13.9 KiB, free: 1047.8 MiB)
[2024-11-14T16:27:32.836+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 8.5 MiB, free 419.4 MiB)
[2024-11-14T16:27:32.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 2.4 MiB, free 417.1 MiB)
[2024-11-14T16:27:32.852+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 7ea45ba85247:33227 (size: 2.4 MiB, free: 431.0 MiB)
[2024-11-14T16:27:32.853+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2024-11-14T16:27:32.857+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 7929966, minimum partition size: 1048576
[2024-11-14T16:27:32.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO CodeGenerator: Code generated in 11.957404 ms
[2024-11-14T16:27:32.923+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:27:32.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Got job 25 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:27:32.925+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Final stage: ResultStage 45 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:27:32.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
[2024-11-14T16:27:32.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:32.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[120] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:27:32.940+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 359.7 KiB, free 416.7 MiB)
[2024-11-14T16:27:32.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 127.0 KiB, free 416.6 MiB)
[2024-11-14T16:27:32.943+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 7ea45ba85247:33227 (size: 127.0 KiB, free: 430.9 MiB)
[2024-11-14T16:27:32.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:32.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[120] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:32.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
[2024-11-14T16:27:32.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 232) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.946+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 233) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:32.954+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.21.0.8:35711 (size: 127.0 KiB, free: 1047.7 MiB)
[2024-11-14T16:27:32.971+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.21.0.8:60634
[2024-11-14T16:27:32.995+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:32 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.21.0.8:35711 (size: 2.4 MiB, free: 1045.3 MiB)
[2024-11-14T16:27:33.089+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 233) in 143 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:33.683+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 232) in 739 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:33.684+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2024-11-14T16:27:33.685+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: ResultStage 45 (save at NativeMethodAccessorImpl.java:0) finished in 0.759 s
[2024-11-14T16:27:33.686+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:33.687+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
[2024-11-14T16:27:33.688+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Job 25 finished: save at NativeMethodAccessorImpl.java:0, took 0.761611 s
[2024-11-14T16:27:33.689+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO FileFormatWriter: Start to commit write Job e0741e6a-809c-433b-9056-d47009842bfa.
[2024-11-14T16:27:33.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO FileFormatWriter: Write Job e0741e6a-809c-433b-9056-d47009842bfa committed. Elapsed time: 0 ms.
[2024-11-14T16:27:33.691+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO FileFormatWriter: Finished processing stats for write job e0741e6a-809c-433b-9056-d47009842bfa.
[2024-11-14T16:27:33.799+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2024-11-14T16:27:33.801+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Got job 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions
[2024-11-14T16:27:33.802+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Final stage: ResultStage 47 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)
[2024-11-14T16:27:33.803+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
[2024-11-14T16:27:33.803+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:33.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[122] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents
[2024-11-14T16:27:33.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 475.0 KiB, free 416.1 MiB)
[2024-11-14T16:27:33.810+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 112.5 KiB, free 416.0 MiB)
[2024-11-14T16:27:33.811+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 7ea45ba85247:33227 (size: 112.5 KiB, free: 430.8 MiB)
[2024-11-14T16:27:33.812+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:33.813+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 47 (MapPartitionsRDD[122] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:33.813+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSchedulerImpl: Adding task set 47.0 with 50 tasks resource profile 0
[2024-11-14T16:27:33.814+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 234) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 235) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.825+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.21.0.8:35711 (size: 112.5 KiB, free: 1045.2 MiB)
[2024-11-14T16:27:33.836+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 236) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.837+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 234) in 24 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:33.838+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 237) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.839+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 235) in 24 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:33.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 4.0 in stage 47.0 (TID 238) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.848+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 236) in 12 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:33.849+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 5.0 in stage 47.0 (TID 239) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.850+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 237) in 12 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:33.861+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 6.0 in stage 47.0 (TID 240) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.862+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 4.0 in stage 47.0 (TID 238) in 15 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:33.863+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 7.0 in stage 47.0 (TID 241) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.864+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 5.0 in stage 47.0 (TID 239) in 15 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:33.873+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 8.0 in stage 47.0 (TID 242) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.874+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 6.0 in stage 47.0 (TID 240) in 12 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:33.875+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 9.0 in stage 47.0 (TID 243) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.875+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 7.0 in stage 47.0 (TID 241) in 12 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:33.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 10.0 in stage 47.0 (TID 244) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 8.0 in stage 47.0 (TID 242) in 13 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:33.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 11.0 in stage 47.0 (TID 245) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 9.0 in stage 47.0 (TID 243) in 12 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:33.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 12.0 in stage 47.0 (TID 246) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.899+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 11.0 in stage 47.0 (TID 245) in 13 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:33.900+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 13.0 in stage 47.0 (TID 247) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.900+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 10.0 in stage 47.0 (TID 244) in 16 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:33.909+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 14.0 in stage 47.0 (TID 248) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 12.0 in stage 47.0 (TID 246) in 12 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:33.911+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 15.0 in stage 47.0 (TID 249) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.912+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 13.0 in stage 47.0 (TID 247) in 12 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:33.923+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 16.0 in stage 47.0 (TID 250) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.924+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 14.0 in stage 47.0 (TID 248) in 16 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:33.926+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 17.0 in stage 47.0 (TID 251) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 15.0 in stage 47.0 (TID 249) in 15 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:33.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 18.0 in stage 47.0 (TID 252) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.937+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 16.0 in stage 47.0 (TID 250) in 13 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:33.938+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 19.0 in stage 47.0 (TID 253) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.939+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 17.0 in stage 47.0 (TID 251) in 13 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:33.948+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 20.0 in stage 47.0 (TID 254) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.949+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 18.0 in stage 47.0 (TID 252) in 12 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:33.950+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 21.0 in stage 47.0 (TID 255) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.951+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 19.0 in stage 47.0 (TID 253) in 14 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:33.964+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 22.0 in stage 47.0 (TID 256) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 21.0 in stage 47.0 (TID 255) in 15 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:33.966+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 23.0 in stage 47.0 (TID 257) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.970+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 20.0 in stage 47.0 (TID 254) in 22 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:33.973+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 7ea45ba85247:33227 in memory (size: 127.0 KiB, free: 430.9 MiB)
[2024-11-14T16:27:33.975+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.21.0.8:35711 in memory (size: 127.0 KiB, free: 1045.3 MiB)
[2024-11-14T16:27:33.981+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 24.0 in stage 47.0 (TID 258) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.982+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 22.0 in stage 47.0 (TID 256) in 18 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:33.984+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 25.0 in stage 47.0 (TID 259) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.985+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 23.0 in stage 47.0 (TID 257) in 20 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:33.995+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 26.0 in stage 47.0 (TID 260) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.996+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 24.0 in stage 47.0 (TID 258) in 15 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:33.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Starting task 27.0 in stage 47.0 (TID 261) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:33.998+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:33 INFO TaskSetManager: Finished task 25.0 in stage 47.0 (TID 259) in 13 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:34.007+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 28.0 in stage 47.0 (TID 262) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.008+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 26.0 in stage 47.0 (TID 260) in 13 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:34.009+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 29.0 in stage 47.0 (TID 263) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.010+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 27.0 in stage 47.0 (TID 261) in 12 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:34.018+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 30.0 in stage 47.0 (TID 264) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.019+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 28.0 in stage 47.0 (TID 262) in 11 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:34.020+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 31.0 in stage 47.0 (TID 265) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.021+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 29.0 in stage 47.0 (TID 263) in 12 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:34.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 32.0 in stage 47.0 (TID 266) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.032+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 30.0 in stage 47.0 (TID 264) in 14 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:34.034+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 33.0 in stage 47.0 (TID 267) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.035+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 31.0 in stage 47.0 (TID 265) in 16 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:34.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 34.0 in stage 47.0 (TID 268) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.045+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 32.0 in stage 47.0 (TID 266) in 13 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:34.046+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 35.0 in stage 47.0 (TID 269) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.047+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 33.0 in stage 47.0 (TID 267) in 12 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:34.054+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 36.0 in stage 47.0 (TID 270) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.055+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 34.0 in stage 47.0 (TID 268) in 11 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:34.057+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 37.0 in stage 47.0 (TID 271) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.058+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 35.0 in stage 47.0 (TID 269) in 11 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:34.067+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 38.0 in stage 47.0 (TID 272) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.068+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 36.0 in stage 47.0 (TID 270) in 13 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:34.069+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 39.0 in stage 47.0 (TID 273) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.070+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 37.0 in stage 47.0 (TID 271) in 14 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:34.079+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 40.0 in stage 47.0 (TID 274) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 38.0 in stage 47.0 (TID 272) in 13 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:34.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 41.0 in stage 47.0 (TID 275) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 39.0 in stage 47.0 (TID 273) in 13 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:34.089+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 42.0 in stage 47.0 (TID 276) (172.21.0.8, executor 0, partition 42, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.090+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 40.0 in stage 47.0 (TID 274) in 12 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:34.094+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 43.0 in stage 47.0 (TID 277) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.095+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 41.0 in stage 47.0 (TID 275) in 13 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:34.105+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 44.0 in stage 47.0 (TID 278) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.106+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 42.0 in stage 47.0 (TID 276) in 17 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:34.108+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 45.0 in stage 47.0 (TID 279) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.109+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 43.0 in stage 47.0 (TID 277) in 15 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:34.118+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 46.0 in stage 47.0 (TID 280) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.118+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 44.0 in stage 47.0 (TID 278) in 13 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:34.120+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 47.0 in stage 47.0 (TID 281) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.121+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 45.0 in stage 47.0 (TID 279) in 13 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:34.129+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 48.0 in stage 47.0 (TID 282) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.130+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 46.0 in stage 47.0 (TID 280) in 12 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:34.133+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 49.0 in stage 47.0 (TID 283) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.134+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 47.0 in stage 47.0 (TID 281) in 13 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:34.142+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 48.0 in stage 47.0 (TID 282) in 14 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:34.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 49.0 in stage 47.0 (TID 283) in 13 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:34.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool
[2024-11-14T16:27:34.146+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: ResultStage 47 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.341 s
[2024-11-14T16:27:34.147+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:34.147+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
[2024-11-14T16:27:34.148+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Job 26 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.346675 s
[2024-11-14T16:27:34.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO OptimisticTransaction: [tableId=9fee92a3,txnId=d0eb2626] Attempting to commit version 1 with 3 actions with Serializable isolation level
[2024-11-14T16:27:34.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DeltaLog: Creating a new snapshot v1 for commit version 1
[2024-11-14T16:27:34.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DeltaLog: Loading version 1.
[2024-11-14T16:27:34.225+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO Snapshot: [tableId=9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7] DELTA: Compute snapshot for version: 1
[2024-11-14T16:27:34.228+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 204.4 KiB, free 416.3 MiB)
[2024-11-14T16:27:34.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 416.3 MiB)
[2024-11-14T16:27:34.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 7ea45ba85247:33227 (size: 35.6 KiB, free: 430.9 MiB)
[2024-11-14T16:27:34.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO SparkContext: Created broadcast 43 from toString at String.java:2951
[2024-11-14T16:27:34.236+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 2, totalFileSize: 4738)
[2024-11-14T16:27:34.379+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:27:34.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:27:34.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:27:34.418+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 7ea45ba85247:33227 in memory (size: 112.5 KiB, free: 431.0 MiB)
[2024-11-14T16:27:34.421+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.21.0.8:35711 in memory (size: 112.5 KiB, free: 1045.5 MiB)
[2024-11-14T16:27:34.425+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 204.7 KiB, free 416.7 MiB)
[2024-11-14T16:27:34.432+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 416.6 MiB)
[2024-11-14T16:27:34.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 7ea45ba85247:33227 (size: 35.7 KiB, free: 430.9 MiB)
[2024-11-14T16:27:34.435+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO SparkContext: Created broadcast 44 from toString at String.java:2951
[2024-11-14T16:27:34.436+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196673 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:27:34.445+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Registering RDD 126 (toString at String.java:2951) as input to shuffle 14
[2024-11-14T16:27:34.446+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Got map stage job 27 (toString at String.java:2951) with 2 output partitions
[2024-11-14T16:27:34.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Final stage: ShuffleMapStage 48 (toString at String.java:2951)
[2024-11-14T16:27:34.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:27:34.448+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:34.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[126] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:34.451+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 124.3 KiB, free 416.5 MiB)
[2024-11-14T16:27:34.453+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 416.5 MiB)
[2024-11-14T16:27:34.454+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 7ea45ba85247:33227 (size: 35.2 KiB, free: 430.9 MiB)
[2024-11-14T16:27:34.455+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:34.455+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[126] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:27:34.456+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
[2024-11-14T16:27:34.456+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 284) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4931 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.457+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 285) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4931 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.466+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.21.0.8:35711 (size: 35.2 KiB, free: 1045.4 MiB)
[2024-11-14T16:27:34.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.21.0.8:35711 (size: 35.7 KiB, free: 1045.4 MiB)
[2024-11-14T16:27:34.522+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 284) in 65 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:27:34.527+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 285) in 70 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:27:34.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2024-11-14T16:27:34.529+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: ShuffleMapStage 48 (toString at String.java:2951) finished in 0.080 s
[2024-11-14T16:27:34.530+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:34.531+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:34.532+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:34.533+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:34.584+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 7ea45ba85247:33227 in memory (size: 35.2 KiB, free: 430.9 MiB)
[2024-11-14T16:27:34.585+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.21.0.8:35711 in memory (size: 35.2 KiB, free: 1045.4 MiB)
[2024-11-14T16:27:34.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Registering RDD 136 (toString at String.java:2951) as input to shuffle 15
[2024-11-14T16:27:34.711+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Got map stage job 28 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:27:34.712+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (toString at String.java:2951)
[2024-11-14T16:27:34.713+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
[2024-11-14T16:27:34.714+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:34.715+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[136] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:34.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 426.3 KiB, free 416.2 MiB)
[2024-11-14T16:27:34.760+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 102.6 KiB, free 416.1 MiB)
[2024-11-14T16:27:34.761+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 7ea45ba85247:33227 (size: 102.6 KiB, free: 430.8 MiB)
[2024-11-14T16:27:34.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:34.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[136] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:27:34.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSchedulerImpl: Adding task set 50.0 with 50 tasks resource profile 0
[2024-11-14T16:27:34.763+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 8.0 in stage 50.0 (TID 286) (172.21.0.8, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.764+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 22.0 in stage 50.0 (TID 287) (172.21.0.8, executor 0, partition 22, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.774+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.21.0.8:35711 (size: 102.6 KiB, free: 1045.3 MiB)
[2024-11-14T16:27:34.786+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.21.0.8:60634
[2024-11-14T16:27:34.809+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_8 in memory on 172.21.0.8:35711 (size: 879.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.810+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_22 in memory on 172.21.0.8:35711 (size: 293.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.825+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 42.0 in stage 50.0 (TID 288) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.825+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 22.0 in stage 50.0 (TID 287) in 62 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:27:34.826+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 289) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.827+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 8.0 in stage 50.0 (TID 286) in 63 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:27:34.854+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_0 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.855+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_42 in memory on 172.21.0.8:35711 (size: 683.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.867+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 290) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.868+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 289) in 43 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:27:34.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 291) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 42.0 in stage 50.0 (TID 288) in 45 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:27:34.894+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_1 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.895+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_2 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.907+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 292) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.908+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 290) in 40 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:27:34.909+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 293) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 291) in 40 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:27:34.937+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_3 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_4 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.955+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 5.0 in stage 50.0 (TID 294) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.955+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 292) in 48 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:27:34.957+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 6.0 in stage 50.0 (TID 295) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.958+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 293) in 49 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:27:34.983+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_5 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.984+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO BlockManagerInfo: Added rdd_133_6 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:34.996+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 7.0 in stage 50.0 (TID 296) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.997+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 5.0 in stage 50.0 (TID 294) in 42 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:27:34.998+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Starting task 9.0 in stage 50.0 (TID 297) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:34.999+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:34 INFO TaskSetManager: Finished task 6.0 in stage 50.0 (TID 295) in 40 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:27:35.027+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_9 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.028+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_7 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.043+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 10.0 in stage 50.0 (TID 298) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.044+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 9.0 in stage 50.0 (TID 297) in 47 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:27:35.045+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 11.0 in stage 50.0 (TID 299) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.046+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 7.0 in stage 50.0 (TID 296) in 49 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:27:35.076+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_10 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_11 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.091+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 12.0 in stage 50.0 (TID 300) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 11.0 in stage 50.0 (TID 299) in 47 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:27:35.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 13.0 in stage 50.0 (TID 301) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.094+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 10.0 in stage 50.0 (TID 298) in 49 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:27:35.122+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_12 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.123+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_13 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.136+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 14.0 in stage 50.0 (TID 302) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.136+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 13.0 in stage 50.0 (TID 301) in 45 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:27:35.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 15.0 in stage 50.0 (TID 303) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.138+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 12.0 in stage 50.0 (TID 300) in 47 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:27:35.161+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_14 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.162+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_15 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.175+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 16.0 in stage 50.0 (TID 304) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.176+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 15.0 in stage 50.0 (TID 303) in 39 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:27:35.176+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 17.0 in stage 50.0 (TID 305) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.177+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 14.0 in stage 50.0 (TID 302) in 41 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:27:35.203+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_17 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.204+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_16 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.219+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 18.0 in stage 50.0 (TID 306) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.220+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 17.0 in stage 50.0 (TID 305) in 43 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:27:35.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 19.0 in stage 50.0 (TID 307) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.221+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 16.0 in stage 50.0 (TID 304) in 45 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:27:35.244+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_19 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.245+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_18 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.259+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 20.0 in stage 50.0 (TID 308) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.260+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 19.0 in stage 50.0 (TID 307) in 39 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:27:35.260+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 21.0 in stage 50.0 (TID 309) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.261+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 18.0 in stage 50.0 (TID 306) in 41 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:27:35.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_20 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.289+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_21 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.302+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 23.0 in stage 50.0 (TID 310) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.303+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 21.0 in stage 50.0 (TID 309) in 42 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:27:35.304+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 24.0 in stage 50.0 (TID 311) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.305+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 20.0 in stage 50.0 (TID 308) in 45 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:27:35.337+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_24 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.343+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_23 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.358+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 25.0 in stage 50.0 (TID 312) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.359+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 23.0 in stage 50.0 (TID 310) in 57 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:27:35.360+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 26.0 in stage 50.0 (TID 313) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.361+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 24.0 in stage 50.0 (TID 311) in 57 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:27:35.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_25 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.394+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_26 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.407+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 27.0 in stage 50.0 (TID 314) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.408+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 25.0 in stage 50.0 (TID 312) in 49 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:27:35.409+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 28.0 in stage 50.0 (TID 315) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.410+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 26.0 in stage 50.0 (TID 313) in 49 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:27:35.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_28 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.434+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_27 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 29.0 in stage 50.0 (TID 316) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.448+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 28.0 in stage 50.0 (TID 315) in 39 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:27:35.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 30.0 in stage 50.0 (TID 317) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.450+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 27.0 in stage 50.0 (TID 314) in 42 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:27:35.475+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_29 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.476+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_30 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.488+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 31.0 in stage 50.0 (TID 318) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.489+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 29.0 in stage 50.0 (TID 316) in 41 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:27:35.490+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 32.0 in stage 50.0 (TID 319) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.490+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 30.0 in stage 50.0 (TID 317) in 41 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:27:35.513+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_31 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.514+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_32 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.528+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 33.0 in stage 50.0 (TID 320) (172.21.0.8, executor 0, partition 33, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.529+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 31.0 in stage 50.0 (TID 318) in 40 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:27:35.529+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 34.0 in stage 50.0 (TID 321) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.530+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 32.0 in stage 50.0 (TID 319) in 40 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:27:35.558+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_34 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.558+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_33 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.570+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 35.0 in stage 50.0 (TID 322) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.571+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 34.0 in stage 50.0 (TID 321) in 41 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:27:35.572+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 36.0 in stage 50.0 (TID 323) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.572+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 33.0 in stage 50.0 (TID 320) in 43 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:27:35.596+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_35 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.597+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_36 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 37.0 in stage 50.0 (TID 324) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 35.0 in stage 50.0 (TID 322) in 39 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:27:35.610+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 38.0 in stage 50.0 (TID 325) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.611+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 36.0 in stage 50.0 (TID 323) in 39 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:27:35.633+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_37 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.633+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_38 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.645+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 39.0 in stage 50.0 (TID 326) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.645+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 38.0 in stage 50.0 (TID 325) in 36 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:27:35.646+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 40.0 in stage 50.0 (TID 327) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.647+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 37.0 in stage 50.0 (TID 324) in 38 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:27:35.668+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_40 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.669+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_39 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.679+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 41.0 in stage 50.0 (TID 328) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.680+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 40.0 in stage 50.0 (TID 327) in 35 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:27:35.681+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 43.0 in stage 50.0 (TID 329) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.682+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 39.0 in stage 50.0 (TID 326) in 37 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:27:35.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_43 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_41 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.717+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 44.0 in stage 50.0 (TID 330) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.718+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 41.0 in stage 50.0 (TID 328) in 39 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:27:35.719+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 45.0 in stage 50.0 (TID 331) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.720+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 43.0 in stage 50.0 (TID 329) in 39 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:27:35.742+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_44 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_45 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 46.0 in stage 50.0 (TID 332) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 44.0 in stage 50.0 (TID 330) in 39 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:27:35.759+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 47.0 in stage 50.0 (TID 333) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.760+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 45.0 in stage 50.0 (TID 331) in 41 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:27:35.783+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_46 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.784+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_47 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.797+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 48.0 in stage 50.0 (TID 334) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.798+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 46.0 in stage 50.0 (TID 332) in 42 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:27:35.799+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 49.0 in stage 50.0 (TID 335) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.800+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 47.0 in stage 50.0 (TID 333) in 40 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:27:35.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_49 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.826+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added rdd_133_48 in memory on 172.21.0.8:35711 (size: 46.0 B, free: 1045.3 MiB)
[2024-11-14T16:27:35.838+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 49.0 in stage 50.0 (TID 335) in 40 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:27:35.842+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 48.0 in stage 50.0 (TID 334) in 45 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:27:35.842+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2024-11-14T16:27:35.843+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: ShuffleMapStage 50 (toString at String.java:2951) finished in 1.127 s
[2024-11-14T16:27:35.844+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:27:35.844+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: running: Set()
[2024-11-14T16:27:35.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:27:35.845+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: failed: Set()
[2024-11-14T16:27:35.867+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:27:35.869+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Got job 29 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:27:35.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Final stage: ResultStage 53 (toString at String.java:2951)
[2024-11-14T16:27:35.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2024-11-14T16:27:35.871+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:27:35.872+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[139] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:27:35.883+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 372.3 KiB, free 415.8 MiB)
[2024-11-14T16:27:35.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 7ea45ba85247:33227 in memory (size: 102.6 KiB, free: 430.9 MiB)
[2024-11-14T16:27:35.885+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.21.0.8:35711 in memory (size: 102.6 KiB, free: 1045.4 MiB)
[2024-11-14T16:27:35.886+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 416.2 MiB)
[2024-11-14T16:27:35.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 7ea45ba85247:33227 (size: 91.6 KiB, free: 430.8 MiB)
[2024-11-14T16:27:35.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:27:35.888+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[139] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:27:35.889+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2024-11-14T16:27:35.890+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 336) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:27:35.899+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.21.0.8:35711 (size: 91.6 KiB, free: 1045.3 MiB)
[2024-11-14T16:27:35.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.21.0.8:60634
[2024-11-14T16:27:35.930+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 7ea45ba85247:33227 in memory (size: 3.9 KiB, free: 430.8 MiB)
[2024-11-14T16:27:35.931+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.21.0.8:35711 in memory (size: 3.9 KiB, free: 1045.3 MiB)
[2024-11-14T16:27:35.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 336) in 54 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:27:35.943+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2024-11-14T16:27:35.944+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: ResultStage 53 (toString at String.java:2951) finished in 0.073 s
[2024-11-14T16:27:35.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:27:35.945+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
[2024-11-14T16:27:35.946+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DAGScheduler: Job 29 finished: toString at String.java:2951, took 0.077208 s
[2024-11-14T16:27:35.953+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO Snapshot: [tableId=9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7] DELTA: Done
[2024-11-14T16:27:35.954+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO Snapshot: [tableId=9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7] Created snapshot Snapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=1, metadata=Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000000.json; isDirectory=false; length=3008; replication=1; blocksize=33554432; modification_time=1731601519475; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=a595743531ef21bf02a54d4e253d1147 versionId=null, S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000001.json; isDirectory=false; length=1730; replication=1; blocksize=33554432; modification_time=1731601654189; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=bb76ce5716e7fb72fee1a9e76e405062 versionId=null),List(),None,1731601654189), checksumOpt=None)
[2024-11-14T16:27:35.955+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://lakehouse/gold/gold_data/_delta_log, version=1, metadata=Metadata(9fee92a3-fe2c-4f46-bdf2-6f80734f4ac7,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"id","type":"string","nullable":true,"metadata":{}},{"name":"imdb_id","type":"string","nullable":true,"metadata":{}},{"name":"budget","type":"integer","nullable":true,"metadata":{}},{"name":"genres_convert","type":"string","nullable":true,"metadata":{}},{"name":"original_language","type":"string","nullable":true,"metadata":{}},{"name":"release_date","type":"date","nullable":true,"metadata":{}},{"name":"revenue","type":"double","nullable":true,"metadata":{}},{"name":"title","type":"string","nullable":true,"metadata":{}},{"name":"time","type":"string","nullable":true,"metadata":{}},{"name":"overview","type":"string","nullable":true,"metadata":{}},{"name":"vote_average","type":"double","nullable":true,"metadata":{}},{"name":"vote_count","type":"double","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601513370)), logSegment=LogSegment(s3a://lakehouse/gold/gold_data/_delta_log,1,WrappedArray(S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000000.json; isDirectory=false; length=3008; replication=1; blocksize=33554432; modification_time=1731601519475; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=a595743531ef21bf02a54d4e253d1147 versionId=null, S3AFileStatus{path=s3a://lakehouse/gold/gold_data/_delta_log/00000000000000000001.json; isDirectory=false; length=1730; replication=1; blocksize=33554432; modification_time=1731601654189; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=bb76ce5716e7fb72fee1a9e76e405062 versionId=null),List(),None,1731601654189), checksumOpt=None)
[2024-11-14T16:27:35.956+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO MapPartitionsRDD: Removing RDD 86 from persistence list
[2024-11-14T16:27:35.957+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO BlockManager: Removing RDD 86
[2024-11-14T16:27:35.958+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO OptimisticTransaction: [tableId=9fee92a3,txnId=d0eb2626] Committed delta #1 to s3a://lakehouse/gold/gold_data/_delta_log
[2024-11-14T16:27:35.976+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO SparkUI: Stopped Spark web UI at http://7ea45ba85247:4040
[2024-11-14T16:27:35.982+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO StandaloneSchedulerBackend: Shutting down all executors
[2024-11-14T16:27:35.983+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2024-11-14T16:27:36.010+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-11-14T16:27:36.036+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO MemoryStore: MemoryStore cleared
[2024-11-14T16:27:36.037+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO BlockManager: BlockManager stopped
[2024-11-14T16:27:36.043+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-11-14T16:27:36.049+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-11-14T16:27:36.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO SparkContext: Successfully stopped SparkContext
[2024-11-14T16:27:36.486+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO ShutdownHookManager: Shutdown hook called
[2024-11-14T16:27:36.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0bdfce2-ee26-4e28-ace8-f2cdbe1e8d70
[2024-11-14T16:27:36.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-91d7d1a8-d67b-4c99-9c41-b36f27aa4e2c
[2024-11-14T16:27:36.495+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0bdfce2-ee26-4e28-ace8-f2cdbe1e8d70/pyspark-52c5905a-0062-47ef-a4d4-af04b75894c4
[2024-11-14T16:27:36.504+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2024-11-14T16:27:36.505+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2024-11-14T16:27:36.505+0000] {spark_submit.py:579} INFO - 24/11/14 16:27:36 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2024-11-14T16:27:36.602+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=mergeeeee, task_id=merge_id, execution_date=20241114T162112, start_date=20241114T162646, end_date=20241114T162736
[2024-11-14T16:27:36.643+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-11-14T16:27:36.656+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
