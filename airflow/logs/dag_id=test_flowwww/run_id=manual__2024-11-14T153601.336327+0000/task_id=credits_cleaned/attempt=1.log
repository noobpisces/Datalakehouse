[2024-11-14T16:18:32.119+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: test_flowwww.credits_cleaned manual__2024-11-14T15:36:01.336327+00:00 [queued]>
[2024-11-14T16:18:32.131+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: test_flowwww.credits_cleaned manual__2024-11-14T15:36:01.336327+00:00 [queued]>
[2024-11-14T16:18:32.132+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2024-11-14T16:18:32.152+0000] {taskinstance.py:1382} INFO - Executing <Task(SparkSubmitOperator): credits_cleaned> on 2024-11-14 15:36:01.336327+00:00
[2024-11-14T16:18:32.160+0000] {standard_task_runner.py:57} INFO - Started process 4751 to run task
[2024-11-14T16:18:32.163+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'test_flowwww', 'credits_cleaned', 'manual__2024-11-14T15:36:01.336327+00:00', '--job-id', '269', '--raw', '--subdir', 'DAGS_FOLDER/test_flow.py', '--cfg-path', '/tmp/tmpv839ic_c']
[2024-11-14T16:18:32.166+0000] {standard_task_runner.py:85} INFO - Job 269: Subtask credits_cleaned
[2024-11-14T16:18:32.225+0000] {task_command.py:416} INFO - Running <TaskInstance: test_flowwww.credits_cleaned manual__2024-11-14T15:36:01.336327+00:00 [running]> on host 7ea45ba85247
[2024-11-14T16:18:32.335+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='test_flowwww' AIRFLOW_CTX_TASK_ID='credits_cleaned' AIRFLOW_CTX_EXECUTION_DATE='2024-11-14T15:36:01.336327+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-14T15:36:01.336327+00:00'
[2024-11-14T16:18:32.348+0000] {base.py:73} INFO - Using connection ID 'spark-conn' for task execution.
[2024-11-14T16:18:32.351+0000] {spark_submit.py:403} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog --jars /opt/***/jars/hadoop-aws-3.3.4.jar,/opt/***/jars/s3-2.18.41.jar,/opt/***/jars/aws-java-sdk-1.12.367.jar,/opt/***/jars/delta-core_2.12-2.2.0.jar,/opt/***/jars/delta-storage-2.2.0.jar, --packages org.apache.hadoop:hadoop-aws:3.3.4 --num-executors 2 --total-executor-cores 2 --executor-cores 2 --executor-memory 2g --driver-memory 1g --name arrow-spark --deploy-mode client /opt/***/jobs/python/test_Credit.py s3a://lakehouse/bronze/credits.parquet s3a://lakehouse/sliver/credit
[2024-11-14T16:18:32.567+0000] {spark_submit.py:579} INFO - /home/***/.local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2024-11-14T16:18:35.031+0000] {spark_submit.py:579} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-11-14T16:18:35.204+0000] {spark_submit.py:579} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2024-11-14T16:18:35.205+0000] {spark_submit.py:579} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2024-11-14T16:18:35.213+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws added as a dependency
[2024-11-14T16:18:35.217+0000] {spark_submit.py:579} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-f85282eb-f1ff-453d-b171-13b8d812b9ba;1.0
[2024-11-14T16:18:35.218+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:18:35.404+0000] {spark_submit.py:579} INFO - found org.apache.hadoop#hadoop-aws;3.3.4 in central
[2024-11-14T16:18:35.440+0000] {spark_submit.py:579} INFO - found com.amazonaws#aws-java-sdk-bundle;1.12.262 in central
[2024-11-14T16:18:35.488+0000] {spark_submit.py:579} INFO - found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
[2024-11-14T16:18:35.517+0000] {spark_submit.py:579} INFO - :: resolution report :: resolve 290ms :: artifacts dl 9ms
[2024-11-14T16:18:35.518+0000] {spark_submit.py:579} INFO - :: modules in use:
[2024-11-14T16:18:35.519+0000] {spark_submit.py:579} INFO - com.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]
[2024-11-14T16:18:35.520+0000] {spark_submit.py:579} INFO - org.apache.hadoop#hadoop-aws;3.3.4 from central in [default]
[2024-11-14T16:18:35.521+0000] {spark_submit.py:579} INFO - org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
[2024-11-14T16:18:35.522+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:18:35.522+0000] {spark_submit.py:579} INFO - |                  |            modules            ||   artifacts   |
[2024-11-14T16:18:35.523+0000] {spark_submit.py:579} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-11-14T16:18:35.524+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:18:35.525+0000] {spark_submit.py:579} INFO - |      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
[2024-11-14T16:18:35.526+0000] {spark_submit.py:579} INFO - ---------------------------------------------------------------------
[2024-11-14T16:18:35.527+0000] {spark_submit.py:579} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-f85282eb-f1ff-453d-b171-13b8d812b9ba
[2024-11-14T16:18:35.527+0000] {spark_submit.py:579} INFO - confs: [default]
[2024-11-14T16:18:35.532+0000] {spark_submit.py:579} INFO - 0 artifacts copied, 3 already retrieved (0kB/7ms)
[2024-11-14T16:18:35.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-11-14T16:18:37.349+0000] {spark_submit.py:579} INFO - 2024-11-14 16:18:37,349 INFO: Python version on driver: 3.9.18
[2024-11-14T16:18:37.350+0000] {spark_submit.py:579} INFO - 2024-11-14 16:18:37,349 INFO: Initializing Spark session...
[2024-11-14T16:18:37.519+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SparkContext: Running Spark version 3.3.2
[2024-11-14T16:18:37.548+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceUtils: ==============================================================
[2024-11-14T16:18:37.549+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-11-14T16:18:37.550+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceUtils: ==============================================================
[2024-11-14T16:18:37.551+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SparkContext: Submitted application: CleanCredits
[2024-11-14T16:18:37.579+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-11-14T16:18:37.595+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
[2024-11-14T16:18:37.598+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-11-14T16:18:37.693+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SecurityManager: Changing view acls to: ***
[2024-11-14T16:18:37.694+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SecurityManager: Changing modify acls to: ***
[2024-11-14T16:18:37.695+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SecurityManager: Changing view acls groups to:
[2024-11-14T16:18:37.696+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SecurityManager: Changing modify acls groups to:
[2024-11-14T16:18:37.697+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2024-11-14T16:18:38.119+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO Utils: Successfully started service 'sparkDriver' on port 44299.
[2024-11-14T16:18:38.168+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkEnv: Registering MapOutputTracker
[2024-11-14T16:18:38.214+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkEnv: Registering BlockManagerMaster
[2024-11-14T16:18:38.242+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-11-14T16:18:38.243+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-11-14T16:18:38.248+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-11-14T16:18:38.277+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e4cb4f22-d50c-4ab1-984b-a3b3b8934966
[2024-11-14T16:18:38.304+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-11-14T16:18:38.324+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-11-14T16:18:38.681+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-11-14T16:18:38.743+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///opt/***/jars/hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44299/jars/hadoop-aws-3.3.4.jar with timestamp 1731601117501
[2024-11-14T16:18:38.745+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///opt/***/jars/s3-2.18.41.jar at spark://7ea45ba85247:44299/jars/s3-2.18.41.jar with timestamp 1731601117501
[2024-11-14T16:18:38.747+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///opt/***/jars/aws-java-sdk-1.12.367.jar at spark://7ea45ba85247:44299/jars/aws-java-sdk-1.12.367.jar with timestamp 1731601117501
[2024-11-14T16:18:38.749+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///opt/***/jars/delta-core_2.12-2.2.0.jar at spark://7ea45ba85247:44299/jars/delta-core_2.12-2.2.0.jar with timestamp 1731601117501
[2024-11-14T16:18:38.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///opt/***/jars/delta-storage-2.2.0.jar at spark://7ea45ba85247:44299/jars/delta-storage-2.2.0.jar with timestamp 1731601117501
[2024-11-14T16:18:38.751+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44299/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601117501
[2024-11-14T16:18:38.752+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:44299/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601117501
[2024-11-14T16:18:38.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:44299/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601117501
[2024-11-14T16:18:38.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar at spark://7ea45ba85247:44299/files/org.apache.hadoop_hadoop-aws-3.3.4.jar with timestamp 1731601117501
[2024-11-14T16:18:38.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.4.jar to /tmp/spark-cb49971b-ab3a-4fb5-97db-eff4bbd8e989/userFiles-e8b9f559-dfe9-4825-8881-f7620b9ac9ff/org.apache.hadoop_hadoop-aws-3.3.4.jar
[2024-11-14T16:18:38.773+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar at spark://7ea45ba85247:44299/files/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar with timestamp 1731601117501
[2024-11-14T16:18:38.774+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:38 INFO Utils: Copying /home/***/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar to /tmp/spark-cb49971b-ab3a-4fb5-97db-eff4bbd8e989/userFiles-e8b9f559-dfe9-4825-8881-f7620b9ac9ff/com.amazonaws_aws-java-sdk-bundle-1.12.262.jar
[2024-11-14T16:18:39.231+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://7ea45ba85247:44299/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1731601117501
[2024-11-14T16:18:39.233+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO Utils: Copying /home/***/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-cb49971b-ab3a-4fb5-97db-eff4bbd8e989/userFiles-e8b9f559-dfe9-4825-8881-f7620b9ac9ff/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar
[2024-11-14T16:18:39.373+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-11-14T16:18:39.619+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.21.0.3:7077 after 72 ms (0 ms spent in bootstraps)
[2024-11-14T16:18:39.805+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241114161839-0003
[2024-11-14T16:18:39.809+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241114161839-0003/0 on worker-20241114153331-172.21.0.8-42023 (172.21.0.8:42023) with 2 core(s)
[2024-11-14T16:18:39.815+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20241114161839-0003/0 on hostPort 172.21.0.8:42023 with 2 core(s), 2.0 GiB RAM
[2024-11-14T16:18:39.819+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34231.
[2024-11-14T16:18:39.820+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO NettyBlockTransferService: Server created on 7ea45ba85247:34231
[2024-11-14T16:18:39.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-11-14T16:18:39.831+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7ea45ba85247, 34231, None)
[2024-11-14T16:18:39.836+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO BlockManagerMasterEndpoint: Registering block manager 7ea45ba85247:34231 with 434.4 MiB RAM, BlockManagerId(driver, 7ea45ba85247, 34231, None)
[2024-11-14T16:18:39.840+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7ea45ba85247, 34231, None)
[2024-11-14T16:18:39.842+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7ea45ba85247, 34231, None)
[2024-11-14T16:18:39.968+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241114161839-0003/0 is now RUNNING
[2024-11-14T16:18:40.158+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:40 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-11-14T16:18:40.575+0000] {spark_submit.py:579} INFO - 2024-11-14 16:18:40,575 INFO: Spark session initialized successfully.
[2024-11-14T16:18:40.591+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2024-11-14T16:18:40.887+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:40 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2024-11-14T16:18:40.909+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:40 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2024-11-14T16:18:40.910+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:40 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2024-11-14T16:18:42.614+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:42 INFO SharedState: Warehouse path is 's3a://lakehouse/'.
[2024-11-14T16:18:44.690+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.8:39512) with ID 0,  ResourceProfileId 0
[2024-11-14T16:18:44.786+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.21.0.8:45041 with 1048.8 MiB RAM, BlockManagerId(0, 172.21.0.8, 45041, None)
[2024-11-14T16:18:45.069+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:45 INFO InMemoryFileIndex: It took 112 ms to list leaf files for 1 paths.
[2024-11-14T16:18:46.366+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2024-11-14T16:18:46.386+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:18:46.387+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:18:46.388+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:18:46.390+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:18:46.400+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:18:46.482+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 106.2 KiB, free 434.3 MiB)
[2024-11-14T16:18:48.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2024-11-14T16:18:50.285+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7ea45ba85247:34231 (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:18:50.291+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:18:50.312+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:18:50.314+0000] {spark_submit.py:579} INFO - 24/11/14 16:18:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2024-11-14T16:19:04.840+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4590 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:05.187+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.21.0.8:45041 (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:07.282+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2454 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:19:07.286+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2024-11-14T16:19:07.292+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 20.871 s
[2024-11-14T16:19:07.297+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:19:07.298+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2024-11-14T16:19:07.300+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 20.935380 s
[2024-11-14T16:19:07.458+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 7ea45ba85247:34231 in memory (size: 38.3 KiB, free: 434.4 MiB)
[2024-11-14T16:19:07.469+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.21.0.8:45041 in memory (size: 38.3 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:11.483+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:11 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:19:11.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:11 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:19:11.490+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:11 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, id: bigint>
[2024-11-14T16:19:12.096+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO CodeGenerator: Code generated in 234.129519 ms
[2024-11-14T16:19:12.137+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO CodeGenerator: Code generated in 28.980262 ms
[2024-11-14T16:19:12.183+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 206.2 KiB, free 434.2 MiB)
[2024-11-14T16:19:12.201+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 36.2 KiB, free 434.2 MiB)
[2024-11-14T16:19:12.202+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7ea45ba85247:34231 (size: 36.2 KiB, free: 434.4 MiB)
[2024-11-14T16:19:12.203+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO SparkContext: Created broadcast 1 from showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:19:12.233+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:19:12.316+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2024-11-14T16:19:12.318+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2024-11-14T16:19:12.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:19:12.320+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:19:12.321+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:12.323+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:19:12.493+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 27.9 KiB, free 434.1 MiB)
[2024-11-14T16:19:12.508+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 434.1 MiB)
[2024-11-14T16:19:12.512+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7ea45ba85247:34231 (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:19:12.515+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:12.518+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:19:12.519+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2024-11-14T16:19:12.534+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4913 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:12.620+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.21.0.8:45041 (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:13.563+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.21.0.8:45041 (size: 36.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:14.707+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2183 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:19:14.709+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2024-11-14T16:19:14.711+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 2.378 s
[2024-11-14T16:19:14.712+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:19:14.713+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2024-11-14T16:19:14.714+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 2.396639 s
[2024-11-14T16:19:14.785+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:14 INFO CodeGenerator: Code generated in 25.878955 ms
[2024-11-14T16:19:14.864+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:19:14.865+0000] {spark_submit.py:579} INFO - |id   |cast_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |director                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
[2024-11-14T16:19:14.866+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:19:14.866+0000] {spark_submit.py:579} INFO - |862  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.867+0000] {spark_submit.py:579} INFO - |8844 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.868+0000] {spark_submit.py:579} INFO - |15602|[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |[Walter Matthau, Jack Lemmon, Ann-Margret, Sophia Loren, Daryl Hannah, Burgess Meredith, Kevin Pollak]                                                                                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:19:14.869+0000] {spark_submit.py:579} INFO - |31357|[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |[Whitney Houston, Angela Bassett, Loretta Devine, Lela Rochon, Gregory Hines, Dennis Haysbert, Michael Beach, Mykelti Williamson, Lamont Johnson, Wesley Snipes]                                                                                                                                                                                                                                                                                                                                                  |
[2024-11-14T16:19:14.870+0000] {spark_submit.py:579} INFO - |11862|[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |[Steve Martin, Diane Keaton, Martin Short, Kimberly Williams-Paisley, George Newbern, Kieran Culkin, BD Wong, Peter Michael Goetz, Kate McGregor-Stewart, Jane Adams, Eugene Levy, Lori Alan]                                                                                                                                                                                                                                                                                                                     |
[2024-11-14T16:19:14.871+0000] {spark_submit.py:579} INFO - |949  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.872+0000] {spark_submit.py:579} INFO - |11860|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.872+0000] {spark_submit.py:579} INFO - |45325|[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |[Jonathan Taylor Thomas, Brad Renfro, Rachael Leigh Cook, Michael McShane, Amy Wright, Eric Schweig, Tamara Mello]                                                                                                                                                                                                                                                                                                                                                                                                |
[2024-11-14T16:19:14.873+0000] {spark_submit.py:579} INFO - |9091 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.875+0000] {spark_submit.py:579} INFO - |710  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.876+0000] {spark_submit.py:579} INFO - |9087 |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |[Michael Douglas, Annette Bening, Michael J. Fox, Martin Sheen, Anna Deavere Smith, Shawna Waldron, Samantha Mathis, David Paymer, Richard Dreyfuss, Nina Siemaszko, Wendie Malick, Beau Billingslea, Gail Strickland, Joshua Malina, Clement von Franckenstein, John Mahoney, John Mahon, Gabriel Jarret]                                                                                                                                                                                                        |
[2024-11-14T16:19:14.877+0000] {spark_submit.py:579} INFO - |12110|[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |[Leslie Nielsen, Mel Brooks, Amy Yasbeck, Peter MacNicol, Lysette Anthony, Harvey Korman, Steven Weber, Mark Blankfield, Megan Cavanagh, Gregg Binkley, Anne Bancroft]                                                                                                                                                                                                                                                                                                                                            |
[2024-11-14T16:19:14.877+0000] {spark_submit.py:579} INFO - |21032|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.878+0000] {spark_submit.py:579} INFO - |10858|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|[Anthony Hopkins, Joan Allen, Powers Boothe, Ed Harris, Bob Hoskins, E.G. Marshall, David Paymer, David Hyde Pierce, Paul Sorvino, Mary Steenburgen, J.T. Walsh, James Woods, Brian Bedford, Kevin Dunn, Fyvush Finkel, Annabeth Gish, Larry Hagman, Madeline Kahn, Dan Hedaya, Bridgette Wilson, Tom Bower, Tony Goldwyn, Edward Herrmann, Tony Lo Bianco, Saul Rubinek, Robert Beltran, John Cunningham, John Diehl, John C. McGinley, Michael Chiklis, Ric Young, Boris Sichkin, Sam Waterston, Marley Shelton]|
[2024-11-14T16:19:14.879+0000] {spark_submit.py:579} INFO - |1408 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.880+0000] {spark_submit.py:579} INFO - |524  |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.880+0000] {spark_submit.py:579} INFO - |4584 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.881+0000] {spark_submit.py:579} INFO - |5    |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.882+0000] {spark_submit.py:579} INFO - |9273 |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.883+0000] {spark_submit.py:579} INFO - |11517|null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
[2024-11-14T16:19:14.884+0000] {spark_submit.py:579} INFO - +-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2024-11-14T16:19:14.885+0000] {spark_submit.py:579} INFO - only showing top 20 rows
[2024-11-14T16:19:14.886+0000] {spark_submit.py:579} INFO - 
[2024-11-14T16:19:14.897+0000] {spark_submit.py:579} INFO - 2024-11-14 16:19:14,897 INFO: Saving cleaned data to s3a://lakehouse/sliver/credit
[2024-11-14T16:19:15.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty
[2024-11-14T16:19:15.739+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 7ea45ba85247:34231 in memory (size: 12.2 KiB, free: 434.4 MiB)
[2024-11-14T16:19:15.743+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.21.0.8:45041 in memory (size: 12.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:15.753+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7ea45ba85247:34231 in memory (size: 36.2 KiB, free: 434.4 MiB)
[2024-11-14T16:19:15.757+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.21.0.8:45041 in memory (size: 36.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:15.786+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO InitialSnapshot: [tableId=8c30c883-0050-4acf-a6e7-e497d417ec65] Created snapshot InitialSnapshot(path=s3a://lakehouse/sliver/credit/_delta_log, version=-1, metadata=Metadata(5006e61e-c4d2-44e1-862b-4d4e0bfe6f40,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601155773)), logSegment=LogSegment(s3a://lakehouse/sliver/credit/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:19:15.900+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO DeltaLog: No delta log found for the Delta table at s3a://lakehouse/sliver/credit/_delta_log
[2024-11-14T16:19:15.901+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO InitialSnapshot: [tableId=5006e61e-c4d2-44e1-862b-4d4e0bfe6f40] Created snapshot InitialSnapshot(path=s3a://lakehouse/sliver/credit/_delta_log, version=-1, metadata=Metadata(23187992-d55f-485a-b6e3-604fecb5c981,null,null,Format(parquet,Map()),null,List(),Map(),Some(1731601155900)), logSegment=LogSegment(s3a://lakehouse/sliver/credit/_delta_log,-1,List(),List(),None,-1), checksumOpt=None)
[2024-11-14T16:19:15.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:15 INFO OptimisticTransaction: [tableId=23187992,txnId=e1fc8637] Updated metadata from - to Metadata(b7c05502-f397-4a35-a6dd-7625f58f3c5a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"id","type":"long","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601155922))
[2024-11-14T16:19:16.442+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:19:16.443+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(transform(from_json(ArrayType(StructType(StructField(name,StringType,true)),true), cast#0, Some(Etc/UTC)), lambdafunction(lambda x#12.name, lambda x#12, false)))
[2024-11-14T16:19:16.444+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO FileSourceStrategy: Output Data Schema: struct<cast: string, crew: string, id: bigint ... 1 more fields>
[2024-11-14T16:19:16.545+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DeltaParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2024-11-14T16:19:16.611+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:19:16.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO CodeGenerator: Code generated in 59.545145 ms
[2024-11-14T16:19:16.729+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO CodeGenerator: Code generated in 23.964797 ms
[2024-11-14T16:19:16.736+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 206.3 KiB, free 434.2 MiB)
[2024-11-14T16:19:16.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 434.2 MiB)
[2024-11-14T16:19:16.758+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7ea45ba85247:34231 (size: 36.3 KiB, free: 434.4 MiB)
[2024-11-14T16:19:16.762+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO SparkContext: Created broadcast 3 from save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:19:16.766+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 36317959 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:19:16.840+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Registering RDD 15 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2024-11-14T16:19:16.846+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Got map stage job 2 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:19:16.847+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:19:16.848+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:19:16.849+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:16.852+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:19:16.882+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 49.0 KiB, free 434.1 MiB)
[2024-11-14T16:19:16.892+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 434.1 MiB)
[2024-11-14T16:19:16.895+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7ea45ba85247:34231 (size: 19.5 KiB, free: 434.3 MiB)
[2024-11-14T16:19:16.896+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:16.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:19:16.899+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0
[2024-11-14T16:19:16.902+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:16.903+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4902 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:16.942+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.21.0.8:45041 (size: 19.5 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:17.345+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.21.0.8:45041 (size: 36.3 KiB, free: 1048.7 MiB)
[2024-11-14T16:19:17.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 547 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:19:20.606+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 3706 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:19:20.607+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2024-11-14T16:19:20.608+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: ShuffleMapStage 2 (save at NativeMethodAccessorImpl.java:0) finished in 3.750 s
[2024-11-14T16:19:20.608+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:19:20.609+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: running: Set()
[2024-11-14T16:19:20.610+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:19:20.611+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: failed: Set()
[2024-11-14T16:19:20.636+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 5348362, minimum partition size: 1048576
[2024-11-14T16:19:20.662+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2024-11-14T16:19:20.714+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO CodeGenerator: Code generated in 44.668026 ms
[2024-11-14T16:19:20.818+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0
[2024-11-14T16:19:20.820+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Got job 3 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2024-11-14T16:19:20.821+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Final stage: ResultStage 4 (save at NativeMethodAccessorImpl.java:0)
[2024-11-14T16:19:20.821+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
[2024-11-14T16:19:20.822+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:20.823+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[17] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
[2024-11-14T16:19:20.870+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7ea45ba85247:34231 in memory (size: 19.5 KiB, free: 434.4 MiB)
[2024-11-14T16:19:20.874+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.21.0.8:45041 in memory (size: 19.5 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:20.875+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 367.3 KiB, free 433.8 MiB)
[2024-11-14T16:19:20.879+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 133.2 KiB, free 433.7 MiB)
[2024-11-14T16:19:20.881+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7ea45ba85247:34231 (size: 133.2 KiB, free: 434.2 MiB)
[2024-11-14T16:19:20.882+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:20.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2024-11-14T16:19:20.884+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0
[2024-11-14T16:19:20.903+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:20.904+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (172.21.0.8, executor 0, partition 1, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:20.927+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.21.0.8:45041 (size: 133.2 KiB, free: 1048.6 MiB)
[2024-11-14T16:19:21.145+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.21.0.8:39512
[2024-11-14T16:19:24.407+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 3506 ms on 172.21.0.8 (executor 0) (1/2)
[2024-11-14T16:19:24.408+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 3504 ms on 172.21.0.8 (executor 0) (2/2)
[2024-11-14T16:19:24.409+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2024-11-14T16:19:24.411+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO DAGScheduler: ResultStage 4 (save at NativeMethodAccessorImpl.java:0) finished in 3.567 s
[2024-11-14T16:19:24.412+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:19:24.413+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2024-11-14T16:19:24.414+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO DAGScheduler: Job 3 finished: save at NativeMethodAccessorImpl.java:0, took 3.595287 s
[2024-11-14T16:19:24.416+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO FileFormatWriter: Start to commit write Job adf0f4a7-e794-46d0-9b7d-1d5f240d9826.
[2024-11-14T16:19:24.419+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO FileFormatWriter: Write Job adf0f4a7-e794-46d0-9b7d-1d5f240d9826 committed. Elapsed time: 1 ms.
[2024-11-14T16:19:24.424+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:24 INFO FileFormatWriter: Finished processing stats for write job adf0f4a7-e794-46d0-9b7d-1d5f240d9826.
[2024-11-14T16:19:25.342+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 7ea45ba85247:34231 in memory (size: 133.2 KiB, free: 434.4 MiB)
[2024-11-14T16:19:25.346+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.21.0.8:45041 in memory (size: 133.2 KiB, free: 1048.8 MiB)
[2024-11-14T16:19:26.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO CodeGenerator: Code generated in 150.057482 ms
[2024-11-14T16:19:26.301+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128
[2024-11-14T16:19:26.302+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000331 s
[2024-11-14T16:19:26.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO OptimisticTransaction: [tableId=23187992,txnId=e1fc8637] Attempting to commit version 0 with 5 actions with Serializable isolation level
[2024-11-14T16:19:26.683+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO DeltaLog: Creating a new snapshot v0 for commit version 0
[2024-11-14T16:19:26.684+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO DeltaLog: Loading version 0.
[2024-11-14T16:19:26.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO Snapshot: [tableId=23187992-d55f-485a-b6e3-604fecb5c981] DELTA: Compute snapshot for version: 0
[2024-11-14T16:19:26.773+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 204.6 KiB, free 434.0 MiB)
[2024-11-14T16:19:26.788+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 433.9 MiB)
[2024-11-14T16:19:26.790+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7ea45ba85247:34231 (size: 35.6 KiB, free: 434.3 MiB)
[2024-11-14T16:19:26.792+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO SparkContext: Created broadcast 6 from toString at String.java:2951
[2024-11-14T16:19:26.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:26 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 2106)
[2024-11-14T16:19:27.233+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO FileSourceStrategy: Pushed Filters:
[2024-11-14T16:19:27.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO FileSourceStrategy: Post-Scan Filters:
[2024-11-14T16:19:27.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO FileSourceStrategy: Output Data Schema: struct<txn: struct<appId: string, version: bigint, lastUpdated: bigint ... 1 more fields>, add: struct<path: string, partitionValues: map<string,string>, size: bigint, modificationTime: bigint, dataChange: boolean ... 5 more fields>, remove: struct<path: string, deletionTimestamp: bigint, dataChange: boolean, extendedFileMetadata: boolean, partitionValues: map<string,string> ... 5 more fields>, metaData: struct<id: string, name: string, description: string, format: struct<provider: string, options: map<string,string>>, schemaString: string ... 6 more fields>, protocol: struct<minReaderVersion: int, minWriterVersion: int> ... 5 more fields>
[2024-11-14T16:19:27.252+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2024-11-14T16:19:27.429+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO CodeGenerator: Code generated in 73.146716 ms
[2024-11-14T16:19:27.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 204.9 KiB, free 433.7 MiB)
[2024-11-14T16:19:27.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 433.7 MiB)
[2024-11-14T16:19:27.450+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7ea45ba85247:34231 (size: 35.7 KiB, free: 434.3 MiB)
[2024-11-14T16:19:27.452+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO SparkContext: Created broadcast 7 from toString at String.java:2951
[2024-11-14T16:19:27.489+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2024-11-14T16:19:27.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Registering RDD 25 (toString at String.java:2951) as input to shuffle 1
[2024-11-14T16:19:27.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Got map stage job 5 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:19:27.524+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (toString at String.java:2951)
[2024-11-14T16:19:27.525+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Parents of final stage: List()
[2024-11-14T16:19:27.526+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:27.526+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:19:27.546+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 124.3 KiB, free 433.6 MiB)
[2024-11-14T16:19:27.558+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 433.5 MiB)
[2024-11-14T16:19:27.560+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7ea45ba85247:34231 (size: 35.2 KiB, free: 434.3 MiB)
[2024-11-14T16:19:27.562+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:27.563+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:19:27.564+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2024-11-14T16:19:27.566+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.21.0.8, executor 0, partition 0, PROCESS_LOCAL, 4930 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:27.589+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.21.0.8:45041 (size: 35.2 KiB, free: 1048.7 MiB)
[2024-11-14T16:19:27.974+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.21.0.8:45041 (size: 35.7 KiB, free: 1048.7 MiB)
[2024-11-14T16:19:28.049+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 484 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:19:28.050+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2024-11-14T16:19:28.051+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO DAGScheduler: ShuffleMapStage 5 (toString at String.java:2951) finished in 0.524 s
[2024-11-14T16:19:28.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:19:28.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO DAGScheduler: running: Set()
[2024-11-14T16:19:28.053+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:19:28.054+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO DAGScheduler: failed: Set()
[2024-11-14T16:19:28.149+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 7ea45ba85247:34231 in memory (size: 35.2 KiB, free: 434.3 MiB)
[2024-11-14T16:19:28.152+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.21.0.8:45041 in memory (size: 35.2 KiB, free: 1048.7 MiB)
[2024-11-14T16:19:28.422+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 14899 bytes
[2024-11-14T16:19:28.423+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO CodeGenerator: Code generated in 218.448401 ms
[2024-11-14T16:19:28.540+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:28 INFO CodeGenerator: Code generated in 92.025841 ms
[2024-11-14T16:19:29.071+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO CodeGenerator: Code generated in 54.057254 ms
[2024-11-14T16:19:29.082+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Registering RDD 35 (toString at String.java:2951) as input to shuffle 2
[2024-11-14T16:19:29.083+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Got map stage job 6 (toString at String.java:2951) with 50 output partitions
[2024-11-14T16:19:29.083+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (toString at String.java:2951)
[2024-11-14T16:19:29.084+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2024-11-14T16:19:29.090+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:29.092+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[35] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:19:29.260+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 426.2 KiB, free 433.3 MiB)
[2024-11-14T16:19:29.265+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 102.6 KiB, free 433.2 MiB)
[2024-11-14T16:19:29.268+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7ea45ba85247:34231 (size: 102.6 KiB, free: 434.2 MiB)
[2024-11-14T16:19:29.269+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:29.284+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[35] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2024-11-14T16:19:29.285+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO TaskSchedulerImpl: Adding task set 7.0 with 50 tasks resource profile 0
[2024-11-14T16:19:29.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:29.288+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 8) (172.21.0.8, executor 0, partition 33, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:29.313+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.21.0.8:45041 (size: 102.6 KiB, free: 1048.6 MiB)
[2024-11-14T16:19:29.468+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.21.0.8:39512
[2024-11-14T16:19:30.049+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_0 in memory on 172.21.0.8:45041 (size: 465.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.050+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_33 in memory on 172.21.0.8:45041 (size: 463.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.250+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 9) (172.21.0.8, executor 0, partition 42, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.251+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 8) in 963 ms on 172.21.0.8 (executor 0) (1/50)
[2024-11-14T16:19:30.254+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10) (172.21.0.8, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.255+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 968 ms on 172.21.0.8 (executor 0) (2/50)
[2024-11-14T16:19:30.325+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_1 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.367+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 11) (172.21.0.8, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 115 ms on 172.21.0.8 (executor 0) (3/50)
[2024-11-14T16:19:30.442+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_2 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.478+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 12) (172.21.0.8, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.479+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 11) in 113 ms on 172.21.0.8 (executor 0) (4/50)
[2024-11-14T16:19:30.561+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_3 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.591+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 13) (172.21.0.8, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.592+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 12) in 113 ms on 172.21.0.8 (executor 0) (5/50)
[2024-11-14T16:19:30.610+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_42 in memory on 172.21.0.8:45041 (size: 556.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.648+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 14) (172.21.0.8, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.649+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 9) in 399 ms on 172.21.0.8 (executor 0) (6/50)
[2024-11-14T16:19:30.656+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_4 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.695+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 15) (172.21.0.8, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.696+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 13) in 105 ms on 172.21.0.8 (executor 0) (7/50)
[2024-11-14T16:19:30.705+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_5 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.755+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 16) (172.21.0.8, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.756+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 14) in 108 ms on 172.21.0.8 (executor 0) (8/50)
[2024-11-14T16:19:30.772+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_6 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.806+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 17) (172.21.0.8, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 15) in 112 ms on 172.21.0.8 (executor 0) (9/50)
[2024-11-14T16:19:30.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_7 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.837+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 18) (172.21.0.8, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.838+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 16) in 83 ms on 172.21.0.8 (executor 0) (10/50)
[2024-11-14T16:19:30.864+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_8 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.898+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 19) (172.21.0.8, executor 0, partition 10, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.899+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_9 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.900+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 17) in 94 ms on 172.21.0.8 (executor 0) (11/50)
[2024-11-14T16:19:30.935+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 20) (172.21.0.8, executor 0, partition 11, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.936+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 18) in 98 ms on 172.21.0.8 (executor 0) (12/50)
[2024-11-14T16:19:30.963+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_10 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:30.993+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 21) (172.21.0.8, executor 0, partition 12, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:30.995+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 19) in 96 ms on 172.21.0.8 (executor 0) (13/50)
[2024-11-14T16:19:30.996+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:30 INFO BlockManagerInfo: Added rdd_32_11 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.026+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 22) (172.21.0.8, executor 0, partition 13, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.027+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 20) in 93 ms on 172.21.0.8 (executor 0) (14/50)
[2024-11-14T16:19:31.050+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_12 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.078+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 23) (172.21.0.8, executor 0, partition 14, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.079+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_13 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.080+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 21) in 85 ms on 172.21.0.8 (executor 0) (15/50)
[2024-11-14T16:19:31.106+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 24) (172.21.0.8, executor 0, partition 15, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.107+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 22) in 82 ms on 172.21.0.8 (executor 0) (16/50)
[2024-11-14T16:19:31.130+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_14 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.157+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_15 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.160+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 25) (172.21.0.8, executor 0, partition 16, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.161+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 23) in 84 ms on 172.21.0.8 (executor 0) (17/50)
[2024-11-14T16:19:31.185+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 26) (172.21.0.8, executor 0, partition 17, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.186+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 24) in 80 ms on 172.21.0.8 (executor 0) (18/50)
[2024-11-14T16:19:31.208+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_16 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.230+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_17 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.234+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 27) (172.21.0.8, executor 0, partition 18, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.235+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 25) in 74 ms on 172.21.0.8 (executor 0) (19/50)
[2024-11-14T16:19:31.263+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 28) (172.21.0.8, executor 0, partition 19, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.264+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 26) in 79 ms on 172.21.0.8 (executor 0) (20/50)
[2024-11-14T16:19:31.287+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_18 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.308+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_19 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.313+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 29) (172.21.0.8, executor 0, partition 20, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.314+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 27) in 81 ms on 172.21.0.8 (executor 0) (21/50)
[2024-11-14T16:19:31.337+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 30) (172.21.0.8, executor 0, partition 21, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.338+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 28) in 76 ms on 172.21.0.8 (executor 0) (22/50)
[2024-11-14T16:19:31.368+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_20 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.401+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_21 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.403+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 31) (172.21.0.8, executor 0, partition 22, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.404+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 29) in 92 ms on 172.21.0.8 (executor 0) (23/50)
[2024-11-14T16:19:31.433+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 32) (172.21.0.8, executor 0, partition 23, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.434+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 30) in 97 ms on 172.21.0.8 (executor 0) (24/50)
[2024-11-14T16:19:31.458+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_22 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.485+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 33) (172.21.0.8, executor 0, partition 24, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.486+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 31) in 82 ms on 172.21.0.8 (executor 0) (25/50)
[2024-11-14T16:19:31.487+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_23 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 34) (172.21.0.8, executor 0, partition 25, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.517+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 32) in 85 ms on 172.21.0.8 (executor 0) (26/50)
[2024-11-14T16:19:31.535+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_24 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.564+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 35) (172.21.0.8, executor 0, partition 26, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.565+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 33) in 80 ms on 172.21.0.8 (executor 0) (27/50)
[2024-11-14T16:19:31.568+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_25 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.591+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 36) (172.21.0.8, executor 0, partition 27, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.592+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 34) in 76 ms on 172.21.0.8 (executor 0) (28/50)
[2024-11-14T16:19:31.608+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_26 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.636+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 37) (172.21.0.8, executor 0, partition 28, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.637+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_27 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.638+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 35) in 74 ms on 172.21.0.8 (executor 0) (29/50)
[2024-11-14T16:19:31.665+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 38) (172.21.0.8, executor 0, partition 29, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.666+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 36) in 75 ms on 172.21.0.8 (executor 0) (30/50)
[2024-11-14T16:19:31.685+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_28 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.710+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 39) (172.21.0.8, executor 0, partition 30, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.711+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 37) in 75 ms on 172.21.0.8 (executor 0) (31/50)
[2024-11-14T16:19:31.717+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_29 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.743+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 40) (172.21.0.8, executor 0, partition 31, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.744+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 38) in 80 ms on 172.21.0.8 (executor 0) (32/50)
[2024-11-14T16:19:31.765+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_30 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.803+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 41) (172.21.0.8, executor 0, partition 32, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.804+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 39) in 93 ms on 172.21.0.8 (executor 0) (33/50)
[2024-11-14T16:19:31.808+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_31 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.833+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 42) (172.21.0.8, executor 0, partition 34, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.834+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 40) in 91 ms on 172.21.0.8 (executor 0) (34/50)
[2024-11-14T16:19:31.851+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_32 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.878+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 43) (172.21.0.8, executor 0, partition 35, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.879+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 41) in 76 ms on 172.21.0.8 (executor 0) (35/50)
[2024-11-14T16:19:31.882+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_34 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.916+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 44) (172.21.0.8, executor 0, partition 36, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.917+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 42) in 84 ms on 172.21.0.8 (executor 0) (36/50)
[2024-11-14T16:19:31.929+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_35 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.965+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO BlockManagerInfo: Added rdd_32_36 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:31.970+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 45) (172.21.0.8, executor 0, partition 37, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.971+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 43) in 94 ms on 172.21.0.8 (executor 0) (37/50)
[2024-11-14T16:19:31.992+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 46) (172.21.0.8, executor 0, partition 38, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:31.993+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:31 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 44) in 77 ms on 172.21.0.8 (executor 0) (38/50)
[2024-11-14T16:19:32.022+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_37 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.050+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_38 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.051+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 47) (172.21.0.8, executor 0, partition 39, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.052+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 45) in 80 ms on 172.21.0.8 (executor 0) (39/50)
[2024-11-14T16:19:32.076+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 48) (172.21.0.8, executor 0, partition 40, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.077+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 46) in 84 ms on 172.21.0.8 (executor 0) (40/50)
[2024-11-14T16:19:32.097+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_39 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.122+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_40 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.125+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 49) (172.21.0.8, executor 0, partition 41, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.126+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 47) in 77 ms on 172.21.0.8 (executor 0) (41/50)
[2024-11-14T16:19:32.150+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 50) (172.21.0.8, executor 0, partition 43, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.151+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 48) in 76 ms on 172.21.0.8 (executor 0) (42/50)
[2024-11-14T16:19:32.176+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_41 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.198+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_43 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.202+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 51) (172.21.0.8, executor 0, partition 44, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.203+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 49) in 78 ms on 172.21.0.8 (executor 0) (43/50)
[2024-11-14T16:19:32.224+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 52) (172.21.0.8, executor 0, partition 45, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.225+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 50) in 76 ms on 172.21.0.8 (executor 0) (44/50)
[2024-11-14T16:19:32.247+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_44 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.270+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 53) (172.21.0.8, executor 0, partition 46, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.271+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 51) in 69 ms on 172.21.0.8 (executor 0) (45/50)
[2024-11-14T16:19:32.281+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_45 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.306+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 54) (172.21.0.8, executor 0, partition 47, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.307+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 52) in 82 ms on 172.21.0.8 (executor 0) (46/50)
[2024-11-14T16:19:32.319+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_46 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.347+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 55) (172.21.0.8, executor 0, partition 48, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.348+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 53) in 78 ms on 172.21.0.8 (executor 0) (47/50)
[2024-11-14T16:19:32.354+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_47 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.379+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 56) (172.21.0.8, executor 0, partition 49, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.380+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 54) in 74 ms on 172.21.0.8 (executor 0) (48/50)
[2024-11-14T16:19:32.393+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_48 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.420+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 55) in 73 ms on 172.21.0.8 (executor 0) (49/50)
[2024-11-14T16:19:32.424+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added rdd_32_49 in memory on 172.21.0.8:45041 (size: 46.0 B, free: 1048.6 MiB)
[2024-11-14T16:19:32.446+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 56) in 67 ms on 172.21.0.8 (executor 0) (50/50)
[2024-11-14T16:19:32.446+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2024-11-14T16:19:32.447+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: ShuffleMapStage 7 (toString at String.java:2951) finished in 3.347 s
[2024-11-14T16:19:32.448+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: looking for newly runnable stages
[2024-11-14T16:19:32.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: running: Set()
[2024-11-14T16:19:32.449+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: waiting: Set()
[2024-11-14T16:19:32.450+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: failed: Set()
[2024-11-14T16:19:32.480+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 7ea45ba85247:34231 in memory (size: 102.6 KiB, free: 434.3 MiB)
[2024-11-14T16:19:32.482+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.21.0.8:45041 in memory (size: 102.6 KiB, free: 1048.7 MiB)
[2024-11-14T16:19:32.488+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO SparkContext: Starting job: toString at String.java:2951
[2024-11-14T16:19:32.489+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Got job 7 (toString at String.java:2951) with 1 output partitions
[2024-11-14T16:19:32.490+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Final stage: ResultStage 10 (toString at String.java:2951)
[2024-11-14T16:19:32.491+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
[2024-11-14T16:19:32.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Missing parents: List()
[2024-11-14T16:19:32.492+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at toString at String.java:2951), which has no missing parents
[2024-11-14T16:19:32.497+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 372.3 KiB, free 433.3 MiB)
[2024-11-14T16:19:32.506+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 433.2 MiB)
[2024-11-14T16:19:32.507+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7ea45ba85247:34231 (size: 91.6 KiB, free: 434.2 MiB)
[2024-11-14T16:19:32.520+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
[2024-11-14T16:19:32.521+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at toString at String.java:2951) (first 15 tasks are for partitions Vector(0))
[2024-11-14T16:19:32.522+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2024-11-14T16:19:32.523+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 57) (172.21.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2024-11-14T16:19:32.536+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.21.0.8:45041 (size: 91.6 KiB, free: 1048.6 MiB)
[2024-11-14T16:19:32.551+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.21.0.8:39512
[2024-11-14T16:19:32.618+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 57) in 96 ms on 172.21.0.8 (executor 0) (1/1)
[2024-11-14T16:19:32.619+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2024-11-14T16:19:32.620+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: ResultStage 10 (toString at String.java:2951) finished in 0.127 s
[2024-11-14T16:19:32.620+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2024-11-14T16:19:32.621+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
[2024-11-14T16:19:32.622+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DAGScheduler: Job 7 finished: toString at String.java:2951, took 0.132327 s
[2024-11-14T16:19:32.670+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO CodeGenerator: Code generated in 32.454611 ms
[2024-11-14T16:19:32.674+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO Snapshot: [tableId=23187992-d55f-485a-b6e3-604fecb5c981] DELTA: Done
[2024-11-14T16:19:32.674+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO Snapshot: [tableId=23187992-d55f-485a-b6e3-604fecb5c981] Created snapshot Snapshot(path=s3a://lakehouse/sliver/credit/_delta_log, version=0, metadata=Metadata(b7c05502-f397-4a35-a6dd-7625f58f3c5a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"id","type":"long","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601155922)), logSegment=LogSegment(s3a://lakehouse/sliver/credit/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/sliver/credit/_delta_log/00000000000000000000.json; isDirectory=false; length=2106; replication=1; blocksize=33554432; modification_time=1731601166614; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=703dc11b3a339da99996854456ea1999 versionId=null),List(),None,1731601166614), checksumOpt=None)
[2024-11-14T16:19:32.676+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://lakehouse/sliver/credit/_delta_log, version=0, metadata=Metadata(b7c05502-f397-4a35-a6dd-7625f58f3c5a,null,null,Format(parquet,Map()),{"type":"struct","fields":[{"name":"cast","type":{"type":"array","elementType":{"type":"struct","fields":[{"name":"name","type":"string","nullable":true,"metadata":{}}]},"containsNull":true},"nullable":true,"metadata":{}},{"name":"crew","type":"string","nullable":true,"metadata":{}},{"name":"id","type":"long","nullable":true,"metadata":{}},{"name":"cast_name","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}},{"name":"director","type":{"type":"array","elementType":"string","containsNull":true},"nullable":true,"metadata":{}}]},List(),Map(),Some(1731601155922)), logSegment=LogSegment(s3a://lakehouse/sliver/credit/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://lakehouse/sliver/credit/_delta_log/00000000000000000000.json; isDirectory=false; length=2106; replication=1; blocksize=33554432; modification_time=1731601166614; access_time=0; owner=***; group=***; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=703dc11b3a339da99996854456ea1999 versionId=null),List(),None,1731601166614), checksumOpt=None)
[2024-11-14T16:19:32.701+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO OptimisticTransaction: [tableId=23187992,txnId=e1fc8637] Committed delta #0 to s3a://lakehouse/sliver/credit/_delta_log
[2024-11-14T16:19:32.707+0000] {spark_submit.py:579} INFO - 2024-11-14 16:19:32,707 INFO: Data cleaning and saving process completed successfully.
[2024-11-14T16:19:32.708+0000] {spark_submit.py:579} INFO - 2024-11-14 16:19:32,707 INFO: Data cleaning and saving process completed successfully.
[2024-11-14T16:19:32.730+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO SparkUI: Stopped Spark web UI at http://7ea45ba85247:4040
[2024-11-14T16:19:32.735+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO StandaloneSchedulerBackend: Shutting down all executors
[2024-11-14T16:19:32.736+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2024-11-14T16:19:32.764+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-11-14T16:19:32.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO MemoryStore: MemoryStore cleared
[2024-11-14T16:19:32.796+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManager: BlockManager stopped
[2024-11-14T16:19:32.800+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-11-14T16:19:32.807+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-11-14T16:19:32.829+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:32 INFO SparkContext: Successfully stopped SparkContext
[2024-11-14T16:19:33.272+0000] {spark_submit.py:579} INFO - 2024-11-14 16:19:33,272 INFO: Closing down clientserver connection
[2024-11-14T16:19:33.336+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO ShutdownHookManager: Shutdown hook called
[2024-11-14T16:19:33.337+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-e677d76f-5eeb-49e5-a7ba-c89367d3e085
[2024-11-14T16:19:33.342+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb49971b-ab3a-4fb5-97db-eff4bbd8e989
[2024-11-14T16:19:33.347+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb49971b-ab3a-4fb5-97db-eff4bbd8e989/pyspark-4a796d5c-74a2-4bd6-9a29-2034d72815ea
[2024-11-14T16:19:33.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2024-11-14T16:19:33.356+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2024-11-14T16:19:33.357+0000] {spark_submit.py:579} INFO - 24/11/14 16:19:33 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2024-11-14T16:19:33.444+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=test_flowwww, task_id=credits_cleaned, execution_date=20241114T153601, start_date=20241114T161832, end_date=20241114T161933
[2024-11-14T16:19:33.582+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-11-14T16:19:33.618+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
