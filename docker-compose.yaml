
x-airflow-common: &airflow-common
  build:
    context: ./docker_image/airflow
    dockerfile: ./Dockerfile
  env_file:
    - ./docker_image/airflow/airflow.env

  volumes:
    - ./airflow/jobs:/opt/airflow/jobs
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
  depends_on:
    - postgres

services:
  mariadb:
    hostname: mariadb
    image: mariadb:10.5.16
    ports:
      - 3306:3306
    env_file: .env
    volumes:
      - mariadb:/var/lib/mysql

  # Hive metastore
  hive-metastore:
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore:latest"
    ports:
      - "9083:9083" # Metastore Thrift
    volumes:
      - ./data_lakehouse/conf/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    env_file: .env
    depends_on:
      - mariadb

  trino-450:
    hostname: trino-450
    image: "trinodb/trino:450"
    ports:
      - "8082:8080"
    volumes:
      - ./data_lakehouse/etc:/etc/trino
    depends_on:
      - minio
      - hive-metastore

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  spark-master:
    build:
      context: ./docker_image/spark
      dockerfile: ./Dockerfile
    container_name: "spark-master-movies"
    ports:
      - "7077:7077" # Spark master port
      - "8081:8080" # Spark master web UI port
    expose:
      - "7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker_image/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - ./data:/opt/spark


  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: "spark-worker-1-movies"
    env_file:
      - .env
    depends_on:
      - spark-master

  minio:
    hostname: minio
    image: "minio/minio:latest"
    container_name: minio-movies
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - minio:/data
    env_file: .env
    command: ["server", "/data", "--console-address", ":9001"]
    # UI dashboard
  superset:
    build:
      context: ./docker_image/superset
      dockerfile: ./Dockerfile
    container_name: Superset-movies
    env_file:
      - .env
    ports:
      - "8088:8088"
    volumes:
      - superset_home:/app/superset_home

  webserver-1:
    <<: *airflow-common
    command: webserver
    ports:
      - "8085:8080"
    depends_on:
      - scheduler

  scheduler:
    <<: *airflow-common
    command: bash -c "airflow db migrate && airflow users create --username admin --firstname Yusuf --lastname Ganiyu --role Admin --email airscholar@gmail.com --password admin && airflow scheduler"
  
  jupyter:
    image: jupyter/pyspark-notebook:spark-3.3.2
    container_name: jupyter
    ports:
      - "8888:8888"   # Jupyter Notebook
    volumes:
      - ./jupyter/notebooks:/home/jovyan/work
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master

  # jupyter:
  #   build:
  #     context: ./docker_image/jupyter
  #     dockerfile: ./Dockerfile
  #   container_name: jupyter-notebook
  #   volumes:
  #     - ./notebooks:/workspace
  #   ports:
  #     - "8888:8888"
  #   environment:
  #     - PYSPARK_PYTHON=python3
  #     - SPARK_MASTER=spark://spark-master:7077
  #   command: jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root
volumes:
  postgres-db-volume:
  minio:
  airflow-data:
  mariadb:
  superset_home:

networks:
  default:
    driver: bridge
